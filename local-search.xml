<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>读《强风吹拂》</title>
    <link href="/2022/04/08/%E8%AF%BB%E4%B9%A6/%E5%BC%BA%E9%A3%8E%E5%90%B9%E6%8B%82/"/>
    <url>/2022/04/08/%E8%AF%BB%E4%B9%A6/%E5%BC%BA%E9%A3%8E%E5%90%B9%E6%8B%82/</url>
    
    <content type="html"><![CDATA[<h2 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h2><h3 id="第一章-竹青庄的房客"><a href="#第一章-竹青庄的房客" class="headerlink" title="第一章 竹青庄的房客"></a>第一章 竹青庄的房客</h3><p>明明没有目的地，却仍日日不间断地跑下去——这样的人，能够断言自己究竟是喜欢还是讨厌跑步吗？</p><p>对阿走而言，能纯粹地享受跑步的乐趣，只停留在幼时踏着青草跑遍高山原野的时期。之后的跑步生涯，无非是被困在椭圆形跑道上，拼命挣扎并抵抗时间流逝的速度——直到那一天，那股一发不可收拾的冲动粉碎了过去堆砌起来的一切。</p><p>即使如此，他也没有因此觉得恐惧或不安。他对独自在人生地不熟的地方生活不以为苦，反而感觉如获新生。</p><p>“为了自我锻炼，”姆萨说，“人在黑暗中下水时，心中往往会产生很大的不安，然而我认为这是一帖省视自我的良方。阿走，你不妨也试试看。”</p><p>呼吸越来越困难，但阿走依然不换气，只是出于习惯地计数自己的心跳。比这还痛苦的经验，他在跑步时可尝过许多；跑到肺部充血，跑到血的气味涌上喉头，是很寻常的事。尽管如此，他还是继续在跑，这是为什么？因为他在跑步中找到快乐吗？还是他不想输给任何人，不想输给自己？</p><h3 id="第二章-天下第一险峰——箱根山"><a href="#第二章-天下第一险峰——箱根山" class="headerlink" title="第二章 天下第一险峰——箱根山"></a>第二章 天下第一险峰——箱根山</h3><p>不论是代表学校参加竞赛，或是在世界舞台上留下纪录的可能性，阿走对这些都毫无眷恋。相较之下，他更喜欢的是：感受肉体破风前进的舒畅感，自由任意的奔驰。那些被组织的期待与野心束缚、像只白老鼠一般任人宰制的日子，他早就厌倦了。</p><p>退出田径队后，阿走仍持续进行自我锻炼，想到达那个他尚未能得见的疾速世界。流逝而过的景色，掠过两耳的风。等他跑出五千米13分40秒的成绩时，自己将目睹什么样的景致？自己的肉体又会使血液沸腾到什么地步？无论如何，他一定要亲身体验这未知的世界。</p><p>“我很想知道，跑步的真谛究竟是什么。”</p><h3 id="第三章-开始练习吧！"><a href="#第三章-开始练习吧！" class="headerlink" title="第三章 开始练习吧！"></a>第三章 开始练习吧！</h3><p>在那样狭隘的人际关系里，他忙着求生存，根本无暇思考、感受其他事物。</p><p>换个角度来说，如果不每天跟自己的身体对话、累积练习量，就没办法在长跑项目拿到好成绩。每一种运动都需要天分，但长跑运动需要的“努力”绝对大于“天分”，而这也是它和其他运动最大的不同。</p><p>“阿走，你觉得什么样的人适合长跑？”</p><p>这种全心全意投注在同一件事上却不以为苦的个性，绝对很适合长跑。”</p><p>为跑步而生的阿走，以及很清楚“想跑却不能跑”有多痛苦的清濑。这两个对跑步怀抱无比热情的人，一定能影响彼此，抵达大多数人难以窥见的至高境界。</p><p>Cross country，是越野赛跑的简称</p><p>就是照着设定好的速度来跑。每一次跑步前，我都会依据你们的体能状态和跑力[2]来调整速度。”</p><p>跑步时最重要的是放松身体，好让自己能跑得久、跑得越来越远。</p><p>Jog，就是慢跑的意思</p><p>加速跑是慢慢地加快速度，然后冲刺；间歇跑则是一种快跑和慢跑交错组合的跑法</p><p>练跑的目的就是增加心肺功能的负担，当然要辛苦一点才有意义</p><p>清濑是个性谨慎细腻的人，因此要求每个人都要填写练习日志。除了必须记下训练表规定的练习花费多少时间，也得记录自己每天自发地做了哪些训练，跑了多久、多远。</p><h3 id="第四章-纪录赛登场"><a href="#第四章-纪录赛登场" class="headerlink" title="第四章 纪录赛登场"></a>第四章 纪录赛登场</h3><p>我把田径当成自己的第二生命，一般人却只把它当成一项无聊的比赛。这个事实对阿走造成很大的冲击，却又不禁同时沾沾自喜起来：原来我们每天拼死拼活追求的目标，大多数人都看不出来它多么有意义呀。</p><h3 id="第六章-灵魂的呼喊"><a href="#第六章-灵魂的呼喊" class="headerlink" title="第六章 灵魂的呼喊"></a>第六章 灵魂的呼喊</h3><p>不被任何事物牵绊，自由地尽情奔跑。不听从任何指挥，只听从身体和灵魂深处发出的呐喊，跑到天涯海角。</p><p>如果只是疯狂地拼命练习，绝对没办法掌握个中精髓。这是一场和自己内心搏斗的战役。我希望你们倾听自己身心的声音，小心谨慎地磨炼自己。”</p><p>战胜不安与恐惧，把自己锻炼得锐利光滑、百尘不侵——这样的力量，就是清濑所说的“强”之一吧。</p><h3 id="第七章-预赛，开跑！"><a href="#第七章-预赛，开跑！" class="headerlink" title="第七章 预赛，开跑！"></a>第七章 预赛，开跑！</h3><p>看着不断加速的阿走，清濑不禁陷入一阵狂喜。<br>大家好好睁大眼，看清楚他跑步的模样！看他那为跑步而生的身躯有多美丽！</p><p>清濑很想放声大喊，但现在只能想办法忍住。阿走，果然只有你。只有你可以这样体现跑步的真貌。能够鞭策我、让我见识到全新世界的人，只有你，阿走。</p><p>认真起来的阿走，竟然能跑这么快！他浑身散发出光芒，耀眼得让人无法直视。果然是万中选一的人。根本不用多说什么就能证明这一切。</p><p>他发出粗重的喘息声，一瞬间就从叶菜子面前经过，笔直地往前跑去，眼里只看得见终点线。他像在短跑一样全力冲刺，跑完最后的五十米，充满坚持和斗志的跑姿震慑了全场的观众。</p><p>因为我想，跟满脑子肌肉的你们，这辈子一起筑梦一次也不错，所以才……！</p><p>“他们犯的另外一个错误是，以为运动只要赢了就好，”藤冈继续说，“日本选手只要得第一名、拿金牌就好了吗？真是大错特错。这绝对不是运动的本质。如果今天我拿到第一却有种输给自己的感觉，对我而言这根本就不算胜利。比赛的成绩和排名，会让人眼花缭乱，模糊了焦点。所谓世界第一，应该由谁决定？我们追求的，不是这种东西；心里那个不变的理想和目标，才是支持我们继续跑下去的动力，不是吗？”</p><p>“要在箱根连胜，就是需要这样的意志力和真正的智慧吧。”</p><p>藤冈把心里的想法转换成语言的力量；他冷静分析自己内心迷惘、愤怒和恐惧的眼光。</p><p>藤冈很强。他的跑步速度本来就无人可出其右，但背后那股支撑着他的意志力其实更厉害。在我只知道不顾一切往前跑时，藤冈一定在他脑子里进行了无数的自我剖析，追求更高境界的跑法。</p><p>这就是我欠缺的。每次遇到说不清楚、讲不明白的地方，总是放任它过去，草草带过。从现在起，不能再这样了。我要像藤冈，不，我要跑得比藤冈更快。为了达到这个目标，我必须认清那个跑步中的我。</p><p>这一定就是清濑之前所说的那种“强”。<br>“我觉得我好像懂了。”</p><h3 id="第八章-冬天又来了"><a href="#第八章-冬天又来了" class="headerlink" title="第八章 冬天又来了"></a>第八章 冬天又来了</h3><p>阿走的心思，几乎全被跑步占去了，例如手腕摆动的幅度、双脚着地时的角度，或是肌肉的紧张和弛缓度等问题。这样比较好？还是那样？他对全身上下的每个细胞都保持高度关注，确认着跑出去的每一步。</p><p>榊每次说的话，其实都有他的道理。只不过，我跟他不一样。我所追求的、想透过跑步发现的事物，应该都跟榊不同吧。</p><p>阿走偷偷伸手摸摸自己的胸口。怎么回事啊？心脏竟然一阵阵隐隐作痛。就像喝冰的饮料时渗进牙齿那种感觉，让牙龈发肿、热热的、刺刺的那种痛。</p><p>愤怒，是他内心怯懦和缺乏自信的写照。清濑和叶菜子叫他要“相信”，其实是想叫他“勇敢面对”吧。勇敢面对自己、面对对手。</p><p>“我很后悔。我气自己那个时候除了打人，想不到其他的解决方法。只有这样而已。”</p><p>阿雪手上提着下北泽一家唱片行的袋子。无论有多忙，阿雪的生活里还是不能没有音乐。</p><p>“家家有本难念的经。总之，家人之间，最好不要对彼此有太多期待，就算关心也要保持适当的距离。”</p><p>明明是一个明年就会面临存亡危机的小社团。明明是一堆门外汉在硬撑，好不容易才走到今天。但是清濑不知道什么是放弃，永远向前看，给大家带来梦想和目标，坚定地领导竹青庄的每个人，追求跑步的最高境界，朝着结合个人竞技与团体竞技的终极目标——箱根驿传的顶点前进。</p><p>“我会让你们看到顶点的，不对，应该说，我们一起来享受站上顶点那种滋味。大家拭目以待。”</p><h3 id="第九章-奔向彼方"><a href="#第九章-奔向彼方" class="headerlink" title="第九章 奔向彼方"></a>第九章 奔向彼方</h3><p>“王子，到今天为止，一直勉强你陪着我们拼这一场，不好意思呐。”清濑说。</p><p>“灰二哥，我不想听到这种话，”王子笑着说，“在鹤见等我吧。”</p><p>总之他没抓到自己该有的节奏。</p><p>“我很难过，不能跟神童说‘真的不行的话，不要勉强参加’。”</p><p>北关东大的选手，在所有出赛者中拥有数一数二的纪录。阿雪早就把跟城太跑同一区间的选手数据给他看过，所以他知道，意气用事跟那个选手拼高下，只是白费力气而已。不过，东京学院大那个家伙，在追过我的时候已经气喘吁吁了。我迟早会追上去，再把它赢回来。</p><p>最后这段路是直线赛道，所以在一公里前就能看到平冢中继站。然而，一旦有了目标物，反而会让人心生一种再怎么跑都到不了的错觉。不可以心急。总之，一定要坚持下去，甩开这几个选手，尽可能争取好成绩，再把接力带交给城次。</p><p>阿走的生存之道，跟他跑步的样子很像：强而有力、直视前方，永远对眼中看到的一切抱着希望与期待。</p><p>但是，这不是我要的。我，我们想去的地方，不是箱根。我们的目的地，一定得靠着跑步才能到达，那是个更远、更深，更美丽的地方。虽然我现在没办法马上去到那里，但总有一天，我一定要亲眼目睹那里的风景。在那之前，我会一直跑下去。看着吧，熬过这痛苦的一公里，我会离那个世界更近一点。</p><p>“真的很痛苦的话，中途弃权也没关系。”<br>神童惊讶地转头，两眼直盯着阿雪。这句话，或许会对神经紧绷、战战兢兢的神童，在身心上都造成不良影响，但就算这样，阿雪还是没办法不说。<br>神童那对因发烧而有点浑浊的双眼，这一瞬间竟闪过一抹清澈的光芒。阿雪与神童四目相望，再次开口说：“就算你这么做，也不会有人会怪你的。所以，真的撑不下去时，拜托你一定要立刻弃权。”</p><p>好强，阿走突然想起。清濑曾经说过的“强”，或许就是这个意思。不论个人赛或驿传，跑步需要具备的强韧，在本质上是永远不会改变的。</p><p>那是再怎么痛苦也要向前进的一种力量，以及持续与自己战斗的勇气，也是不只着眼于眼睛看得到的纪录、更要一次又一次超越自我极限的毅力。</p><p>阿走不得不承认，神童真的很强。今天如果让阿走来跑五区，或许宽政会取得更好的名次，但这不代表阿走赢过神童。<br>神童非常强，而且还向阿走亲自示范了跑步应该是什么样子。<br>我，我们这群人，到底为了什么而跑？<br>阿走目不转睛看着巨幅屏幕。<br>明明这么痛苦，这么难过，为什么就是不能放弃跑步？因为全身细胞都在蠢蠢欲动，想要感受强风迎面吹拂的滋味。</p><p>竹青庄的每个人，都是有实力的人才。我想证明这一点。弱小的社团也好，外行人也好，只要有实力和热情，一样也能跑。不用对任何人唯命是从，只要凭着两只脚，就能跑到任何想去的地方。我想在箱根驿传里证明这件事。这是我长久以来的心愿。”</p><p>那天晚上，当你在街上狂奔、经过我身边的时候，”清濑平静地说，“我心想，终于让我找到了。当时我很想大喊，‘我的梦想，现在正奔驰在我眼前！’我骑着脚踏车追你，很快就发现你是仙台城西高的藏原走。明知道你是谁，却还是把无处可去的你拖下水。”</p><h3 id="第十章-流星"><a href="#第十章-流星" class="headerlink" title="第十章 流星"></a>第十章 流星</h3><p>感情的事，不是比赛，没有输赢。叶菜子的心，只属于叶菜子。城次的心只属于城次。而阿走的心，同样的，也只属于阿走，任谁也无法夺走，无法改变。这是一个不受任何框架束缚的领域。</p><p>阿走，你可别跑得太远。虽然我知道你追求的世界有多美，但那里未免太寂寞太寂寥了，不是我们活生生之人归属的境地。</p><p>“灰二啊，”尼古搔了搔头，“真的要轻松的话，不跑最轻松，我也不用减肥、戒烟了。不管用什么速度，只要决定要跑就不可能轻松。打从一开始，我就只是为了身体健康才跑的，所以呢，不管最后我跑几名，你可都不准抱怨。”</p><p>虽然清濑也会采取强势的手段来对付他们，但他从来不曾苛责那些没有跑步经验的人，也绝不会伤害他们的情感，或看不起别人引以为傲的事物。他总是配合每个人的性格，不厌其烦地引导着大家，让他们愿意主动面对跑步。</p><p>尼古的不幸是，没有任何指导者曾经告诉他，就算他不能当田径选手，也还是可以继续跑步；没有人告诉他，如果真的喜欢跑步，尽情享受跑步的美好就好。</p><p>过程中他终于明白了一个道理：没有意义也不是什么坏事。这不是在说什么漂亮话。跑步的目的，当然是要取得胜利，但胜利其实有许多种形式。所谓的胜利，不单是指在所有参赛者中跑出最好的成绩。就像人活在这世上，怎样才算“人生胜利组”，也没有明确的定义。</p><p>不管有没有意义，为了证明我们到今天为止所做的一切是值得自豪的，现在唯一能做的就是尽全力去跑。</p><p>是了，长跑就是这么寂寞，尼古心想。像在没有星星的夜空下，踏上旅途一般的孤独与自由。跳动到极限的心脏，涔涔的汗水冷却后又马上让肌肤发热、血液流窜奔腾的肌肉，这一切的感受除了尼古自己，都没有任何人知道。到跑完既定的道路、抵达既定的地点为止，都不会跟任何人有接触，尼古必须独自面对这场旁人无法理解的战斗。</p><p>从放弃田径那一刻起，我就一直在等待。等待有人再给我一次机会。等待有人就算知道我的身体不适合田径赛，但能看到我打从灵魂深处热爱跑步、追求跑步、渴望跑步。等待着有人能对我说：尽管去跑吧！</p><p>KING怎么也学不会跟人保持一种若即若离、自然而然的绝佳距离。不管身在何处，不论和谁相处，他都觉得自己像漂浮在半空中。虽然他可以八面玲珑、避免与人争执，却没办法向任何人敞开心胸，只会为了掩饰软弱而虚张声势。面对这样的KING，当然没有人会想踏入他的内心世界。再加上KING自己认为，觉得寂寞是很丢脸的事，结果他的表面功夫也越做越好。</p><p>灰二哥，你说我“是打从灵魂深处在探索跑步这件事”。这句话，说的应该是你吧。是灰二哥你自己的写照。</p><p>“这一年来，我看着你跑步的样子，跟你一起生活到现在，”清濑的声音有如一潭深邃的湖泊，静静地浸润阿走的内心，“我对你的感觉，已经不是‘有没有信心’这句话可以表达的了。相不相信不重要，重要的只有你。阿走，我心目中最棒的跑者，只有你而已。”</p><p>喜悦之情盈满阿走的心。这个人，给了我世间无可取代的东西。就在现在，给我一个永恒闪耀、最珍贵的宝物。</p><p>阿走的状况十分良好，内心却像无风的水面，宛如一面可以映照未来的魔法之水，清澄透澈、静谧无声，没有一丝涟漪。</p><p>完全没有多余的动作，完美的姿势展现出无比的强度与速度，仿佛在向世人宣告：“这才是跑步！”</p><p>“只要努力就一定能成功，其实是一种傲慢。”</p><p>“田径的世界没有那么天真，但是，目标也不是只有一个。”<br>就物理观点来看，大家都跑在同一条赛道上。然而，每个人到达的境界却各有不同，借由跑步找到属于自己的终点。跑者们总是不断在思考、迷惘、犯错，然后再重新来过。<br>如果每个跑者的答案与终点都相同，长跑就不会这么令人着迷了。如果跑步只是这么表面化的行为，看到像阿走这么梦幻的跑法后，恐怕不会还有人想继续跑下去。</p><p>跑步是力量，而不是速度；是虽然孤独，却也跟他人有所连结的一种韧性。</p><p>灰二哥，你说“信心”这个字眼不足以表达你心里的感受。我也这么想。因为任何说出口的话都有可能变成谎言，而百分之百的信任只会自然涌现在心里。这是我头一次明白，信任自己以外的某个人，是多么崇高的一件事。</p><p>既然是祭典，所以，大家开心就好了，阿走豁达地想。我不奢求有人理解自己到底是用什么样的心情在跑步，在这项运动中投注了多少体力与精神。这种痛苦和兴奋，只有跑者自己明白，但跑者可以和现场所有人分享参与比赛的喜悦。不论跑者或观众，都能够一起感受、一起玩味这一路连绵不绝直到大手町的热情欢呼声。<br>虽然只有一个人，却又不是一个人。跑者和观众将道路化成一条流动的河川。</p><p>“清濑，我们到底要跑到哪里才能停下？以为已经抵达目的地，结果前方还有路，而且又长又远。我所追求的跑步……”<br>清濑在藤冈的眼中，看到暗淡的绝望之光。一个人孤独地跑着，永无止境追求着。阿走身上也有跟他一样的阴影。<br>藤冈，你并不孤单。托你的福，让阿走变强了。今后你们俩一定会以彼此的存在相互激励，朝更高的境界迈进，直到有一天，克服万难，到达那个任何人都到不了的地方。<br>清濑其实想这么说，却紧闭着双唇不语，因为他心里其实非常羡慕。羡慕阿走，羡慕藤冈。因为他们是被“选中”的人。于是，清濑只是这么说：“但你还是不会放弃吧？”<br>他只说这么多。<br>“你就是没办法放弃跑步，不是吗？”<br>“说得对，”藤冈这次真的敞开心房，嘴角扬起笑意，“反正就是再重新来过而已。”</p><p>藤冈那些队友中没有任何人发现，即使他跑出决定胜负的成绩，同时创下区间新纪录，但藤冈心里仍然存在着一片无可填补的空虚。<br>这不是因为他输了，而是因为他不满足。而且正是这个原因，驱使他继续跑下去，变得更加强大。<br>“原来，被选中的人也有很多烦恼啊，”清濑喃喃自语着，往王子走去，“阿走应该已经收到情报了吧？”</p><p>从第一次相遇的那天晚上起，我就知道了。我一直等待的、一心一意追求的，就是你，阿走。<br>阿走让清濑亲眼目睹了自己心目中的跑步。那是他长久以来不断渴求，却因为遍体鳞伤而不得已打算舍弃的梦想，阿走却轻而易举地将它展现在他眼前。在这个世界上，我从没见过比阿走更美丽的生物。<br>宛如划破夜空的流星。你奔跑的姿态，就像那一道冷冽的银色流光。<br>如此璀璨夺目。我可以看到，你奔行的轨迹散发出白色的光辉。</p><p>在那个当下，心理和生理处于一种兴奋状态，仿佛跑到天涯海角都不成问题。但他现在的感觉，跟“跑者高潮”有点不太一样，而是一种更澄澈、更冷静的恍惚感。</p><p>清濑的样子有如自始至终都站在那里一样，定定凝视着阿走。他的神情喜悦中又带点哀愁，对阿走绽开笑颜。</p><p>没有必要呼喊对方的名字。只在接触的一瞬间，眼神交会，一切尽在不言中。<br>灰二哥，我们终于来到这么远的地方。言语或肢体碰触，在这最后一刻都不需要了。前往这遥远的国度，我们一起做到了。</p><p>清濑面对的敌人，不是其他大学的选手，而是时间，以及自己脚上的旧伤。</p><p>“ZONE”的意思是指在精神高度集中下，身心产生变化的一种特殊状态。据说，经过严酷训练的运动员在比赛中发挥体能极限时，有少数人可以达到“ZONE”的境界。</p><p>清濑思考了很久。关于长跑比赛，关于跑步这件事的意义，他都彻底思考过，最后选择了宽政大。六道大的每个选手，毫无疑问都拥有继续成长的实力。那样的地方，他觉得不适合自己。但他想继续跑下去的愿念，又像火焰一般炙热、无法平息，因此他觉得自己必须找一个地方，而那里的人与跑步完全无关，然后再次省视自己、问自己。</p><p>我，到底为什么而跑？</p><p>不管跑不跑步，每个人都有自己的痛苦，同理，也有各自的喜悦。不论任何人，都有他必须面对的烦恼；即使明知愿望无法达成，也挣扎着向前进。</p><p>跟田径保持一段距离后，清濑反而认清一个道理：既然不论去任何地方都一样，不如坚定立场，遵循内心的渴望坚持到最后。</p><p>“你啊，被他骗了那么多次，怎么就是学不乖。”<br>无所谓，阿走心想，两眼直盯着不久后可以看到清濑身影出现的转角。被骗多少次都无所谓。只要灰二哥说他要跑，我就会等他。我会一直静静等下去，等着亲眼看到灰二哥使尽全力跑来的那一刻。</p><p>清濑感觉到真中大选手的视线停留在自己左脸颊上，借此刺探他的动向。但他完全没有转头看对手，只是看着前方往前跑。</p><p>清濑在前方看到自己追求的目标。竹青庄的伙伴们站在写着“东京往返箱根大学驿传大赛”的横幅布条下。他们正在对清濑大声呐喊着。</p><p>我一定会跑到那里的。拂过身边的强风告诉我，我还在跑。我正在用自己的身躯，体现我心目中的跑步。好痛快。这辈子从来不曾比现在还要幸福。</p><p>阿走的视线再度回到清濑身上，几乎已经准备冲到赛道上。但当他与清濑四目相对时，看到清濑汗水淋漓的脸上慢慢绽出微笑。那是当一个人豁出所有、也得到所求的一切时，才会露出的神情。</p><p>阿走收回踏上前的脚步。我没办法阻止他，也不能叫他不要再跑了。渴望跑步、决心为跑步献出一切的灵魂，谁也没有资格阻止。</p><p>阿走看到了。突然仰头望向天空的清濑，仿佛找到什么珍贵又美丽的东西，脸上浮现豁然清明的神情。<br>灰二哥，你曾经对我说，你想知道跑步的真谛究竟是什么。我们之间的一切，就从这里开始。现在，让我告诉你，我的回答。<br>我不知道。虽然我还是不知道答案，但我知道在跑步里有幸福也有不幸。我知道在跑步这件事中，存在着我和你的一切。</p><p>阿走有一种近乎确信的预感。我，大概到死为止都会一直跑下去吧。<br>就算有一天，我的身体再也跑不动，我的灵魂在我咽下最后一口气之前，也不会放弃跑步。因为跑步带给阿走一切。这地球上存在的最珍贵事物——喜悦、痛苦、快乐，或是嫉妒、尊敬、愤怒，还有希望——透过跑步，阿走学到这一切。</p><h3 id="尾声"><a href="#尾声" class="headerlink" title="尾声"></a>尾声</h3><p>“对我来说，是灰二哥他教会我关于跑步的一切，”阿走说，“除了一件事以外。”<br>“那是什么事？”<br>跑步的真谛到底是什么？<br>只有这件事，灰二哥他没有教我。或许，这是不能靠别人来教的事。<br>因为想知道答案，阿走才会跑步，持续不停地跑。他也曾经以为自己已经到达顶点，但那感觉总是瞬间即逝，而且这些成绩也不代表跑步的意义。<br>“你很快就自己发现那是什么了，”阿走平静地对身旁的一年级新生说，“只要你继续跑步，总有一天也会开始追寻它。”</p>]]></content>
    
    
    <categories>
      
      <category>读书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>跑步</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Less is More:De-amplifying I/Os for Key-value Stores with a Log-assisted LSM-tree</title>
    <link href="/2022/03/26/%E8%AF%BB%E8%AE%BA%E6%96%87/L2SM/"/>
    <url>/2022/03/26/%E8%AF%BB%E8%AE%BA%E6%96%87/L2SM/</url>
    
    <content type="html"><![CDATA[<h1 id="Less-is-More-De-amplifying-I-Os-for-Key-value-Stores-with-a-Log-assisted-LSM-tree"><a href="#Less-is-More-De-amplifying-I-Os-for-Key-value-Stores-with-a-Log-assisted-LSM-tree" class="headerlink" title="Less is More: De-amplifying I/Os for Key-value Stores with a Log-assisted LSM-tree"></a>Less is More: De-amplifying I/Os for Key-value Stores with a Log-assisted LSM-tree</h1><h2 id="0x00-Motivation"><a href="#0x00-Motivation" class="headerlink" title="0x00 Motivation"></a>0x00 Motivation</h2><p>LSM-Tree的结构决定了其必须要管理大量的小键值对。在实际的工作负载中，大量随机且频繁的KV更新请求会快速破坏LSM的结构。因此，LSM-KV Store必须不断通过Compaction操作来维持KV对的有序性并降低同一Level中不同SSTable之间Key的重叠率。此外，在LSM-Tree中，越深层的Level，Compaction会触发的越频繁。这会给系统带来巨大的计算和IO开销。</p><p>图1展示了LSM-tree的维护成本。上层SSTable的key相较下层较为稀疏，在Compaction操作时会带来很严重的写放大（图中上层的1个SSTable要与下层的4个SSTable执行归并排序，这就意味着下层的4个SSTable都要被重写）。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/L2SM-F1-2.png" alt="image-20220325194722218"></p><p>图2展示了随着时间的变化，不同Level的磁盘I/O数量。L0中的SSTable是无序的，因此其维护成本变化不大，其他Level的磁盘I/O都随着请求的增加而增加。此外，可以看到越深层的Level，其磁盘I/O次数增长越快。</p><h2 id="0x10-L2SM-Design"><a href="#0x10-L2SM-Design" class="headerlink" title="0x10 L2SM Design"></a>0x10 L2SM Design</h2><h3 id="0x11-Architecture-Overview"><a href="#0x11-Architecture-Overview" class="headerlink" title="0x11 Architecture Overview"></a>0x11 Architecture Overview</h3><p>L2SM的关键设计目标是在维持LSM-Tree结构的基础上，尽量减少I/O放大。</p><p>如图3所示，L2SM将数据保存在内存和磁盘中：</p><ul><li>In-Memory structures：与经典LSM-tree结构相似，L2SM维护了两个内存数据结构MemTable和ImmuTable来吸收和组织大量无序且随机的KV对，随后顺序写到磁盘上。</li><li>On-disk structures：磁盘上的数据被划分为两部分，分别存储到LSM-tree和SST-log，SST-log用于吸收那些会破坏LSM-tree结构的操作。SST-log也是个多层结构，除了L0以外，LSM-tree和SST-log层层对应，SST-log也由多个SSTable组成。其目的是用此日志结构来吸收大量对LSM-tree结构造成破坏的操作，以更稳定的状态和更低的更新开销来保护LSM-tree结构。</li></ul><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/L2SM-F3.png"></p><p>L2SM的数据流：</p><ol><li>KV对先写到MemTable中，随后转为ImmuTable，接着Minor Compaction操作会将ImmuTable持久化为L0中的SSTable；</li><li>当某一层的SSTable数量达到阈值时，选择出那些对LSM-tree潜在造成较大破坏的SSTable（例如包含hot-key range的SSTable），然后通过Presudo Compaction（PC）操作将其移动到同一Level的SST-log中，由Log Metadata Manager管理。需要注意的是，PC操作只是通过更新元数据来进行<strong>逻辑移动</strong>，并不会带来任何物理I/O开销。</li><li>如果SST-log的Level大小超过阈值，则Aggregate Compaction（AC）操作会从该Level中选择SSTable来与LSM-tree下一Level的有重叠范围SSTable进行合并。</li></ol><p>因此，在L2SM中，一个KV项首先会水平从LSM-tree中移到SST-log，然后垂直移动到LSM-Tree的下一Level中。</p><h3 id="0x12-LSM-Tree-and-SST-log"><a href="#0x12-LSM-Tree-and-SST-log" class="headerlink" title="0x12 LSM-Tree and SST-log"></a>0x12 LSM-Tree and SST-log</h3><h4 id="LSM-Tree"><a href="#LSM-Tree" class="headerlink" title="LSM-Tree"></a>LSM-Tree</h4><p>在L2SM中，Compaction操作被划分为：PC操作和AC操作。PC操作将SSTable从LSM-Tree移到同一层的SST-Log中，AC操作将SSTable与LSM-Tree中下一Level的重叠SSTable进行合并。</p><p>PC和AC操作根据SSTable的属性（hotness和density，热度和密度）来选择SSTable进行移动和合并。</p><p>此外，经典LSM-Tree KV-Store一次仅选择一个SSTable来与下一Level的重叠SSTable进行合并。而L2SM一次AC操作会从SST-Log中选择多个SSTable来进行更加密集的合并，以实现更好的I/O性能。</p><h4 id="SST-Log"><a href="#SST-Log" class="headerlink" title="SST-Log"></a>SST-Log</h4><p>SST-Log主要由以下四个作用：</p><ul><li>从LSM-Tree中剥离出那些反复破坏LSM-Tree结构的「hot」数据（频繁更新的数据），并将其存到SST-Log提供的独立空间中；</li><li>提供一个缓冲区来识别和压缩那些键值范围稀疏的SSTable，然后将它们合并到LSM-Tree中；</li><li>延迟并减轻对LSM-Tree的破坏性操作，例如将多次Compaction操作累积为一个；</li><li>允许尽早从LSM-Tree中删除过时和lazy delte的数据；</li></ul><p>不同于LSM-Tree，SST-Log不要求每一Level中的KV保持有序，因此同一Level的不同SSTable的键值范围会有重叠。所以在SST-Log中进行查找时必须查找所有的SSTable，这会带来一定的开销。但在L2SM中允许这种重叠是必须的，因为SST-Log的设计目的便是为了吸收和累积更新，以使这些更新在AC操作中可以合并为一个，这可以尽量减少对LSM-Tree的影响。</p><p>在LSM-Tree中，越深层的Level，其SSTable的访问频率越低，SSTable的密度也更高。因此，对于深层的Level来来说，不需要为其分配太大的SST-Log Level。L2SM通过一个称为「Inverse Proportional Log Size」的方案来决定SST-Log中每一个Level 的大小。具体看原文，这里不多做叙述。</p><h3 id="0x13-Hotness-and-Density"><a href="#0x13-Hotness-and-Density" class="headerlink" title="0x13 Hotness and Density"></a>0x13 Hotness and Density</h3><p>为了减轻对LSM-Tree结构的破坏性干扰，L2SM需要识别出频繁更新和稀疏的SSTable，并将它们隔离在SST-Log中。</p><p>L2SM使用两个指标，hotness和density，来定量分析SSTable的属性。「hotness」用于衡量SSTable中KV对的更新频率，「density」用于衡量SSTable的key覆盖和影响的范围。这两个指标共同描述了若将相关KV项保存在LSM-Tree中可能会对LSM-Tree的结构造成潜在破坏的严重程度。</p><h4 id="Hotness-of-SSTables"><a href="#Hotness-of-SSTables" class="headerlink" title="Hotness of SSTables"></a>Hotness of SSTables</h4><p>L2SM通过维护一个「Hotness Detecting Bitmap（HotMap）」来定量分析一个SSTable的「hotness」。HotMap是一个存在于内存中全局多层布隆过滤器（Bloom Filter， BF）。</p><p>如图4所示，一个M层的HotMap有M个对齐的BF组成。当一个KV项在第$i$次更行时，将第$i$层的BF相应bit位重置为1。因此，一个M层的HotMap最多可以记录给定KV项的M次更新。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/L2SM-F4.png" alt="image-20220325213716525"></p><p>一个SSTable的「hotness」计算方式为$\sum_{i=1}^{m-1}(x_i \times 2^i)$，其中$x^i$表示HotMap指示SSTable中访问次数为$i$的KV项的数量。</p><p>HotMap能不能发挥作用主要看参数M和P，下面介绍L2SM是如何配置这两个参数的。</p><p><strong>Configuring M</strong></p><p>M是HotMap的层数，决定了其能记录的KV项的更新次数。显然M越大，HotMap能记录的更新次数越多，HotMap也就越精确，但这也会带来较大的内存开销。L2SM使用一个简单的方法来设置M。</p><p>对$n$个key进行$r$次请求的工作负载，每个key的平均访问次数为$\tau = r/n$，L2SM使用$M = \left \lceil r/n \right \rceil$来设置HotMap的层数。其合理性也很容易解释，当一个KV项的更新次数超过平均更新次数时，该KV项便可以被认为是hot-key。</p><p><strong>Configuring P</strong></p><p>P是每个BF所表示的bit数组的大小，决定了BF的FPR（False Positive Rate）。当P过小时，BF的FPR会过高，能发挥的作用有限。</p><p>另$\rho$表示在工作负载的所有唯一key中hot-key所占的比例。用N表示所有唯一Key的数量，K表示BF中使用的哈希函数数量，<a href="https://www.eecs.harvard.edu/~michaelm/postscripts/im2005b.pdf">根据已有的研究</a>，bit数组的大小应该被设置为$P = \frac{K \times N}{ln2}$。</p><p><strong>Auto-turning HotMap</strong></p><p>随着时间的推移，HotMap会被逐渐填满，最终失去区分hot-key和cold key的作用。因此，必须确保HotMap能自适应工作负载，在运行时能始终发挥作用。</p><p>为了保持一个较低FPR，需要周期性的对HotMap进行更新和扩容。L2SM提出了一个称为Online Adaptive Auto-tuning的方案来自动调整HotMap。</p><p>有几种情况会触发该调整方案来调整HotMap。</p><p>如图5所示，如果顶层的BF接近其容量限制，这表明HotMap过小而无法以较低的FPR来服务于其设计目的，此时将停用该层。当停用该层时，会进一步检查下一层。如果下一层的空间消耗超过20%，则将顶层的BF大小扩大10%，将其所有位重置为0，然后将其旋转到底层，如图5(a)所示；否则，若下一层的使用情况小于20%，为了节省空间，直接将顶层BF的大小设置为当前底层BF的大小，将其所有位重置为0，然后旋转到底层，如图5(b)所示。其原理是，若第二层消耗很小，则很可能大多数键都是冷的，并且工作集没有增长，当前的HotMap大小是足够的。</p><p>假设顶层的BF足够大，可以容纳所有的唯一写入，如果任何两个相邻层接受的唯一键太接近（例如，两层之间接受的插入差异小于10%，并且每层占用超过层大小20%），也即两层过于相似，这发生在重复更新一组键时。此时，可以通过重置顶层BF并将其旋转到底层来将其退休，如图5(c)所示。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/L2SM-F5.png" alt="image-20220326100338719"></p><p><strong>Overhead</strong></p><p>内存开销可以用$M \times P$来表示。M是BF的数量，P是BF的大小。</p><h4 id="Density-of-SSTables"><a href="#Density-of-SSTables" class="headerlink" title="Density of SSTables"></a>Density of SSTables</h4><p>在L2SM中，大多数情况下SSTable的大小一致，并且其KV项是有序的。L2SM使用SSTable中KV项的数量和key range的比值来表示其密度。</p><p>SSTable的key range是SSTable中第一个key和最后一个key之间的差。但由于实际工作负载中，key的表示形式不同，可能为字符串或数字。因此不能直接通过数字减法来计算。</p><p>L2SM通过将key转换为128位的二进制值来简化此计算过程。然后通过逐位比较两个128位二进制值（比较第一个key和最后一个key），以找到两个key中不同的最高位。假设不同的最高位是第$i$位，则SSTable的key range可以粗算为$2^i$。如果此SSTable包含$k$个KV项，则其密度可以计算为$k/2^i$。为了进一步简化计算，L2SM使用对数来表示SSTable的密度值，即$lg(k/2^i) = lgk - i$。此外，还可以用$S = i - lgk$来表示SSTable的sparseness，这是与density相反的表示方式。</p><h3 id="0x14-Pseudo-Compaction"><a href="#0x14-Pseudo-Compaction" class="headerlink" title="0x14 Pseudo Compaction"></a>0x14 Pseudo Compaction</h3><p>在L2SM中，当LSM-Tree中的某个Level被写满时，根据SSTable的hotness 和density ，PC能够快速选择出那些对LSM-Tree结构造成潜在破坏的SSTable，将其隔离在SST-Log中，以降低I/O放大。</p><p>为了确定移入SST-Log的最佳SSTable，L2SM使用一个Combined Weight来联合考虑hotness和density，以确定SSTable的选择。</p><p>对于给定的SSTable $i$，假设其hotness为$H_i$，sparseness 为$S_i$，则权重方程为$W_i = \alpha \times H_i + (1 - \alpha) \times S_i$，其中$\alpha$</p><p>是预设的权重参数，默认为0.5 。</p><p>要计算SSTable的组合权重，首先需要将S和H都归一化到0～1之间。归一化后其组合权重可以表示为：<br>$$<br>W_i = \alpha  \times \frac{H_i}{H_{max} - H_{min}} + (1 - \alpha) \times  \frac{S_i}{S_{max} - S_{min}}<br>$$</p><h3 id="0x15-Aggregated-Compaction"><a href="#0x15-Aggregated-Compaction" class="headerlink" title="0x15 Aggregated Compaction"></a>0x15 Aggregated Compaction</h3><p>AC操作负责回收SST-Log的空间，它尝试在SST-Log中保留那些对LSM-Tree结构影响最大的SSTable，并将</p><p>冷而密集的SSTable合并到LSM-Tree的下一Level中。</p><p>当SST-Log超过其大小限制时，会触发AC操作将冷而密集的SSTable合并到LSM-Tree，同时将热而稀疏的SSTable保存在SST-Log。此时需要对SST-Log中的所有SSTable进行组合权重计算，以选择SSTable。</p><p>整个Compaction过程如下所示：</p><ol><li>根据组合权重W找到最冷最密集的「种子」SSTable，并使用该SSTable在SST-Log中递归找到所有与它的key range重叠的SSTable，根据版本顺序对所有的SSTable进行排序；</li><li>基于步骤1选择出的SSTable，从最旧的SSTable开始，放入victim Compaction Set（CS），在LSM-Tree的下一Level中找到与CS中的SSTable有重叠Key range的SSTable，将其放入victim Involved Set（IS）；</li><li>重复步骤2，直到步骤1中找到的所有SSTable都放在CS中，或者IS和CS中SSTable的比值大于预设值（默认为10，用于控制AC所引起的I/O放大）；</li><li>最后开始正式的归并排序。首先从CS中最旧的SSTable开始，删除其中所有已标记删除和过时的KV项。然后将其与IS中的相关SSTable进行合并，最后将生成的新的SSTable插入到LSM-Tree的下一Level中，这样便完成了AC过程。</li></ol><p>图6是该AC过程的一个示例。块中的数字表示其时间顺序，也即版本（越小表示越旧）。SST-Log中有6个SSTable，SSTable 8为最冷最密集的SSTable，有三个SSTable与其有重叠（SSTable 6、14和29）。CS中包括SSTable 6、8和14，虽然SSTable 29也与SSTable 8有重叠，但因为超过了I/O限制，其不参与此次AC过程。所以，最后是SSTable 6、8和14与IS中的SSTable进行合并重写。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/L2SM-F6.png" alt="image-20220326112729159"></p>]]></content>
    
    
    <categories>
      
      <category>Key-Value Store</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Key-Value Store</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读《书剑恩仇录》</title>
    <link href="/2022/03/19/%E8%AF%BB%E4%B9%A6/%E4%B9%A6%E5%89%91%E6%81%A9%E4%BB%87%E5%BD%95/"/>
    <url>/2022/03/19/%E8%AF%BB%E4%B9%A6/%E4%B9%A6%E5%89%91%E6%81%A9%E4%BB%87%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前几天突然想起「慧极必伤，情深不寿」这句话，记不清出处，又查了一下，原文应该是「情深不寿，强极则辱，谦谦君子，温润如玉」。此句出自金庸的第一部武侠小说《书剑恩仇录》。</p><p>就真的因为这句话去读了这本小说。我是用微信读书看的，经常能看到网友的批注，其中不乏对文中各个角色的点评，甚至是批评。私以为，大可不必。人入江湖，身不由己，纵你神功盖世，也无可奈何，每个人都有其局限性。当局者迷，旁观者清。</p><h2 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h2><p>第5章 置酒弄丸招薄怒 还书贻剑种深情</p><p>霍青桐奔了一段路，忽然勒马回身，见陈家洛正自呆呆相望，一咬嘴唇，举手向他招了两下。陈家洛见她招手，不由得一阵迷乱，走了过去。霍青桐跳下马来。两人面对面的呆了半晌，说不出话来。 </p><p>霍青桐见他神情落寞，心中很不好受，微一踌躇，说道：“你不要我跟你去救文四爷，为了什么，我心中明白。你昨日见了那少年对待我的模样，便瞧我不起。这人是陆菲青陆老前辈的徒弟，是怎么样的人，你可以去问陆老前辈，瞧我是不是不知自重的女子！”说罢纵身上马，绝尘而去。 </p><p>第6章 乌鞘岭口拚鬼侠 赤套渡头扼官军</p><p>陈家洛手托短剑，呆呆的出神，望着霍青桐追上回人大队，渐渐隐没在远方大漠与蓝天相接之处，心头一震，正要去问陆菲青，一个念头猛地涌上心来：“汉回不通婚，他们回人自来教规极严，霍青桐姑娘对我虽好，但除非我皈依回教，做他们的族人，否则多惹情丝，终究没有结果，徒然自误误人，各寻烦恼而已。”“我对回教的真神并不真心信奉，如为了霍青桐姑娘而假意信奉，未免不诚，非正人君子之所为。岂不遭人轻视耻笑？”正出神间，忽见前面一骑如一溜烟般奔来，越到身前越快，却是心砚回来了。 </p><p>第7章 有情有义怜难侣 无法无天振饥民</p><p>回首西望，天上众星明亮，遥想平沙大漠之上，这星光是否正照到了那青青翠羽，淡淡黄衫？ </p><p>第8章 琴音朗朗闻雁落 剑气沉沉作龙吟</p><p>​    陈家洛也带了心砚到湖上散心，在苏堤白堤漫步一会，独坐第一桥畔，望湖山深处，但见竹木森森，苍翠重叠，不雨而润，不烟而晕，山峰秀丽，挺拔云表，心想：“袁中郎初见西湖，比作是曹植初会洛神，说道：‘山色如娥，花光如颊，温风如酒，波纹如绫，才一举头，已不觉目酣神醉。’不错，果然是令人目酣神醉！”<br>​    他幼时曾来西湖数次，其时未解景色之美，今日重至，才领略到这山容水意，花态柳情。</p><p>​    “锦绣乾坤佳丽，御世立纲陈纪。四朝辑瑞徵师济，盼皇畿，云开雉扇移。黎民引领鸾舆至，安堵村村扬酒旗。恬熙，御炉中靉靆瑞云霏。” </p><p>陈家洛道：“先严已不幸谢世。小弟碌碌庸才，功名利禄，与我无缘。”</p><p>陈家洛道：“与其残民以逞，不如曳尾于泥涂耳。”</p><p>东方耳又道：“纳兰公子绝世才华，自是人中英彦，但你瞧他词中这一句：‘且由他蛾眉谣诼，古今同忌。身世悠悠何足问，冷笑置之而已。’未免自恃才调，过于冷傲。少年不寿，词中已见端倪。”说罢双目盯住陈家洛，意思是说少年人恃才傲物，未必有什么好下场。陈家洛笑道：“大笑拂衣归矣，如斯者古今能几？向名花美酒拚沉醉。天下事，公等在。”这又是纳兰之词。东方耳见他一派狂生气概，不住摇头，但又不舍得就此作别，想再试一试他的胸襟气度，随手翻过扇子，见反面并无书画，说道：“此扇小弟极为喜爱，斗胆求兄见赐，不知可否？”陈家洛道：“兄台既然见爱，将去不妨。”东方耳指着空白的一面道：“此面还求兄台挥毫一书，以为他日之思。兄台寓所何在？小弟明日差人来取如何？”陈家洛道：“既蒙不嫌鄙陋，小弟即刻就写便是。”命心砚打开包裹，取出笔砚，略加思索，在扇面上题诗一绝，诗云：<br>    “携书弹剑走黄沙，瀚海天山处处家，大漠西风飞翠羽，江南八月看桂花。” </p><p>第9章 千军岳峙围千顷 万马潮汹动万乘</p><p>侍卫牵过御马，乾隆对陈家洛道：“你骑我这匹马。”侍卫忙又牵过一匹马来。两人上马，向春熙门而去。<br>这时郁雷之声渐响，轰轰不绝。待出春熙门，耳中尽是浪涛之声，眼望大海，却是平静一片，海水在塘下七八丈，月光淡淡，平铺海上，映出点点银光。<br>乾隆望着海水出了神，隔了一会，说道：“你我十分投缘。我明天回杭州，再住三天就回北京，你也跟我同去好吗？最好以后常在我身边。我见到你，就如同见到令尊一般。”<br>陈家洛万想不到他会如此温和亲切的说出这番话来，一时倒怔住了难以回答。<br>乾隆道：“你文武全才，将来做到令尊的职位，也非难事，这比混迹江湖要高上万倍了。”皇帝这话，便是允许将来升他为殿阁大学士。清代无宰相，大学士是一人之下万人之上的高位，心想他必定喜出望外，叩头谢恩。那知陈家洛道：“你一番好意，我十分感谢，但如我贪恋富贵，也不会身离阁老之家，孤身流落江湖了。”<br>乾隆道：“我正要问你，为什么好好的公子不做，却到江湖上去厮混，难道是不容于父兄么？”陈家洛道：“那倒不是，这是奉我母亲之命。我父亲、哥哥是不知道的。他们花了很多心力，到处找寻，直到这时，哥哥还在派人寻我。”乾隆道：“你母亲叫你离家，那可真奇了，却又干么？”</p><p>​    玉色晶莹，在月亮下发出淡淡柔光，陈家洛谢了接过，触手生温，原来是一块异常珍贵的暖玉。玉上以金丝嵌着四行细篆铭文：“情深不寿，强极则辱。谦谦君子，温润如玉。” </p><p>乾隆笑道：“如我不知你是胸襟豁达之人，也不会给你这块玉，更不会叫你赠给意中人。这四句铭文虽似不吉，其中实含至理。”陈家洛低吟“情深不寿，强极则辱”那两句话，体会其中含意，只觉天地悠悠，世间不如意事忽然间一齐兜上心头，悲从中来，直欲放声一哭。乾隆道：“少年爱侣，情深爱极，每遭鬼神之忌，是以才子佳人多无美满下场，反不如伧夫俗子常能白头偕老。情不可极，刚则易折，先贤这话，确是合乎万物之情。” </p><p>​    一丘黄土，埋香掩玉，陈家洛想起旧时情谊，不禁凄然，在坟前作了三个揖。 </p><p>第11章 烟腾火炽走豪侠 粉腻脂香羁至尊</p><p>待众人游船围着玉如意花舫时，只见她启朱唇、发皓齿，笛子声中，唱了起来：“望平康，凤城东，千门绿杨。一路紫丝缰，引游郎，谁家乳燕双双？隔春波，碧烟染窗；倚晴天，红杏窥墙，一带板桥长。闲指点，茶寮酒舫，声声卖花忙。穿过了条条深巷，插一枝带露柳娇黄。” </p><p>众人把那卷轴打开，见是一幅书法，写的是：“西湖清且涟漪，扁舟时荡晴晖。处处青山独住，翩翩白鹤迎归。昔年曾到孤山，苍藤古木高寒。想见先生风致，画图留与人看。”笔致什为秀拔，却无图章落款，只题着“临赵孟俯书”五字。 </p><p>古往今来，嫖院之人何止千万，却要算乾隆这次嫖得最为规模宏大，当真是好威风，好煞气，于日后“十全武功”，不遑多让焉。后人有《西江月》一首为证，词曰：<br>    铁甲层层密布，刀枪闪闪生光，忠心赤胆保君皇，护主平安上炕。<br>    湖上选歌徵色，帐中抱月眠香。刺嫖二客有谁防？屋顶金钩铁掌。 </p><p>第12章 高塔入云盟九鼎 快招如电显双鹰</p><p>关明梅把陈家洛拉在一旁道：“你娶了亲没有？”陈家洛脸一红道：“没有。”关明梅又道：“定了亲么？”陈家洛道：“也没有。”关明梅点点头，温颜微笑，忽然厉声道：“如你无情无义，将来负了赠剑之人，我老婆子决不饶你。”陈家洛不禁愕然无辞以对。 </p><p>第13章 盈盈彩烛三生约 霍霍青霜万里行</p><p>李沅芷知道说错了话，涨红了脸，过了一会，低声道：“你骂我爹爹！人各有志我也不敢勉强。只要你爱这样，我也会觉得好的。我应承听你的话，以后决不再去帮爹爹，我想我师父也会欢喜。”最后两句话说得声音响了些，多半窗外的陆菲青也听见了。余鱼同坐在桌边，只是不语。李沅芷低声道：“你说我官家小姐不好，那我就不做官家小姐。你说你红花会好，那我也……我也跟着你做……做江湖上的亡命之徒……”这几句话用了极大的气力才说出口，说到最后，又羞又急，竟哭了出来。 </p><p>陈家洛道：“前辈太客气了。令徒曾到过回部吧？”陆菲青道：“她从小在西北一带。”陈家洛道：“嗯，我见他和那位回人姑娘好似交情不错。”霍青桐和陈家洛离别之时，曾说过一句话：“那人是怎样的人，你可以去问她师父。”陈家洛几次想问陆菲青，总觉太着痕迹，始终忍着不问，此刻陆菲青自己过来谈起，这才轻描淡写、似乎漠不关心的问了几句，其实心中已在怦怦暗跳，手心潜出汗水。 </p><p>余鱼同接过打开，见纸上写着十六个细字：“情深意真，岂在丑俊？千山万水，苦随君行。”笔致娟秀，认得是李沅芷的字迹，不料她竟一路跟随而来，他眉头一皱，把字条交给陈家洛。</p><p>第14章 吐气扬眉雷掌疾 惊才绝艳雪莲馨</p><p>“多才惹得多愁，多情便有多忧，不重不轻证候，甘心消受，谁教你会风流？” </p><p>出得房来，想下岗去找李沅芷，经过殿堂时见到壁画，驻足略观，见画的是八位高僧出家的经过，一幅画中题词说道，这位高僧在酒楼上听到一句曲词，因而大彻大悟。余鱼同不即往下看去，闭目凝思，那是一句什么曲词，能有偌大力量？睁开眼来，见题词中写着七字：“你既无心我便休”。这七个字犹如当头棒喝，耳中嗡嗡作响，登时便呆住了。 </p><p>第15章 密意柔情锦带舞 长枪大戟铁弓鸣</p><p>霍青桐向妹妹偷望一眼，见她容光焕发，凝望着陈家洛，眼光中流露着千般仰慕，万种柔情，竟无丝毫担心害怕，不由得暗暗叹了口气，转头望陈家洛时，见他神定气闲，泰然自若。两人目光相接，陈家洛微微点头，温然微笑。霍青桐脸上一阵晕红，转开了头。 </p><p>木卓伦道：“青儿，你妹子真勇敢。”霍青桐点点头，掩面奔进营帐。一时之间，似乎有个大铁椎在不住敲打自己胸口，腹酸心痛，恨不得立时死了才好。 </p><p>第16章 奇谋破敌将军苦 儿戏降魔玉女嗔</p><p>。<br>    她发令已毕，独自骑马向西，下马跪下，泪流满面，低声祷祝：“万能的真主，愿你圣道得胜，打败入侵的敌人。现今我爹爹不相信我，哥哥不相信我，连我部下也不相信我，为了要使他们听令，我只得杀人。安拉，求你佑护，让我们得胜，让爹爹和妹妹平安归来。如果他们要死，求你千万放过，让我来代替他们。求你让陈公子和妹妹永远相爱，永远幸福。你把妹妹造得这样美丽，一定对她特别眷爱，望你对她眷爱到底。” </p><p>香香公主微笑着对陈家洛道：“你对这位大哥说，我们很是高兴，请他和我们同去找姊姊。”陈家洛这才和李沅芷行礼厮见，说道：“李大哥怎么也来啦？别来可好？”李沅芷红了脸，只是格格的笑，望着余鱼同，下巴微扬，示意要他说明。余鱼同道：“总舵主，她是我陆师叔的徒弟。”陈家洛道：“我知道，我们见过几次。”余鱼同笑道：“她是我师妹。”陈家洛惊问：“怎么？”余鱼同道：“她出来爱穿男装。” </p><p>第17章 我见犹怜二老意 谁能遣此双姝情</p><p>陈家洛心想：“我不知李沅芷是女扮男装，何尝不笨？”“难道自己真的瞧不出李沅芷是女扮男装吗？”她虽装得什像，但面目娇媚秀美，一望而知是个绝色美人。但一来其时初接总舵主大任，深惧不胜负荷，又逢文泰来被捕，不知如何搭救，戒慎恐惧之际，不敢再惹儿女之情，二来陈家洛一生之中，相处熟稔的女孩子只是晴画、雨诗那样的小丫头，温柔婉顺，他说什么就听什么，霍青桐这般英风飒飒，虽美而不可亲，一见就只想远观而不愿接近，似乎自己故意想找个藉口来退缩在一边。其实他见李沅芷面目美秀，脂粉气什重，只当她是个善于调情骗女人的浮浪子弟，但确比自己俊美得多，他一生事事皆占上风，忽然间给人比了下去，既感气恼，又生了醋意成见，不免故意对其贬低，不肯正视真相。其后天目山徐天宏洞房之夕李沅芷前来混闹，陈家洛也料到是陆菲青的女弟子，内心深处，却不愿由此消去对霍青桐的芥蒂，此后也正因此而得与香香公主相爱，却又未免辜负了霍青桐的一番心意，对她不免有愧于心。喜愧参半，不由得叹了口长气。 </p><p>第18章 为民除害方称侠 抗暴蒙污不愧贞</p><p>关明梅望着渐渐在大漠边缘沉下去的太阳，缓缓说道：“什么都讲个缘法。从前，我常常很是难受，但近来我忽然高兴了。”伸手把陈正德大褂上一个松了的扣子扣上了，又道：“一个人天天在享福，却不知道这就是福气，总是想着天边拿不着的东西，那知道最珍贵的宝贝就在自己身边。现今我是懂了。”陈正德红光满面，神采焕发，望着妻子。 </p><p>第19章 驱驴有术居奇货 除恶无方从佳人</p><p>李沅芷垂下泪来，叫道：“你心里是不喜欢我的，我知道。你快带我见爹爹去，我要死啦。”眼望远处幻象，道：“那是西湖，我爹爹在西湖边上做提督，他……他……你认识他么？” </p><p>第20章 心伤殿隅星初落 魂断城头日已昏</p><p>陈家洛硬起心肠，道：“你跟姊姊去吧！”香香公主垂泪道：“你一定要回来！”陈家洛点点头。香香公主道：“你十年不来，我等你十年；一辈子不来，我等你一辈子。”陈家洛想送件东西给她，以为去日之思，伸手在袋里一摸，触手生温，摸到了乾隆在海塘上所赠的那块温玉，取出来放在香香公主手中，低声道：“你见这玉，就如见我一般。”香香公主含泪接了，说道：“我一定还要见你。就算要死，也是见了你再死。”陈家洛微笑道：“干么这般伤心？等大事成功之后，咱们一起到北京城外的万里长城去玩。”香香公主出了一会神，脸上微露笑意，道：“你说过的话，可不许不算。”陈家洛道：“我几时骗过你来？”香香公主这才勒马不跟。 </p><p>天虹叹道：“诸行无常，诸法无我。人之所滞，在以无为有。若托心本无，异想便息。”陈家洛道：“众生方大苦难。高僧支道林曾有言道：桀纣以残害为性，岂能由其适性逍遥？”</p><p>第21章 忍见红颜堕火窟 空馀碧血葬香魂</p><p>她低声道：“至神至圣的安拉，我不是不信你会怜悯我，但是除了用我身上的鲜血之外，没有别的法子可以教他逃避危难。”于是从衣袖中摸出短剑，在身子下面的砖块上划了“不可相信皇帝”几个字，轻轻叫了两声：“大哥！”将短剑刺进了那世上最纯洁最美丽的胸膛。 </p><p>霍青桐又是伤心，又是愤恨，怒道：“你怎地如此胡涂，竟会去相信皇帝？”陈家洛惭愧无地，道：“我只道他是汉人，又是我的亲哥哥。”霍青桐道：“汉人又怎样？难道汉人就不做坏事么？做了皇帝，还有什么手足之情？”陈家洛哽咽道：“是我害了喀丝丽！我……我恨不得即刻随她而去。” </p><p>白振见众人都是空手不带兵刃，暗暗叹息，想要对陈家洛暗提几句警告，思前想后，总是不敢。 </p><p>​    李可秀拉着女儿的手，叫道：“在我身边！”他一面和白振两人分别传令，督率侍卫拦截，一面拉着女儿，防她混乱中受伤。余鱼同见状，长叹一声，心想：“我与她爹爹势成水火，她终究非我之偶！”一阵难受，挥笛冲入。<br>​    李沅芷右手使劲一挣，李可秀拉不住，当即被她挣脱。李沅芷叫道：“爹爹保重，女儿去了！”反身跃起，纵入人丛。李可秀大出意外，急叫：“沅儿，沅儿，回来！” </p><p>​    无尘叫道：“十弟，下来吧！”章进只是不动，骆冰去扶他时，只觉他身子僵硬，原来已经气绝。骆冰伏尸大哭。文泰来正在抵敌众侍卫，接应赵半山、常氏双侠等过来，听得骆冰哭声，不由得洒了几点英雄之泪，怒气上冲，挥刀连毙三敌。 </p><p>​    霍青桐见师父抱住师公不住垂泪，忙走过去，只见陈正德背上伤口中的血如泉涌，汩汩流出。陆菲青也抢了过来，拿出金创药给他敷治。陈正德苦笑摇了摇头，对关明梅道：“我对不住你……累得你几十年心中不快活，你回到回部之后，和袁……袁大哥去成为夫妻……我在九泉，也心安了。陆兄弟，你帮我成全了这桩美事……” </p><p>白振避开一掌，接了一掌，知道不是敌手，跳开一步，叫道：“陈总舵主，我不是你对手。”陈家洛道：“我敬重你是条汉子，只要你不再给皇帝卖命，那就去吧！”赵半山守在东面窗口，往旁侧一让。白振凄然一笑，道：“多谢两位美意。在下到此地步，还有什么面目再混迹于江湖？”纵身从窗口跳出，远远去了。 </p><p>陈家洛提笔醮墨，先写了“香冢”两个大字，略沉吟，又写了一首铭文：<br>    “浩浩愁，茫茫劫，短歌终，明月缺。郁郁佳城，中有碧血。碧亦有时尽，血亦有时灭，一缕香魂无断绝！是耶非耶？化为蝴蝶。”<br>    群雄伫立良久，直至东方大白，才连骑向西而去。 </p><p>第22章 魂归何处</p><p>阿凡提一抹胡子，森然说道：“陈兄弟，这柄长剑，是秃鹫陈正德老爷子用来自杀的。还有一柄，雪雕陈夫人用来抹了自己脖子。翠羽黄衫托我将这柄剑带来给你。她说你再要自杀，不要悬梁，就用陈老爷子这把剑。翠羽黄衫一得知你的死讯，她就用她师父陈夫人的短剑自杀。我们穆斯林说一是一，说二是二，从来没有说了不算数的。” </p><p>陈家洛默然不语。陆菲青缓缓摇头，叹道：“‘一朝之忿，忘其身，以及其亲，非惑与？’红花会的众位兄弟，今日都是你的‘亲’了，你自暴自弃的自尽，只不过出于一朝之忿，把他们全都忘了。”陈家洛道：“晚辈也不是出于一朝之忿，而是前后思量，实在无德无能、无智无勇，愚而信人，可说是罪不容诛，非自尽不足以谢天下……”说着不禁流下泪来，言语中已带呜咽。陆菲青轻拍他肩头，说道：“‘君子之过也，如日月之食也：过也，人皆见之；更也，人皆仰之。’这是《论语》中的话。”陈家洛道：“前辈教训得是。不过我们一败涂地，已经无可更改的了。” </p><p>陆菲青凛然道：“孟子说：‘居天下之广居，立天下之正位，行天下之大道。得志，与民由之，不得志，独行其道。富贵不能淫，贫贱不能移，威武不能屈，此之谓大丈夫。’何况红花会众兄弟跟我们这些人，个个都是舍生忘死，为国为民，行的是天下之大道，并非单只你‘独行其道’。虽然前途艰难，未必有成，但大丈夫知其不可而为之，自反而缩，虽万千人，吾往矣！”伸掌大力在胸口拍了几下，说道：“总舵主，咱们英雄好汉，又怕了什么？” </p><p>微信读书</p><p>陈家洛默然不语。陆菲青缓缓摇头，叹道：“‘一朝之忿，忘其身，以及其亲，非惑与？’红花会的众位兄弟，今日都是你的‘亲’了，你自暴自弃的自尽，只不过出于一朝之忿，把他们全都忘了。”陈家洛道：“晚辈也不是出于一朝之忿，而是前后思量，实在无德无能、无智无勇，愚而信人，可说是罪不容诛，非自尽不足以谢天下……”说着不禁流下泪来，言语中已带呜咽。陆菲青轻拍他肩头，说道：“‘君子之过也，如日月之食也：过也，人皆见之；更也，人皆仰之。’这是《论语》中的话。”陈家洛道：“前辈教训得是。不过我们一败涂地，已经无可更改的了。” </p><p>陆菲青凛然道：“孟子说：‘居天下之广居，立天下之正位，行天下之大道。得志，与民由之，不得志，独行其道。富贵不能淫，贫贱不能移，威武不能屈，此之谓大丈夫。’何况红花会众兄弟跟我们这些人，个个都是舍生忘死，为国为民，行的是天下之大道，并非单只你‘独行其道’。虽然前途艰难，未必有成，但大丈夫知其不可而为之，自反而缩，虽万千人，吾往矣！”伸掌大力在胸口拍了几下，说道：“总舵主，咱们英雄好汉，又怕了什么？” </p><p>微信读书</p>]]></content>
    
    
    <categories>
      
      <category>读书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>金庸武侠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读《飞狐外传》</title>
    <link href="/2022/03/19/%E8%AF%BB%E4%B9%A6/%E9%A3%9E%E7%8B%90%E5%A4%96%E4%BC%A0/"/>
    <url>/2022/03/19/%E8%AF%BB%E4%B9%A6/%E9%A3%9E%E7%8B%90%E5%A4%96%E4%BC%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h2><h3 id="第2章-大雨商家堡"><a href="#第2章-大雨商家堡" class="headerlink" title="第2章 大雨商家堡"></a>第2章 大雨商家堡</h3><p>​    田归农脸如白纸，望着院子中的大雨。<br>​    三个人的目光瞧着三处，谁也不瞧谁一眼，各自安安静静的坐着，一言不发。但三人心中，却如波涛汹涌，有大哀伤，有大决心，也有大恐惧。</p><h3 id="第3章-宝刀和柔情"><a href="#第3章-宝刀和柔情" class="headerlink" title="第3章 宝刀和柔情"></a>第3章 宝刀和柔情</h3><p>那小姐相貌娇美，肤色白腻，樱红小嘴，双目灵动，别说北地罕有如此佳丽，即令江南也是少有。她身穿一件葱绿织锦的皮袄，颜色鲜艳，但在她容光映照之下，再灿烂的锦缎也显得黯然无色。<br>    众人眼前一亮，不由得都有自惭形秽之感，有的讪讪的竟自退到了廊下，厅上登时空出一大片地方来。 </p><p>客店中夥伴客人见这三人到来，早知不妙，这时见取出兵刃，人人远避，登时大厅中空荡荡的一片。南小姐关心苗人凤安危，却留在厅角之中。苗人凤见她一个娇怯弱女，居然有此胆量，大是喜慰。只因南小姐在厅角这么一站，苗人凤自此对她生死以之，倾心相爱，当下向她微微一笑，抽出冷月宝刀。 </p><p>​    他一生慷慨豪侠，素来不理会小节，然而这是他生死以之相爱的人……在他脑子里，一直觉得南兰应该逃出去，她是女人，不会半点武功，见到了浓烟烈火自然害怕，她那时又不是他妻子，陪着他死了，又有什么好处？……但在心里，他深深盼望在自己遇到危难之时，有个心爱的人守在身旁，盼望心爱的人不要弃他而先逃……他一直羡慕胡一刀有个真心相爱的夫人，自己可没有。胡一刀虽早死，这一生却比自己过得快活。 </p><p>为什么当日救她的不是这位风流俊俏的田相公，偏生是这个木头一般睡在身旁的丈夫？她却不懂，这个田相公武功不够，根本救不了她，就算能救，他也不肯冒险出手。 </p><h3 id="第4章-英雄年少"><a href="#第4章-英雄年少" class="headerlink" title="第4章 英雄年少"></a>第4章 英雄年少</h3><p>福公子搁下了玉箫，伸出手去搂她纤腰。马春花娇羞地避开了，第二次只微微让了一让。<br>    但当他第三次伸手过去时，她已陶醉在他身上散发出来的男子气息之中。夕阳将玫瑰花的枝叶照得撒在地下，变成斑驳陆离的影子。在花影旁边，一对青年男女的影子渐渐偎倚在一起。太阳快落山了，影子变得很长，斜斜的很难看。<br>    唉，青年男女的热情，不一定是美丽的。 </p><p>​    她嘴角边带着微笑，但这不是为他二人笑的。她看到了他们，却全然没看见他们，她只是在想着适才的幸福和甜蜜。福公子常常向她偷看一眼两眼，但她决不敢回看，因为她很明白，只要回看他一眼，四目交投，再也分拆不开了。 </p><p>他是使暗器的大高手，最恨旁人在暗器之上喂毒，常自言道：“暗器原是正派兵器，以小及远，与拳脚、器械，同为武学三大门之一，只是给无耻小人一喂毒，便让人瞧低了。” </p><h3 id="第5章-铁厅烈火"><a href="#第5章-铁厅烈火" class="headerlink" title="第5章 铁厅烈火"></a>第5章 铁厅烈火</h3><p>赵半山双手负在背后，在厅中缓步来去，朗声说道：“咱们学武的，功夫自然有高有下，但只要心地光明磊落，行事无愧于天地，那么功夫高的固然好，武艺低也是一般受人敬重。我赵某人生平最恨的就是行事歹毒、卑鄙无耻的小人。”他越说声音越严厉，双目瞪着陈禹不动。 </p><p>赵半山拍拍他肩头，说道：“贤弟，你三哥没什么了不起，你将来所作所为，一定要胜过三哥十倍，那才真正是男子汉大丈夫。”胡斐道：“可惜我爹爹过世得早，今日得见三哥，我做人才有了榜样。” </p><p>胡斐哈哈一笑，心道：“我贫你富，你赠我黄金，我也不能拒却。三哥怕我推辞，赠金之后急急驰走，未免将我胡斐当作小孩子了。” </p><h3 id="第6章-血印石"><a href="#第6章-血印石" class="headerlink" title="第6章 血印石"></a>第6章 血印石</h3><p>这二人手腕给胡斐抓在掌中，宛如给铁箍牢牢箍住了一般，那里还动弹得半分？胡斐低声道：“我本是个杀人不眨眼的大盗，现下改邪归正，学做生意，要一万两银子办货，可是短了本钱，只得向二位各借五千两。”二人大吃一惊，齐声道：“我……我没有啊。”胡斐道：“好，你们把凤老爷逼死人命的事，说给我听。那一位说得明白仔细，我便不向他借钱。这一万两银子，只好着落在另一位身上。”二人忙道：“我来说，我来说。”先前谁都不肯说，这时生怕独力负担，做了单头债主，竟争先恐后起来。 </p><p>料想白日定然无人露面，便在僻静处找了株大树，爬上树去闭目养神，想到锺家四口受害的惨状，悲愤难平，心中翻覆起誓：“若不杀那凤贼全家，我胡斐枉自生于天地之间。”又想：“世事变化百端，实在难办得紧。我只是个一勇之夫，单凭武功，岂能事事顺利？” </p><h3 id="第7章-紫衣女郎"><a href="#第7章-紫衣女郎" class="headerlink" title="第7章 紫衣女郎"></a>第7章 紫衣女郎</h3><p>胡斐早看清来人是个妙龄少女，但见她身穿紫衣，身材苗条，正是途中所遇那个骑白马的女子。她背上负着一个包袱，却不是自己在饭铺中所失的是什么？只见她一张瓜子脸，双眉修长，眼大嘴小，姿形秀丽，容光照人，不禁大为惊讶：“这女子年纪和我相若，难道便有一身极高武功，如此轻轻巧巧的取去包袱，竟让我丝毫不觉？” </p><p>她每天只行五六十里路程，但胡斐始终没追上来，芳心可可，竟尽记着这个浑身臭泥的小泥鳅胡斐。</p><h3 id="第8章-风雨深宵古庙"><a href="#第8章-风雨深宵古庙" class="headerlink" title="第8章 风雨深宵古庙"></a>第8章 风雨深宵古庙</h3><p>​    胡斐伸了伸舌头，道：“嘿，武林十三家总掌门，这名头可够威风啊。”袁紫衣笑道：“胡大哥，你武艺这般强，何不也抢几家掌门人做做？咱们一路收过去。你收一家，我收一家，轮流着张罗。到得北京，我是十三家总掌门，你也是十三家总掌门。咱哥儿俩一同去参与福大帅的什么天下掌门人大会，岂不有趣？</p><p>​    两人并肩坐着，突然间同时转过头来，目光相触，微微一笑，各自把头转开。隔了一会，胡斐问道：“你的赵三叔身子安好吧？”袁紫衣道：“好啊！他会有什么不好？”胡斐道：“他在那里？我想念他得紧，真想见见他。”袁紫衣道：“那你到回疆去啊。只要你不死，他不死，准能见着。”胡斐一笑，问道：“你是刚从回疆来吧？”袁紫衣回眸微笑，道：“是啊。你瞧我这副模样像不像？”胡斐摇头道：“我不知道。我先前只道回疆是沙漠荒芜之地，那知竟有姑娘这般美女。”<br>袁紫衣红晕上脸，“呸”了一声，道：“你瞎说什么？”胡斐一言既出，微觉后悔，暗想孤男寡女在这古庙之中，说话可千万轻浮不得，岔开话题，问道：“福大帅开这个天下掌门人大会，到底是为了什么，姑娘能见告么？”袁紫衣听他语气突转端庄，不禁向他望了一眼，说道：“他王公贵人，吃饱了饭没事干，找些武林好手消遣消遣，还不跟斗鸡斗蟋蟀一般？只可叹天下无数武学高手，受了他愚弄，竟不自知。” </p><p>火光映照之下，袁紫衣娇脸如花，低语央求，胡斐不由得心肠软了，见到她握着银鞭的手莹白如玉，一股冲动，便想抛下单刀，伸手去握她的小手。一转念间，想她如此恳切相求，太过不近情理，其中多半有诈，心道：“胡斐啊胡斐，你若惑于美色，不顾大义，枉为英雄好汉。你爹爹胡一刀一世豪杰，岂能有你这等不肖子孙？”叫道：“如此便得罪了。”单刀一起，一招“大三拍”，刀光闪闪，已将袁紫衣上盘罩住，左手扬处，一锭纹银往凤天南心口打去。 </p><p>胡斐呆了半晌，包上包袱，手中却拿了那只玉凤凰，吹灭柴火，躺在稻草堆里，思潮起伏：“若说她对我好，何以要救凤天南，竭力跟我作对？若说对我不好，这玉凤凰，这洗乾净、缝补好的衣服鞋袜又为了什么？”<br>    一时睁大了双眼，那里还睡得着？黑暗之中，依稀闻到袁紫衣身上的淡淡幽香，伸出臂去，似乎抱到了她软软的腰肢，心想：“我抱住了她，她叫我放开，我便放开！她如心里当真对我好得很，那么叫我放开是假的。我是个大傻瓜，其实不该放开，我好后悔。她叫我放开，此刻后不后悔呢？”</p><h3 id="第9章-江湖风波恶"><a href="#第9章-江湖风波恶" class="headerlink" title="第9章 江湖风波恶"></a>第9章 江湖风波恶</h3><p>​    胡斐虽与他一见心折，但唯恐他是杀父仇人，恩仇之际，实所难处，待听他说自己父亲是他生平知交，心头一喜，双手接过女孩，见她约莫七八岁年纪，生得什是娇小，抱在手里，又轻又软，淡淡星光之下见她合眼睡着，呼吸低微，嘴角边露着一丝微笑。 </p><h3 id="第10章-毒手药王"><a href="#第10章-毒手药王" class="headerlink" title="第10章 毒手药王"></a>第10章 毒手药王</h3><p>​    他过去牵了马匹，说道：“咱们不过是邀他治病，又或讨一份解药，对他并无恶意。他最多不肯，那也罢了，何必要害咱们性命？”锺兆文道：“小兄弟，你年纪还轻，不知江湖上人心险诈。你对他虽无恶意，但他跟你素不相识，怎信得你过？眼前便是一个例子，刘鹤真对苗大侠绝无歹意，却何以弄瞎了他眼睛？”胡斐默然。 </p><p>​    那村女道：“你这人很好，我便索性连名字也都跟你说了。我叫程灵素，‘灵枢’的‘灵’，‘素问’的‘素’。”胡斐不知“灵枢”和“素问”乃中国两大医经，只觉这两个字很雅致，不像农村女子的名字，这时已知她决不是寻常乡下姑娘，也不以为异，笑道：“那我便叫你‘灵姑娘’，别人听来，只当我叫你是姓林的姑娘呢。”程灵素嫣然一笑，道：“你总有法儿讨我欢喜。”胡斐心中微动，觉她相貌虽不什美，但这么一言一笑，自有一股妩媚风致。 </p><p>程灵素道：“你说好了！他处处小心，反而着了我道儿，是不是？处处小心提防便有用了吗？只有像你这般，才会太平无事。”胡斐道：“我怎么啊？”程灵素笑道：“叫你挑粪便挑粪，叫你吃饭便吃饭。这般听话，人家怎会忍心害你？”胡斐笑道：“原来做人要听话才好。可是你整人的法儿也太巧妙了些，我还是摸不着头脑。” </p><h3 id="第11章-七心海棠"><a href="#第11章-七心海棠" class="headerlink" title="第11章 七心海棠"></a>第11章 七心海棠</h3><p>胡斐一怔，这才想起，她和自己约法三章，自己可一条也没遵守：“她要我不跟旁人说话，我不但说话，还自报姓名。她要我不许动武，我却连打两人。她叫我不得离开她身子三步，咳，我离开她十步也不止了……”越想越歉然，讪讪的道：“真对不起，只因我见这三人凶狠得紧，只怕伤到了你，心里着急，登时什么都忘了。” </p><p>程灵素微微一笑，道：“你是为我的一片好心，胡大哥，我还是领你的情。” </p><p>程灵素抬起头来，淡淡的道：“什么啊？瞧你急成这副样子！”胡斐定了定神道：“倘若你师哥师姊……并无非杀不可的过恶，请你给他们留一条改过自新的道路。”程灵素道：“是啊，我师父原也这么说。”顿了一顿，说道：“可惜你见不到我师父了，否则你们一老一少，一定挺说得来。”口中说话，手上团扇仍不住拨动。胡斐搔了搔头，指着蜡烛问道：“这毒烟……这毒烟不会致人死命么？”程灵素道：“啊，原来咱们胡大侠在大发慈悲啦。我是要救人性命，不是在伤天害理。”说着转过头来，微微一笑，神色颇为妩媚。胡斐满脸通红，心想自己又做了一次傻瓜，虽不懂喷放毒烟为何反是救人，心中却什感舒畅。 </p><p>程灵素道：“我这蓝花是新试出来的品种，总算承蒙不弃，没在半路上丢掉。”胡斐微笑道：“这花颜色娇艳，很是好看。”程灵素道：“幸亏这蓝花好看，倘若不美，你便把它抛了，是不是？”胡斐一时不知所对，只说：“唔……唔……”心中在想：“倘若这蓝花果真十分丑陋，我会不会仍藏在身边？是否幸亏花美，这才救了我和锺大哥的性命？” </p><p>程灵素指着门外的竹箩道：“大师哥便在这竹箩之中。小妹留下的海棠花粉，足够为他解毒。二师哥何不乘机跟他修好言和，也可得一强助？”姜铁山大喜，他一直为大师哥的纠缠不休而烦恼，想不到小师妹竟已安排了这一举两得的妙计，既退强敌，又解了师兄弟间多年的嫌隙，忙连声道谢，将竹箩提进门去。<br>    胡斐从铁门板上拾起那束枯了的蓝花，放入怀中。程灵素晃了他一眼，向姜铁山挥手道别，说道：“二师哥，你头脸出血，身上毒气已然散去，可别怪小妹无礼啊。”姜铁山一楞，登时醒悟，心道：“她叫王铁匠打我，固是惩我昔日的凶横，但也未始不无善意。鹊妹毒气未散，还得给她放血呢！”想起事事早在这个小师妹的算中，自己远非其敌，终于死心塌地，息了抢夺师父遗着《药王神篇》的念头。 </p><p>程灵素微笑道：“你若求我，我便去。只是你也须答允我一件事。”胡斐大喜，忙道：“答允得，答允得，什么事啊？”程灵素笑道：“这时还不知道，将来我想到了便跟你说，就怕你日后要赖。”胡斐道：“我赖了便是个贼王八！”<br>    程灵素一笑，道：“我收拾些替换衣服，咱们便走。”胡斐见她身子瘦瘦怯怯，低声道：“你一夜没睡，只怕太累了。”程灵素轻轻摇头，翩然进房。 </p><p>胡斐道：“我当是宝贝，你瞧来可不值一笑。”将布包摊开了送到她面前，道：“这是我小时候平四叔给我削的一柄小竹刀，这是我结义兄长赵三哥给的一朵红绒花，这是我祖传的拳经刀谱……”指到袁紫衣所赠的那只玉凤，顿了一顿，说道：“这是朋友送的一件玩意儿。”<br>    那玉凤在月下发出柔和的莹光，程灵素听他语音有异，抬起头来，说道：“是一个姑娘朋友吧？”胡斐脸上一红，道：“是！”程灵素笑道：“这还不是价值连城的宝贝吗？”说着微微一笑，将布包还给胡斐，随即躺倒，闭上眼睛，不再说话。 </p><h3 id="第12章-恩仇之际"><a href="#第12章-恩仇之际" class="headerlink" title="第12章 恩仇之际"></a>第12章 恩仇之际</h3><p>​    胡斐不去看苗人凤的伤目，只望着程灵素神色，要从她脸色之中，看出苗人凤的伤目是否有救。但见程灵素的眼珠晶莹清澈，犹似一泓清水，脸上只露出凝思之意，既无难色，亦无喜容，直教人猜度不透。 </p><p>胡斐见程灵素拿了刀针走到苗人凤身前，心中突然生念：“苗大侠和那毒手药王有仇。江湖上人心难测，若他们安排恶计，由程姑娘借治伤为名，却下毒手，岂不是我胡斐第二次又给人借作了杀人之刀？这时苗大侠全身穴道放松，只须在要穴中轻轻一针，即能制他死命。”正自踌躇，程灵素回过头来，将小刀交了给他，道：“你给我拿着。”忽见他脸色有异，当即会意，笑道：“苗大侠放心，你却不放心吗？”胡斐道：“若是给我治伤，我放一百二十个心。”程灵素道：“你说我是好人呢，还是坏人？”<br>    这句话单刀直入的问了出来，胡斐绝无思索，随口答道：“你自然是好人，非常好的好人！”程灵素很欢喜，向他一笑。她肌肤黄瘦，本算不得美丽，但一笑之下，神采焕发，犹如春花初绽。胡斐心中更无半点疑虑，报以一笑。程灵素道：“你真的信我了吧？”说着脸上微微一红，转过头去，不再和他眼光相对。 </p><p>程灵素在七心海棠上采下四片叶子，在一只瓦钵中捣得烂了，敷在苗人凤眼上。苗人凤脸上肌肉微微一动，接着身下椅子格的一响。<br>    程灵素道：“苗大侠，我听胡大哥说，你有位千金，挺可爱的，她在那里啊？”苗人凤道：“这里不太平，送到邻舍家玩去了。”程灵素用布条给他缚在眼上，说道：“好啦！三天之后，待得疼痛过去，麻痒难当之时，揭开布带，便没事了。现下请进去躺着歇歇。胡大哥，咱们做饭去。” </p><p>​    程灵素见胡斐脸有黯然之色，要逗他高兴，说道：“胡大哥，你累了半天，坐一忽儿吧！”胡斐摇头道：“我不累。”程灵素道：“你坐下，我有话跟你说。”胡斐依言坐下，突觉臀下一虚，喀的一声轻响，椅子四脚全断，碎得四分五裂。程灵素拍手笑道：“五百斤的大牯牛也没你重。” </p><p>胡斐下盘功夫极稳，虽坐了个空，但双腿立时拿桩，并没摔倒，只什觉奇怪。程灵素笑道：“那七心海棠的叶子敷在肉上，痛于刀割十倍，若是你啊，只怕叫出我的妈来啦。”胡斐一笑，这才会意，适才苗人凤忍痛，虽不动声色，但一股内劲，早把椅子坐得脆烂了，程灵素意在跟他开个玩笑。 </p><p>胡斐心中欢喜，说道：“多谢指点。晚辈终身受益。”举着筷子欲夹不夹，思量着他那几句话，筷子停在半空。程灵素用筷子在他筷子上轻轻一敲，笑道：“饭也不吃了吗？”胡斐正自琢磨刀诀，全身的劲力不知不觉都贯注右臂之上。程灵素的筷子敲了过来，他筷子上自然而然的生出一股反震之力，嗒的一声轻响，程灵素的一双筷子竟尔震为四截。她“</p><p>啊”的一声轻呼，笑道：“显本事么？” </p><p>胡斐忙陪笑道：“对不起，我想着苗大侠那番话，不禁出了神。”随手将手中筷子递了给她。程灵素接过来便吃。胡斐却喃喃念着：“嫩胜于老，迟胜于急，与其以客犯主……”一抬头，见她正用自己使过的筷子吃饭，竟丝毫不以为忤，不由得脸上一红，欲待拿来代她拭抹乾净，为时已迟，要道歉几句吧，却又太着形迹，便到厨房去另行取了一双筷子。 </p><p>​    胡斐自这口白菜一吃，才真正踏入了第一流高手的境界，回想适才花了这许多力气才胜得田归农，霎时之间又喜欢，又惭愧。<br>​    程灵素见他终于抢到白菜，笑吟吟的望着他，由衷为他欢喜。<br>​    苗人凤道：“胡家刀法今日终于有了传人，唉，胡大哥啊，胡大哥！”说到这里，语音什为苍凉。 </p><p>”<br>    胡斐听得她全心全意的护着自己，好生感激，但想到她要以厉害毒药去对付苗人凤，说也奇怪，反而不自禁的凛然生惧。<br>    心中又想：“这姑娘聪明才智，胜我十倍，武功也自不弱，但整日和毒物为伍，总是……”他自己也不知“总是……”什么，心底只隐隐觉得对她未免无益，不由得生了关怀照顾之意。</p><h3 id="第13章-古怪的盗党"><a href="#第13章-古怪的盗党" class="headerlink" title="第13章 古怪的盗党"></a>第13章 古怪的盗党</h3><p>​    程灵素解下负在背上的胡斐包袱，问道：“你要回去拿包袱吗？我给你带着了。”<br>​    胡斐喜道：“多谢你了。”程灵素道：“你包袱里东西太多，背着撞得我背脊疼，刚才我打开来整理了一下，放得平整服贴些，匆匆忙忙的，别丢失了东西，那只玉凤凰可更加丢不得。”胡斐给她说中心事，脸上一红，说道：“幸亏你带来了包袱，否则连今晚吃饭住店的银子也没了。最要紧的是我家传的拳经刀谱，决计丢不得。”程灵素打开包袱，取出他那本拳经刀谱，淡淡的道：“可是这本？我给你好好收着。”<br>​    胡斐道：“你真细心，什么都帮我照料着了。”程灵素道：“就可惜那只玉凤给我在路上丢了，真过意不去。”胡斐见她脸色郑重，不像说笑，心中一急，道：“我回头找找去，说不定还能找到。”说着转头便走。程灵素忽道：“咦，这里亮晃晃的是什么东西？”伸手到青草之中，拾起一物，莹然生光，正是那只玉凤。<br>​    胡斐大喜，笑道：“你是女诸葛，小张良，小可甘拜下风。”程灵素道：“见了玉凤凰，瞧你欢喜得什么似的。还给你吧！”将刀谱、玉凤和包袱都还了给他，说道：“胡大哥，咱们后会有期。” </p><p>胡斐一怔，柔声道：“你生气了么？”程灵素道：“我生什么气？”但眼眶一红，珠泪欲滴，忙转过了头去。胡斐道：“你……你去那里？”程灵素道：“我不知道。”胡斐道：“怎么不知道？”程灵素道：“我没爹没娘，师父又死了，又没人送什么玉凤凰、玉麒麟给我，我……我怎么知道去那里。”说到这里，泪水终于流了下来。<br>    胡斐自和她相识以来，见她心思细密，处处占人上风，遇上任何难事，无不迎刃而解，但这时见她悄立晓风之中，残月斜照，怯生生的背影微微耸动，不由得大生怜惜，说道：“我送你一程。”<br>    程灵素背着身子，拉衣角拭了拭眼泪，说道：“我又不去那里，你送我做什么？你要我医治苗大侠的眼睛，我已经给治好啦。” </p><p>胡斐要逗她高兴，说道：“可是还有一件事没做。”程灵素转过身来，问道：“什么？”胡斐道：“我求你医治苗大侠，你说也要叫我做一件事的。什么事啊，你还没说呢。”程灵素究是个年轻姑娘，突然破涕为笑，道：“你不提起，我倒忘了，这叫做自作孽，不可活。好，我要你干什么，你都答允，是不是？”胡斐确是心甘情愿的为她无论做什么事，昂然道：“只要我力所能及，无不从命。”<br>    程灵素伸出手来，道：“好，那只玉凤凰给了我。”胡斐一呆，大是为难，但他终究言出必践，当即将玉凤递了过去。程灵素不接，道：“我要来干什么？我要你把它砸得稀烂。”<br>    这一件事胡斐可万万下不了手，呆呆的怔在当地，瞧瞧程灵素，又瞧瞧手中玉凤，不知如何是好，袁紫衣那俏丽娇美的身形面庞，刹那间在心头连转了几转。<br>    程灵素缓步走近，从他手里接过玉凤，给他放入怀中，微笑道：“从今以后，可别随便答允人家什么。世上有许多事情，嘴里虽答允了，却是没法办到的呢。好吧，咱们可以走啦！”胡斐心头怅惘，感到一股说不出的滋味，给她捧着那盆七心海棠，跟在后面。 </p><p>​    两人稍加休息，又到大厅，你看我，我看你，见对方身上衣履都焕然一新。程灵素低声笑道：“胡大哥，过新年吗？打扮得这么齐整。”胡斐见她脸上薄施脂粉，清秀之中微增娇艳之色，竟似越看越美，浑不似初会时那么肌肤黄瘦，黯无光采，笑道：“你可真像新娘子一般呢。”程灵素脸上一红，转过了头不理。胡斐暗悔失言，但偷眼相瞧，她脸上却不见有何怒色，目光中只露出又顽皮、又羞怯的光芒。 </p><p>胡斐翻阅一遍，大是迷惘，将簿子交给程灵素，道：“你看。”程灵素看了，也猜不透是什么用意，笑道：“胡大员外，恭喜发财！” </p><p>只见程灵素稍施脂粉，容貌虽不算美，却也颇觉俏丽，突然心中一动：“倘若我娶了她为妻，在这里过些太平日子，那是一生中从未享过的福气。袁姑娘虽比她可爱得多，但她不断跟我作对，显是凤天南这大恶霸的一党。况且第一，她未必肯嫁我。第二，就算嫁了我，整天打打杀杀、吵吵闹闹，而程姑娘却对我那么好，在一起有趣得多。只不过这里的主人结交官府，显非良善之辈，我胡斐难道贪图财富安逸，竟与这等人同流合污，狼狈为奸？” </p><p>​    程灵素道：“咱们白吃白喝，白住白宿，半点也没损了什么。这么说来，那主人似乎并没安着歹心。”胡斐道：“我总觉这件事阴阳怪气，很有点儿邪门。”程灵素笑道：“我倒盼这种邪门事儿多遇上些，一路上阴阳怪气个不停。喂，胡大爷，你到底是去那里啊？”胡斐道：“我要上北京。你也同去玩玩，好不好？”程灵素笑道：“好是没什么不好，就只怕有些儿不便。”胡斐奇道：“什么不便？”程灵素笑道：“胡大爷去探访那位赠玉凤的姑娘，还得随身带个使唤丫鬟么？” </p><p>程灵素问道：“这位袁姑娘是个美人儿，是不是？”胡斐微微一怔，脸都红了，说道：“算是很美吧。”程灵素道：“比我这丑丫头好看得多，是不是？”<br>    胡斐没防到她竟会如此单刀直入的询问，不由得颇是尴尬，道：“谁说你是丑丫头了？袁姑娘比你大了几岁，自然生得高大些。”程灵素一笑，说道：“我八岁的时候，拿妈妈的镜子来玩。我姊姊说：‘丑八怪，不用照啦！照来照去还是个丑八怪。’哼！我也不理她，你猜后来怎样？”<br>    胡斐心中一寒，暗想：“你可别把姊姊毒死了。”说道：“我不知道。” </p><p>程灵素听他语音微颤，脸有异色，猜中了他心思，道：“你怕我毒死姊姊吗？那时我还只八岁呢。嗯，不过第二天，家里的镜子通统不见啦。”胡斐道：“这倒奇了。”<br>    程灵素道：“一点也不奇，都给我丢到了井里。”顿了一顿，说道：“但我丢完了镜子，随即就明白了。生来是个丑丫头，就算没了镜子，还是丑的。那井里的水面，便是一面圆圆的镜子，把我的模样给照得清清楚楚。那时候啊，我真想跳到井里去死了。”说到这里，突然举起鞭子狂抽马臀，向前急奔。 </p><p>胡斐纵马跟随，两人一口气驰出十馀里路，程灵素才勒住马头。胡斐见她眼圈红红的，显是适才哭过来着，不敢朝她多看，心想：“你虽没袁姑娘美貌，但决不是丑丫头。何况一个人品德第一，才智方是第二，相貌好不好乃是天生，何必因而伤心？你事事聪明，怎么对此便这地看不开？”瞧着她瘦削的侧影，心中大起怜意，说道：“我有一事相求，不知你肯不肯答允，不知我是否高攀得上？” </p><p>程灵素身子一震，颤声道：“你……你说什么？”胡斐从她侧后望去，见她耳根子和半边脸颊全都红了，说道：“你我都没父母亲人，我想跟你结拜为兄妹，你说好么？”<br>    程灵素的脸颊刹时间变为苍白，大声笑道：“好啊，那有什么不好？我有这么一位兄长，当真是求之不得呢！” </p><p>胡斐听她语气中含有讥讽之意，不禁颇为狼狈，说道：“我是一片真心。”程灵素道：“我难道是假意？”说着跳下马来，在路旁撮土为香，双膝一曲，便跪在地上。胡斐见她如此爽快，也跪在地上，向天拜了几拜。两人相对磕头行礼。程灵素道：“人人都说八拜之交，咱们得磕足八个头……一、二、三、四、……七、八……嗯，我做妹妹，多磕两个。”果然多磕了两个头，这才站起。 </p><p>​    胡斐见她言语行动之中，突然微带狂态，自己也有些不自然起来，说道：“从今而后，我叫你二妹了。”程灵素道：“对，你是大哥。咱们怎么不立下盟誓，说什么有福共享、有难同当？”胡斐道：“结义贵在心盟，说不说都是一样。”程灵素道：“啊，原来如此。”说着跃上了马背，这日直到黄昏，始终没再跟胡斐说话。 </p><p>程灵素道：“你认不认他们？”胡斐道：“待明儿上了道，到荒僻无人之处，这才上前相认。”程灵素笑道：“荒僻无人之处？啊，那可了不得！他们不当你这小胡子是劫镖的强人才怪。”胡斐一笑，道：“这枝镖不值得胡大寨主动手。程二寨主，你瞧如何？”程灵素笑道：“瞧那镖头身上无钱，什是寒伧。你我兄弟盗亦有道，不免拍马上前，送他几锭金子便了。”胡斐哈哈一笑。他确有赠金之心，只是要盘算个妥善法儿，赠金之时须得不失了敬意，才不损人家面子。 </p><p>胡斐心想：“这人所说的人数，和我所猜的一点不错，总算没骗我。管他强援是谁，我岂能舍马姑娘而去？二妹却不能平白无端的在此送了命。”低声道：“二妹，你先骑这马突围出去，我一人照料马姑娘，那便容易得多。”<br>    程灵素知他顾念自己，说道：“咱们结拜之时，说的是‘有难共当’呢，还是‘有难先逃’？”胡斐道：“你和马姑娘从不相识，何必为她犯险？至于我，那可不同。”<br>    程灵素的眼光始终没望他一眼，道：“不错，我何必为她犯险？可是我和你，难道也是从不相识么？” </p><p>胡斐心中大是感激，自忖一生之中，甘愿和自己同死的，平四叔是会的，赵半山也会的，（奇怪得很，一瞬之间，心中忽地掠过一个古怪的念头：苗人凤也会的），今日又有一位年轻姑娘安安静静的站在自己身旁，一点也不踌躇，只是这么说：“活着，咱们一起活，要死，便一起死！” </p><p>程灵素微微一笑，低声问道：“大哥，待会如果走不脱，你救我呢，还是救马姑娘？”胡斐道：“两个都救。”程灵素道：“我是问你，倘若只能救出一个，另一个非死不可，你便救谁？”胡斐微一沉吟，说道：“我救马姑娘！我跟你同死。”<br>    程灵素转过头来，满脸深情，低低叫了声：“大哥！”伸手握住了他手。胡斐心中一震，忽听得屋外脚步声响，往窗孔中一望，叫道：“啊哟，不好！” </p><p>胡斐皱眉道：“这姓商的挺狡猾……”程灵素道：“你要不要出手？”胡斐道：“我是为助马姑娘而来，但是……但是……我可真不知她心意到底怎样？”程灵素对马春花什为不满，说道：“马姑娘决没危险，你好心相助，她未必领你这个情。咱们不如走吧！”胡斐见徐铮的单刀给商宝震掌力逼住了，砍出去时东倒西歪，已全然不成章法，瞧着什是凄惨，说道：“二妹，你说的是，这件事咱们管不了。” </p><pre><code>胡斐弯下腰去，俯身在徐铮耳边，低声道：“徐大哥，你有什么未了之事，兄弟给你办去。”徐铮望望妻子，望望商宝震，苦笑了一下，低声道：“没有。”胡斐道：“我去找到你的两个孩子，抚养他们成人。”他和徐铮全没交情，只眼见他落得这般下场，激于义愤，忍不住挺身而出。 徐铮又苦笑了一下，低声说了一句话，气息太微，胡斐听不明白，把右耳凑到他口边，只听他道：“孩子……孩子……嫁过来之前……早……早就有了……不是我的……”一口气呼出，不再吸进，便此气绝。 </code></pre><h3 id="第14章-北京众武官"><a href="#第14章-北京众武官" class="headerlink" title="第14章 北京众武官"></a>第14章 北京众武官</h3><p>胡斐脸色一沉，道：“那么他打死徐铮徐大哥，是出于福大帅的授意？”<br>    秦耐之忙道：“那倒不是，福大帅贵人事忙，怎知马姑娘已跟那姓徐的成婚？他只是心血来潮，想起了旧情，派几个当差的南来打探一下消息。此刻已有两个兄弟飞马赴京赶报喜讯，福大帅得知他竟有两位公子，这番高兴自不用说了。”<br>    这么一说，胡斐心头许多疑团，一时尽解。只觉此事怨不得马春花，也怨不得福康安，商宝震杀徐铮固然不该，可是他已一命相偿，也已无话可说，只是徐铮一生忠厚老实，明知二子非己亲生，始终隐忍，到最后落得如此下场，深为恻然，长长叹了口气，说道：“秦大哥，此事已分剖明白，原是小弟多管闲事。”轻轻一纵，落在地下。 </p><p>​    胡斐次晨转醒，见自己背上披了一件长袍，想是程灵素在晚间所盖。她站在窗口，秀发为晨风一吹，微微飞扬。胡斐望着她苗条背影，心中混和着感激和怜惜之意，叫了声：“二妹！”程灵素“嗯”的一声，转过身来。<br>​    胡斐见她睡眼惺忪，大有倦色，道：“你一晚没睡吗？啊，我忘了跟你说，有马姑娘在此，他们不敢对咱们怎样。”程灵素道：“马姑娘半夜里悄悄出屋，至今未回。她出去时轻手轻脚，怕惊醒了你，我也就假装睡着。”胡斐微微一惊，转过身来，果见马春花所坐之处只剩下一张空櫈。 </p><p>再走出数丈，见林中堆着两座新坟，坟前并无标志，也不知那一座是徐铮的，那一座是商宝震的。胡斐心想：“虽一个是丈夫，一个是杀丈夫的仇人，但在马姑娘心中，恐怕两人也无多大差别，都是爱着她而她并不爱的人，都是为了她而送命的不幸之人。”想到此处，不由得喟然长叹，于是将秦耐之的说话向程灵素转述了。 </p><p>​    程灵素道：“马姑娘心中喜欢福公子，徐铮就是活着，也只徒增苦恼。他小小一个倒霉的镖师，怎能跟人家兵部尚书、统兵大元帅相争？”胡斐道：“不错，倒还是死了乾净。”在两座坟前拜了几拜，说道：“徐大哥、商公子，你们生前不论和我有恩有怨，死后一笔勾销。马姑娘从此富贵不尽，你们两位死而有知，也不用再记着她了。”<br>​    二人牵了马匹，缓步出林。程灵素道：“大哥，咱们上那儿去？”胡斐道：“先找到客店，让你安睡半日，再说别的，可别累坏了我的好妹子！”程灵素听他说“我的好妹子”，心中说不出的欢喜，转头向他甜甜一笑。 </p><p>程灵素道：“你去跟这福大帅捣捣蛋，不也好吗？我瞧还有一个人是必定要去的。”胡斐道：“谁啊？”程灵素微笑道：“这叫作明知故问了。你还是给我爽爽快快的说出来的好。”<br>    胡斐早已明白她心意，也不再假装，说道：“她也未必一定去。”顿了一顿，又道：“这位袁姑娘是友是敌，我还弄不明白呢。”程灵素道：“如果每个敌人都送我一只玉凤儿，我倒盼望遍天下都是敌人才好……”忽听得窗外一个女子声音说道：“好，我也送你一只！”声音甫毕，嗤的一响，一物射穿窗纸，向程灵素飞来。胡斐拿起桌上程灵素裁衣的竹尺，向那物一敲，击落在桌，左掌挥出，烛火应风而灭。接着听得窗外那人说道：“挑灯夜谈，美得紧哪！”<br>    胡斐听话声依稀便是袁紫衣的口音，胸口一热，冲口而出：“是袁姑娘么？”却听步声细碎，顷刻间已然远去。 </p><p>胡斐打开绢包，不由得呆了，原来包里又是一只玉凤，竟和先前留赠自己的一模一样，心中立想：“难道我那只竟失落了，还是给她盗了去？”伸手到怀中一摸，触手生温，那玉凤好端端的便在怀中，取出来一看，两只玉凤果然雕琢得全然相同，只是一只凤头向左，一只向右，显是一对儿。<br>    绢包中另有一张小小白纸，纸上写道：“马归正主，凤赠侠女。”胡斐又是一呆：“这马又不是我的，怎说得上‘马归正主’？难道要我转还给赵三哥么？”将简帖和玉凤递给程灵素道：“袁姑娘也送了一只玉凤给你。”<br>    程灵素一看简帖上的八字，说道：“我又是什么侠女了？不是给我的。”胡斐道：“包上不明明写着‘程姑娘’？她昨晚又说：‘好，我也送你一只！’”程灵素淡然道：“既是如此，我便收下了。这位袁姑娘如此厚爱，我可无以为报了。” </p><p>但是，北京终于到了，胡斐和程灵素并骑进了都门。<br>    进城门时胡斐向程灵素望了一眼，隐隐约约间似乎看到一滴泪珠落在地下尘土之中，只是她将头偏着，没能见到她容色。<br>    胡斐心头一震：“这次到北京来，可来对了吗？”<br>    其时正当乾隆中叶，升平盛世。京都积储殷富，天下精华，尽汇于斯。 </p><p>胡斐生性极爱结交朋友，对做官的虽无好感，但见这一干人对自己什为尊重，而他本来又喜赌钱，笑道：“还是秦大哥推庄，小弟来下注碰碰运气。聂大哥，你先收着，待会输乾了再问你借。”将银子推还给那姓聂武官。转头问程灵素道：“二妹，你赌不赌？”程灵素抿嘴笑道：“我不会，我帮你捧银子。” </p><p>​    程灵素待他走远，道：“大哥，这座大宅子只怕值二万两银子也不止。这件事大不寻常。”胡斐点头道：“不错，你瞧这中间有什么蹊跷？”程灵素微笑道：“我想总是有个人在暗暗喜欢你，因此故意接二连三，一份一份的送你大礼。”<br>​    胡斐知她在说袁紫衣，脸上一红，摇了摇头。程灵素笑道：“我是跟你说笑呢。我大哥慷慨豪侠，也不会把这些田地房产放在心上。这送礼之人，决不是你的知己，否则的话，还不如送一只玉凤凰。这送礼的若非怕你，便是想笼络你。嗯，谁能有这么大手笔啊？”胡斐凛然道：“是福大帅？” </p><p>程灵素目澄如水，脉脉的望着胡斐，心想这些英雄事迹，你一路上从来不说。 </p><h3 id="第15章-紫罗衫动红烛移"><a href="#第15章-紫罗衫动红烛移" class="headerlink" title="第15章 紫罗衫动红烛移"></a>第15章 紫罗衫动红烛移</h3><p>袁紫衣的匕首翻飞击刺，招招不离胡斐要害，出手狠辣凌厉，直如性命相搏一般。<br>    胡斐那敢怠慢，凝神接战，耳听得凤天南纵声长笑，叫道：“胡家小兄弟，老哥哥失陪了，咱们后会有期。”笑声愈去愈远，黑夜中遥遥听来，便似枭鸣。 </p><p>胡斐快步走到亭中，拿起茶杯喝了一口，低声道：“此人厉害，不可轻敌。”袁紫衣眼皮低垂，细声道：“我多次坏你大事，你不怪我么？”这一句话胡斐却答不上来，说是不怪，可是她接连三次将凤天南从自己手底下救出；说是怪她罢，瞧着她若有情、若无情的眼波，却又怎能怪得？ </p><p>袁紫衣见胡斐走入亭来教自己提防，芳心大慰，她本来心下担忧，生怕斗不过这八卦门高手，这时精神一振，低声道：“我心里好对你不起！我如不行，请你帮我照看着。”依她原来好胜的性子，这句话明显服软，无论如何是不肯说的，但今晚又坏了他的大事，心下什歉，说这句话，是有意跟他说和修好。 </p><p>袁紫衣继续说道：“可是一路之上，我偷你的包袱，跟你打打闹闹，将你推入河里，全无赔罪之意，只因赵半山把你说得太好，夸上了天去，说当今十几岁的少年人中，没一个及得上你。我也是十几岁的人，心里可不服气了。你武功是强的，为人仁义，果然了不起，可是……可是……”胡斐接口道：“可是这小胡斐做事顾前不顾后，脑筋太过胡涂。两个小流氓三言两语，就把他引开了。锺家三口人，还不是死在他胡涂之下？他一心要做好事，却帮助坏人送信去给苗人凤苗大侠，弄瞎了他一双眼睛。福公子派人来接他的老相好、私生子，他却又没来由的打什么抱不平。人家摆个圈套要为凤天南说合，他想也不想，一头就钻了进去。这小胡斐是个鲁莽匹夫，就论武功，也胜不了一个十几岁的小姑娘。那晚在湘妃庙中，那小姑娘如当真要杀了他，还不是早已要了他性命？” </p><p>​    胡斐万万料想不到，这个一直跟自己作对为难的姑娘，竟会当面称赞自己，不由得满脸通红，大为发窘，心中却什感甜美舒畅。从广东直到北京，风尘行旅，间关千里，他心间意下，无日不有袁紫衣的影子在，只是每想到这位美丽动人、却又刁钻古怪的姑娘，七分欢喜之中，不免带着两分困惑，一分着恼。今夜一夕长谈，嫌隙尽去，原来中间竟有这许多原委，怎不令他在三分酒醉之中，再加上了三分心醉？ </p><p>袁紫衣道：“程家妹子，你在那单刀之上，干么不下致命毒药？”程灵素目中含泪，愤然道：“我虽是毒手药王的弟子，但生平从没杀过一个人。难道我就能随随便便的害你么？何况……何况你是他的心上人，从湖南到北京，千里迢迢，他整天除了吃饭睡觉，念念不忘，便是在想着你。我怎会当真害你？”说到这里，泪珠儿终于夺眶而出。<br>    袁紫衣一愕，站起身来，飞快的向胡斐掠了一眼，只见他脸上显得什是忸怩尴尬。<br>    程灵素这一番话，突然吐露了胡斐的心事，实大出他意料之外，不免什是狼狈，但目光之中，却满含款款柔情。<br>    袁紫衣上排牙齿一咬下唇，说道：“我是个苦命人，世上的好事，全跟我无缘。我有时情不自禁，羡慕人家的好事，可是老天注定了的，我一生下来便命苦，比不上别人！人家对我的好意，我只好心里感激，却难以报答，否则师父不容、菩萨不容、上天不容……胡大哥，我自己作不了主，请你原谅……”说到这里，声音哽咽了，泪水扑簌簌的掉在胸前，蓦地里纤手一扬，噗的一声，搧灭了烛火，穿窗而出，登高越房而去。<br>    胡斐和程灵素都是一惊，忙奔到窗边，但见宿雨初晴，银光泻地，早不见了袁紫衣的人影，回过头来，月光下只见桌上兀自留着她的点点泪水。</p><h3 id="第16章-华拳四十八"><a href="#第16章-华拳四十八" class="headerlink" title="第16章 华拳四十八"></a>第16章 华拳四十八</h3><p>提着他走到假山之后，低声喝问：“福康安何以要拿我？”那武官道：“实……实在不知。”胡斐道：“这时他在那里？”那武官道：“福大帅……福大帅从马姑娘的阁子中出来，嘱咐了我们，又……又回进去了。”胡斐伸手点了他哑穴，说道：“命便饶你，明日有人问起，你须说这姓聂的也是我杀的。你如走漏消息，他家小有什风吹草动，我将你全家杀得乾乾净净，老小不留。”那武官说不出话，不住点头。胡斐顺手一拳，将他打得昏晕过去</p><p>​    程灵素“嗯”了一声，微笑道：“人家是九家半总掌门，难道你便连一家也当不上？”她这句话一出口，立即好生后悔：“为什么总念念不忘的想着袁姑娘，又不断提醒大哥，叫他也念念不忘？”见胡斐昂然走出假山，瞧着他的背影，又想：“我便不提醒，他难道便有一刻忘了？”见他大踏步走向戏台，不禁又甜蜜，又心酸。 </p><p>。<br>    胡斐向台上那人一抱拳，说道：“天字派弟子程灵胡，请师兄指教。”<br>    程灵素在假山背后听得清楚，听他自称“程灵胡”，不禁微笑，心中随即一酸：“倘若他当真是我的亲兄长，倒免却了不少烦恼。” </p><p>。<br>    忽听得一个声音在耳边柔声道：“大哥，你作什么梦了？”胡斐跃起身来，揉了揉眼睛，微一凝神，说道：“我来照料马姑娘，该当由你睡一忽儿了。”程灵素道：“先给你装上胡子，这才放心。”拿起浆硬了的一条条头发，用胶水给他黏在颏下和腮边。这一番功夫好不费时，黏了将近一个时辰，眼见红日当窗，方才黏完。<br>    胡斐揽镜一照，不由得哑然失笑，只见自己脸上一部络腮胡子，虬髯戟张，不但面目全非，且大增威武。胡斐很是高兴，笑道：“二妹，我这模样儿挺美啊，日后我真的便留上这么一部大胡子。”<br>    程灵素想说：“只怕你心上人未必应许。”话到口边，终于忍住。她忙了一晚，到这时心力交困，眼见马春花睡得安稳，再也支持不住，伏在桌上便睡着了。<br>    十年之后，胡斐念着此日之情，果真留了一部络腮大胡子，那自不是程灵素这时所能料到了。 </p><h3 id="第17章-龙潭虎穴"><a href="#第17章-龙潭虎穴" class="headerlink" title="第17章 龙潭虎穴"></a>第17章 龙潭虎穴</h3><p>​    汪铁鹗颤声道：“我是戍正当值，天稍黑便该去了。”胡斐道：“你给张九告个假，说他生了病，不能当差。我在这儿等你，快天黑时你来接我。”汪铁鹗呆了半晌，心想只要这一句话儿答允下来，一生便变了模样，要做个铁铮铮的汉子，什么荣华富贵，就一笔勾销；但若一心一意为福大帅出力，不免是非不分，于心不安。 </p><p>胡斐听了那身材瘦削的汉子那声呼喝，又见了这一跃的身法，已知是程灵素前来接应，喜道：“二妹，原来是你！”程灵素“哼”的一声，并不答话。胡斐又问：“马姑娘怎样？病势没转吧？”程灵素道：“不知道。”胡斐知她生气了，柔声道：“二妹，我没听你话，是我的不是，请你原谅这一次。”程灵素道：“我说过不治病，便不治。难道我说的不是人话么？” </p><p>​    胡斐又道：“二妹，你这条计策真再妙不过，倘若不是雇用深夜倒粪的粪车，寻常大车一辆辆停在街心，给巡夜官兵瞧见了，定会起疑。”程灵素冷笑道：“起疑又怎么样？反正你不爱惜自己，便死在官兵手中，也是活该。”胡斐笑道：“我死是活该，只是累得姑娘伤心，那便过意不去。”程灵素冷笑道：“你不听我话，自己爱送命，才没人为你伤心呢。除非是你那个多情多义的袁姑娘……她又怎么不来助你一臂之力？”<br>​    胡斐道：“她只有不断跟我为难，几时帮过我？天下只一位姑娘，才知我会这般蛮干胡来，也只有她，才能在紧急关头救我性命。”这几句话说得程灵素心中舒服慰贴无比，哼了一声，道：“当年救你性命的是马姑娘，因此你这般念念不忘，要报她大恩。”胡斐道：“在我心中，马姑娘又怎能跟我的二妹相比？”<br>​    程灵素在黑暗中微微一笑，道：“你求我救治马姑娘，什么好听的话都会说。待得不求人家了，便又把我的说话当作耳边风。”胡斐道：“倘若我说的是假话，教我不得好死。”程灵素道：“真便真，假便假，谁要你赌咒发誓了？”她这句话口气松动不少，显是胸中的气恼已消了大半。 </p><p>程灵素嫣然一笑，道：“咱们第一天见面，你便没听我吩咐。我叫你不可离我身边，叫你不可出手，你听话了么？”胡斐道：“我以后定要多听你话。”程灵素幽幽的道：“还有以后吗？”胡斐一本正经的道：“有，有！自然有！”程灵素一笑，笑容中颇含苦涩，心中却也欢喜。 </p><h3 id="第18章-天下掌门人大会"><a href="#第18章-天下掌门人大会" class="headerlink" title="第18章 天下掌门人大会"></a>第18章 天下掌门人大会</h3><p>​    胡斐听得邻桌上的一个老者说道：“武林之中，有的是门派抬高了人，有的是人抬高了门派。那位青什么道长，只因是武当山太和宫的观主，便算是天下四大掌门人之一，我看未必便有什么真才实学吧？至于‘三才剑’一门呢，若不是出了汤大侠这样一位百世难逢的人物，在武林中又能占到什么席位呢？”一个壮汉接口道：“师叔说得是。”胡斐听了也暗暗点头。 </p><p>仆役送菜上来，福大帅府宴客，端的非比寻常，单是那一坛坛二十年的状元红陈绍，便是极难尝到的美酒。胡斐酒到杯乾，一口气喝了二十馀杯。程灵素见他酒兴什豪，只抿嘴微笑，自己在烟袋中抽一两口旱烟，偶尔回头，便望凤天南一眼，生怕他走得没了影踪。 </p><p>胡斐心道：“福康安治军严整，确非平庸之辈。无怪他数次出征，每一次都打胜仗。”但见他满脸春风，神色什喜，又想：“这人全无心肝，害死了心上人，两个儿子给人抢了去，竟漫不在乎。”随即转念：“这人当真厉害之极，家里出了这等大事，脸上却半点不露。” </p><p>​    许多有见识的掌门人均想：“这那里是少了许多纷争？各门各派一分等级次第，武林中立时便惹出无穷祸患。这二十四只御杯势必你争我夺。天下武人从此为名位而争斗，自相残杀，刀光血影，再也没宁日了。” </p><p>福康安又道：“得了这二十四只御杯的，自然须得好好的看管着。倘若给别门别派抢了去、偷了去，那玉龙八门、金凤八门、银鲤八门，跟今日会中所定，却又不同了哇！”这番话说得又明白了一层，却仍有不少武人附和哄笑。 </p><h3 id="第19章-宝刀银针"><a href="#第19章-宝刀银针" class="headerlink" title="第19章 宝刀银针"></a>第19章 宝刀银针</h3><p>​    他明知在此处多耽得一刻，便多增一分凶险，但一来心中存着这许多疑团未解；二来眼见凤天南便在身旁，好容易知道了他的下落，岂能又让他走了？三来也要瞧一瞧馀下的三只玉龙杯由那派的掌门人所得。<br>​    其实，这些都只是他心里所计较的原因，真正的原因，却是在心中隐隐约约觉得的：袁紫衣一定会来。既知她要来，他就决计不走。便有天大危险，也吓他不走。 </p><h3 id="第20章-相见欢"><a href="#第20章-相见欢" class="headerlink" title="第20章 相见欢"></a>第20章 相见欢</h3><p>他自从蓦地里见到那念念不忘的俊俏姑娘竟是个尼姑，便即神魂不定，始终无法静下来思索，脑海中诸般念头此去彼来，犹似乱潮怒涌，连背上的伤痛也忘记了。 </p><p>​    圆性却蒙峨嵋派中一位辈份什高的尼姑救去，带到天山，自幼便给她落发，授以武艺。那位尼姑的住处和天池怪侠袁士霄及红花会群雄相去不远，平日切磋武学，时相过从。圆性天资极佳，她师父的武功原已极为高深繁复，但她贪多不厌，每次见到袁士霄，总缠着他要传授几招，而从陈家洛、霍青桐直至心砚，红花会群雄无人不是多多少少的传过她一些功夫。天池怪侠袁士霄老来寂寞，对她传授尤多。袁士霄于天下武学，几乎说得上无所不知，何况再加上十几位明师，是以圆性艺兼各派之所长，她人又聪明机警，以智巧补功力不足，若不是年纪太轻，内功修为尚浅，直已可跻一流高手之境。<br>​    这一年圆性禀明师父，回中土为母报仇，鸳鸯刀骆冰便托她带来白马，遇到胡斐时赠送于他。只赵半山将胡斐夸得太好，圆性少年性情，心下不服，这才有途中和胡斐数度较量之事。不料两人见面后惺惺相惜，心中情苗暗茁。圆性待得惊觉，已柔肠百转，难以自遣了。她自行制约，不敢多和胡斐见面，只暗中跟随。后来见他结识了程灵素，她既自伤，亦复宽慰，自己是方外之人，终身注定以青灯古佛为伴，她自幼蒙师父教养长大，十六岁上曾立下重誓，要作师父的衣钵传人，师恩深重，决计不敢有背。程灵素聪明智慧，犹胜于己，对胡斐更一往情深，胡斐得以为侣，原亦大佳。因此上留赠玉凤，微通消息，但暗地里却已不知偷弹了多少珠泪，自伤身世，伤痛不禁……她此番东来报仇，大仇人是甘霖惠七省汤沛，心想若暗中行刺下毒，原亦不难，但此人一生假仁假义，沽名钓誉，须得在天下好汉之前揭破他的假面具，那比将他一剑穿心更加痛快。 </p><p>​    眼见再奔得几步，凤天南便可逃出福府，圆性遥遥望见，急叫：“胡大哥……这恶人要逃走了！快杀了他！” </p><p>须知“儒以文乱法，侠以武犯禁”，历来人主大臣，若不能网罗文武才士以为己用，便欲加之斧钺而诛灭，以免为患民间，扇动天下，自来便是如此。这时听到石万嗔大叫：“有人在茶酒之中下了毒药。”个个心惊肉跳，至于福康安自己和众卫士其实也肚中疼痛，旁人自然不知。 </p><p>胡斐瞧了马春花的情状，便程灵素不说，也知已命在顷刻，想起商家堡中昔日之情，不禁怔怔的掉下泪来。他自在福康安府中见到袁紫衣成了尼姑圆性，心中一直郁郁，此刻眼泪一流，触动心事，再也忍耐不住，呜呜咽咽的哭了起来。 </p><p>程灵素和圆性如何不明白他因何伤心？程灵素道：“我再去瞧瞧马姑娘。”缓步走进厢房。圆性给他这么一哭，眼圈也早红了，强自忍住便欲夺眶而出的眼泪，颤声道：“胡大哥，多谢你待我的一片……一片……”说到这里，泪水再也难忍。<br>    胡斐泪眼模糊的抬起头来，道：“你……你难道不能……不能还俗吗？待杀了那姓汤的，报了父母大仇，求求你，不要再做尼姑了。” </p><p>胡斐追了出去，颤声问道：“你……你去那里？”圆性道：“你何必管我？此后便如一年之前，你不知世上有我，我不知世上有你，岂不乾净？”胡斐道：“我不要乾净！我只要跟你在一起！”话声什是固执。圆性柔声道：“我们命里没这福气……”话没说完，拂袖出门。 </p><p>胡斐本来生性谨细，绝非莽撞之徒，只是他究属少年，血气方刚，眼看马春花为福康安害得这等惨法，激动了侠义之心，一切全豁了出去，什么也不理会了。<br>    也说不定由于他念念不忘的美丽姑娘忽然之间变成了个尼姑，令他觉得世情惨酷，人生悲苦，要大闹便大闹一场，最多也不过杀头丧命，又有什么大不了？ </p><p>蓦地里听得一人长声吟道：“浩浩愁，茫茫劫。短歌终，明月缺。郁郁佳城，中有碧血。碧亦有时尽，血亦有时灭，一缕香魂无断绝。是耶？非耶？化为蝴蝶。” </p><p>陈家洛道：“我明白啦！你要我假冒那个伤天害理、负心薄幸的福康安，去安慰一下这位多情多义的马姑娘？”胡斐低声道：“正是！”群雄均觉胡斐这个荒唐的念头果然异想天开之至，可是谁也笑不出来。<br>    陈家洛眼望远处，黯然出神，说道：“墓中这位姑娘临死之际，如能见我一面，那是多么的快活！可惜终难如愿……”转头向胡斐道：“好，我便去见见这位马姑娘。” </p><p>两个孩子扑向榻上，大叫：“妈妈，妈妈！”马春花睁开眼来，见是爱子，陡然间精神一振，也不知那里来的力气，将两个孩子紧紧搂在怀里，叫道：“孩子，孩子，妈想得你们好苦！”三个人相拥良久，她转眼见到胡斐，对两个孩子道：“以后你们跟着胡叔叔，好好听他的说话……你们……拜了他作义……义……”<br>    胡斐知她心意，说道：“好，我收了他们作义儿，马姑娘，你放心吧！”马春花脸露微笑，道：“快……快磕头，我好……好放心……”两个孩子跪在胡斐面前，磕下头去。<br>    胡斐让他们磕了四个头，伸手抱起两人，低声道：“马姑娘，你还有什么吩咐么？”马春花道：“我死了之后，求你……求你将我葬……葬在我丈夫徐……师哥的坟旁……他很可怜……从小便喜欢我……可是我不喜欢……不喜欢他。” </p><p>​    过了好一会儿，陈家洛从庙门里慢慢踱了出来。他向胡斐点了点头。胡斐知道马春花离开这世界了。她临死之前见到了心爱的两个儿子，也见到了“情郎”。胡斐不知道她跟陈家洛说了些什么，是责备他的无情薄幸呢，还是诉说自己终生不渝的热情？除了陈家洛之外，这世上是谁也不知道了。 </p><h3 id="第21章-恨无常"><a href="#第21章-恨无常" class="headerlink" title="第21章 恨无常"></a>第21章 恨无常</h3><p>​    程灵素吸一口毒血，便吐在地下，若是寻常毒药，她可以用手指按捺，从空心金针中吸出毒质，便如替苗人凤治眼一般，但碧蚕毒蛊、鹤顶红、孔雀胆三大剧毒入体，又岂是此法所能奏效？她直吸了四十多口，眼见吸出来的血液已全呈鲜红之色，这才放心，吁了一口长气，柔声道：“大哥，你和我都很可怜。你心里喜欢袁姑娘，那知道她却出家做了尼姑……我……我心里……”她慢慢站起身来，柔情无限的瞧着胡斐，从药囊中取出两种药粉，替他敷在手背，又取出一粒黄色药丸，塞在他口中，低低的道：“我师父说中了这三种剧毒，无药可治，因为他只道世上没一个医生，肯不要自己的性命来救活病人。大哥，他决计想不到我……我会待你这样……” </p><p>胡斐只想张口大叫：“我不要你这样，不要你这样！”但除了眼光中流露出反对的神色之外，委实无法示意。<br>    程灵素打开包裹，取出圆性送给她的那只玉凤，凄然瞧了一会，用一块手帕包了，放入胡斐怀里。再取出一枝蜡烛，插在神像前的烛台上，一转念间，从包中另取一枝烛身较细的蜡烛，拗去半截，晃火摺点燃了，放在后院天井中，让蜡烛烧了一会，再取回来放在烛台旁，另取一枝新烛插上烛台。她又从怀里取出一颗黄色药丸，喂在胡斐嘴里。<br>    胡斐瞧着她这般细心布置，不知是何用意，只听她道：“大哥，有一件事我本来不想跟你说，以免惹起你伤心。现下咱们要分手了，不得不说。在掌门人大会之中，我那狠毒的师叔和田归农相遇之时，你可瞧出蹊跷来么？他二人是早就相识的。田归农用来毒瞎苗大侠眼睛的断肠草，定是石万嗔给的。你爹爹所以中毒，刀上毒药多半也是石万嗔配制的。”胡斐登时心中雪亮，只想大叫：“不错！”<br>    程灵素道：“你爹爹妈妈去世之时，我尚未出生，我那几个师兄、师姊，也年纪尚小，未曾投师学艺。那时候当世擅于用毒之人，只先师和石万嗔二人。苗大侠疑心毒药是我师父给的，因之跟他失和动手，我师父既然说不是，当然不是了。我虽疑心这个师叔，可是并无佐证，本来想慢慢查明白了，如果是他，再设法为你报仇。今日事已如此，不管怎样，总之是要杀了他……”说到这里，体内毒性发作，身子摇晃了几下，摔在胡斐身边。<br>    胡斐见她慢慢合上眼睛，口角边流出一条血丝，真如是万把钢锥在心中攒刺一般，只想紧紧抱住她，张口大叫：“二妹，二妹！”但便如深夜梦魇，不论如何大呼大号，总是喊不出半点声息，心里虽然明白，却连一根小指头儿也转动不得。 </p><p>胡斐身旁躺着三具尸首，一个是他义结金兰的小妹子程灵素，两个是他义妹的对头、背叛师门的师兄师姐。破庙中一枝黯淡的蜡烛，随风摇曳，忽明忽暗，他身上说不出的寒冷，心中说不出的凄凉。 </p><p>终于蜡烛点到了尽头，忽地一亮，火焰吐红，一声轻响，破庙中漆黑一团。<br>    胡斐心想：“我二妹便如这蜡烛一样，点到了尽头，再也不能发出光亮了。她一切全算到了，料得石万嗔他们一定还要再来，料到他小心谨慎不敢点新蜡烛，便将那枚混有七心海棠花粉的蜡烛先行拗去半截，诱他上钩。她早死了，在死后还是杀了两个仇人。她一生没害过一个人的性命，她虽是毒手药王的弟子，生平却从未杀过人。她是在自己死了之后，再来清理师父门户，再来杀死这两个狼心狗肺的师兄师姊。” </p><p>“她没跟我说自己的身世，我不知她父亲母亲是怎样的人，不知她为什么要跟无嗔大师学这一身可惊可怖的本事。我常向她说我自己的事，她总是关切的听着。我多想听她说说她自己的事，可是从今以后，再也听不到了。”<br>    “二妹总是处处想到我，处处为我打算。我有什么好，值得她对我这样？值得她用自己的性命，来换我的性命？其实，她根本不必这样，只须割了我的手臂，用他师父的丹药，让我在这世界上再活九年。九年的时光，那已足够了！我们一起快快乐乐的渡过九年，就算她要陪着我死，那时候再死不好么？” </p><p>忽然想起：“我说‘快快乐乐’，这九年之中，我是不是真的会快快乐乐？二妹知道我一直喜欢袁姑娘，虽然发觉她是个尼姑，但思念之情，并不稍减。那么她今日宁可一死，是不是为此呢？” </p><p>在那无边无际的黑暗之中，心中思潮起伏，想起了许许多多事情。程灵素的一言一语，一颦一笑，当时漫不在意，此刻追忆起来，其中所含的柔情密意，才清清楚楚的显现出来。<br>    小妹子对情郎——恩情深，<br>    你莫负了妹子——一段情，<br>    你见了她面时——要待她好，<br>    你不见她面时——天天要十七八遍挂在心！<br>    王铁匠那首情歌，似乎又在耳边缠绕，“我要待她好，可是……可是……她已经死了。她活着的时候，我没待她好，我天天十七八遍挂在心上的，是另一个姑娘。” </p><p>天渐渐亮了，阳光从窗中射进来照在身上，胡斐却只感到寒冷，寒冷……<br>    终于，他觉到身上的肌肉柔软起来，手臂可以微微抬一下了，大腿可以动一下了。他双手撑地，慢慢站起，深情无限的望着程灵素。突然之间，胸中热血沸腾。“我活在这世上还有什么意思？二妹对我这么多情，我却如此薄幸的待她！不如跟她一齐死了！” </p><p>但一瞥眼看到慕容景岳和薛鹊的尸身，立时想起：“爹娘的大仇还没报，害死二妹的石万嗔还活在世上。我这么轻生一死，什么都撒手不管，岂是大丈夫的行径？”<br>    却原来，程灵素在临死之时，这件事也料到了。她将七心海棠蜡烛换了一枝细身的，毒药份量较轻的，她不要石万嗔当场便死，要胡斐慢慢的去找他报仇。石万嗔眼睛瞎了，胡斐便永远不会再吃他亏。她临死时对胡斐说道，害死他父母的毒药，多半是石万嗔配制的。那或许是实情，或许只是猜测，但这足够叫他记着父母之仇，使他不致于一时冲动，自杀殉情。<br>    她什么都料到了，只是，她有一件事没料到。胡斐还是没遵照她的约法三章，在她危急之际，仍出手和敌人动武，终致身中剧毒。<br>    又或许，这也是在她意料之中。她知道胡斐并没爱她，更没有像自己爱他一般深切的爱着自己，但他仁厚侠义，真心待自己好，自己遭到危难之时，他必不顾性命的来救。不如就这样了结。用情郎身上的毒血，毒死了自己，救了情郎的性命。 </p><p>很凄凉，很伤心，可是乾净利落，一了百了，那正不愧为“毒手药王”的弟子，不愧为天下第一毒物“七心海棠”的主人。<br>    少女的心事本来是极难捉摸的，像程灵素那样的少女，更加永远没人能猜得透到底她心中在想些什么。<br>    突然之间，胡斐明白了一件事：“为什么前天晚上在陶然亭畔，陈总舵主祭奠墓中那个姑娘时，竟哭得那么伤心？”原来，当你想到最亲爱的人永远不能再见面时，不由得你不哭，不由得你不哭得这么伤心。 </p><p>他将程灵素和马春花的尸身搬到破庙后院。心想：“两人的尸身上都沾着剧毒，须得小心，别沾上了。我还没报仇，可死不得！”生起柴火，分别将两人火化了。他心中空空洞洞，似乎自己的身子也随着火焰成烟成灰，随手在地下掘了个大坑，把慕容景岳和薛鹊夫妇葬了。 </p><p>眼见日光西斜，程灵素和马春花尸骨成灰，在庙中找了两个小小瓦坛，将两人的骨灰分别收入坛内，心想：“我去将二妹的骨灰葬在我爹娘坟旁，她虽不是我亲妹子，但她如此待我，岂不比亲骨肉还亲么？马姑娘的骨灰，要带去湖北广水，葬在徐大哥墓旁。”回到厢房，见程灵素的衣服包裹兀自放在桌上，凝目良久，忍不住又掉下泪来。 </p><p>只听得她咳了好半晌，才渐渐止了，轻轻的道：“倘若当年我不是在师父跟前立下重誓，终身伴着你浪迹天涯，行侠仗义，岂不是好？胡大哥，你心中难过。但你知不知道，我可比你更伤心十倍啊？”抚着墓碑，低声道：“在那湘妃庙里，你抱住了我，怎么又放开我？……你如不放开我，此刻我不是便在你身边？那晚只要你不放开，便永远不放开了……” </p><p>圆性转过头来，向他看了一眼，心中在说：“我何尝不知该当好好休养，若不是为了你，我何必鞍马劳顿，连夜奔波？”问道：“程家妹子呢？怎么不见她啊？”胡斐泪盈于眶，颤声道：“她……她已去世了。”圆性大惊，站了起来，道：“怎……怎么……去世了？”胡斐道：“你坐下，慢慢听我说。”将自己如何中了石万嗔的剧毒、程灵素如何舍身相救等情一一说了。圆性黯然垂泪。良久良久，两人相对无语，回思程灵素的侠骨柔肠，都是难以自已。<br>    一阵秋风吹来，寒意侵袭，圆性轻轻打了个颤。胡斐脱下身上长袍，披在她的身上，低声道：“你睡一忽儿吧。”圆性道：“不，我不睡。我是赶来跟你说一句话，这……这便要去。”胡斐惊道：“你到那里去？”<br>    圆性凝望着他，轻轻道：“借如生死别，安得长苦悲？”<br>    胡斐听了这两句话，不由得痴了，跟着低声念道：“借如生死别，安得长苦悲？” </p><p>胡斐低声道：“我向东冲出，引开众人，你快往西去。那匹白马系在松树上。”圆性道：“白马是你的，不是我的。”胡斐道：“这当儿还分什么你的、我的！我的命也是你的。我不用照顾你，管教能够突围。”圆性听他说“我的命也是你的”，心里一甜，也想跟着说一句“我的命也是你的”，突然间想到刚逝世的程灵素，终于硬生生忍住，说道：“我不用你照顾，你这就去罢。” </p><p>倘若依了胡斐的计议，一个乘白马奔驰如风，一个持勇力当者披靡，未始不能脱险。可是圆性不愿意，其实在胡斐心中，也是不愿意。也许，两人决计不愿在这生死关头分开；也许，两人早就心中悲苦，觉得还是死了乾净。 </p><p>。<br>    圆性见胡斐挖坑埋葬程灵素的骨灰，心想自己与他立时也便身归黄土，当下悄悄跪倒，忍住背上疼痛，合什为礼，轻轻诵经。<br>    胡斐左肩的伤痛越来越厉害，两只手渐渐挖深，一转头，瞥见圆性合什下跪，神态庄严肃穆，忽感喜慰：“她潜心皈佛，我何苦勉强要她还俗？幸亏她没应允，否则她临死之时，心中不得平安。” </p><p>胡斐弹刀清啸，心中感慨，还刀入鞘，将宝刀放回土坑之中，使它长伴父亲于地下，再将程灵素的骨灰坛也轻轻放入土坑，拨土掩好。他取出金创药为圆性敷上伤口，给她包扎好，说道：“从今以后，你跟着我再也不离开了！”<br>    圆性含泪道：“胡大哥，不成的……我见到你是我命苦，不见你，我仍然命苦……”她跪倒在地，双手合什，轻念佛偈：<br>    一切恩爱会，无常难得久。<br>    生世多畏惧，命危于晨露。<br>    由爱故生忧，由爱故生怖。<br>    若离于爱者，无忧亦无怖。<br>    念偈时泪如雨下，念毕，悄然上马，缓步西去。胡斐牵过骆冰所赠的白马，快步追将上去，说道：“你骑了这马去吧。你身上有伤，还是……还是……”圆性摇摇头，纵马便行。<br>    胡斐望着她背影，那八句佛偈，在耳际心头不住盘旋。<br>    他身旁那匹白马望着圆性渐行渐远，不由得纵声悲嘶，不明白旧主人为什么竟不转过头来。 </p><p>​    胡斐见她背影渐小，即将隐没，突然之间，耳畔似乎又响起了王铁匠的情歌：<br>​    你不见她面时，天天要十七八遍挂在心！<br>​    “袁姑娘，二妹，连同我三个儿，我们又没做坏事，为什么都这样苦恼？难道都是天生命苦吗？” </p><p>回头望望父亲坟前程灵素骨灰的埋葬之处，一阵凉风吹来，吹得坟边青草尽皆伏倒。“再过几天，这些青草都变黄了，最后也都死了。它们倒可在这里长伴二妹，我却不能。二妹今年只十八岁。明年我再来看她，她仍是十八岁，我却一年年大了、老了，到最后还不是同这些青草一般？‘无忧亦无怖’有什么好？恩爱会也罢，不是恩爱会也罢，总都是‘无常难得久’！” </p><p>第22章 后记</p><p>​    程灵素身上夸张的成份不多，她是一个可爱、可敬的姑娘，她虽然不太美丽，但我十分喜欢她。她的可爱，不在于她身上的现实主义，而在于她浪漫的、深厚的真情，每次写到她，我都流眼泪的，像对郭襄、程英、阿碧、小昭一样，我都爱她们，但愿读者也爱她们。 </p>]]></content>
    
    
    <categories>
      
      <category>读书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>金庸武侠</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ElasticBF:Elastic Bloom Filter with Hotness Awareness for Boosting Read Performance in Large Key-Value Stores</title>
    <link href="/2022/03/19/%E8%AF%BB%E8%AE%BA%E6%96%87/ElasticBF-2/"/>
    <url>/2022/03/19/%E8%AF%BB%E8%AE%BA%E6%96%87/ElasticBF-2/</url>
    
    <content type="html"><![CDATA[<h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>在论文<a href="https://www.usenix.org/system/files/conference/hotstorage18/hotstorage18-paper-zhang.pdf"><strong>ElasticBF: Fine-grained and Elastic Bloom Filter Towards Efficient Read for LSM-tree-based KV Stores</strong></a>中，作者认为在基于LSM的KV-Store中，即使是同一Level中的不同SSTable之间也存在访问倾斜。也即有的SSTable访问频率高，而有的SSTable访问频率较低。</p><p>而在论文<a href="https://www.usenix.org/system/files/atc19-li-yongkun.pdf">ElasticBF: Elastic Bloom Filter with Hotness Awareness for Boosting Read Performance in Large Key-Value Stores</a>中，作者进一步认为，在同一SSTable内的不同区域之间也存在访问倾斜。基于数据访问倾斜的特性，在设计Bloom Filter时，可以对hot data分配更大的bits-per-key，来减少FPR，以进一步减少由于FP导致的额外I/O提高KV Store的读性能。</p><p>下面将对该论文的内容进行摘要总结。</p><h2 id="0x10-Motivation"><a href="#0x10-Motivation" class="headerlink" title="0x10 Motivation"></a>0x10 Motivation</h2><p>为了证明不仅SSTable之间存在访问倾斜，而且SSTable内部不同区域之间也存在访问倾斜，作者做了一系列实验进行验证。这些实验关闭了SSTable的Bloom Filter，这样在查找某个key时，只能一层一层的，一个SSTable一个SSTable的进行查找。</p><p>图2展示了不同SSTable的访问频率。可得出如下结论：</p><ol><li>lower level的SSTable访问频率更高，这是因为在执行查找时总是自上而下查找的；</li><li>从曲线的波动情况来看，同一层中不同的SSTable之间的访问频率也有很大的差异，而且这种情况不只发尚在某一层中，而是在每层都普遍存在的，且高层的波动范围更剧烈，这说明越高的level，其数据冷热差异越明显；</li></ol><p>第二点结论也说明Moneky论文提出的单纯基于level来确定Bloom Filter的bits-per-key，以利用数据倾斜，是不够合理的。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F2.png" alt="image-20220318202320399"></p><p>为了进一步利用顺序写的带宽优势，SSTable的大小有可能会进一步增加，例如RocksDB的SSTable达到了64MB。因此，SSTable内部的访问倾斜可能也很严重。</p><p>记录每个KV对的访问频率对内存和CPU来讲都是很大的开销，因此本文在进行实验验证时将64MB的SSTable划分为64个区域，每个区域1MB，仅记录每个区域的访问频率。</p><p>图3展示了同一SSTable中所有区域的最大和最小访问频率之差与其平均访问频率之比。可以看到，在很多的SSTable中，此比值是非常大的。这也意味着，即使是在同一SSTable中，不同区域之间也存在很严重的访问倾斜。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F3.png" alt="image-20220318210059442"></p><p>因此，可以通过调整Bloom Filter，根据SSTable或者SSTable的区域的热度来调整bits-per-key，在不增加额外内存空间的基础上减少FPR。</p><h2 id="0x20-Design"><a href="#0x20-Design" class="headerlink" title="0x20 Design"></a>0x20 Design</h2><p>ElasticBF的架构图如图4所示，包括三个部分：</p><ul><li>fine-grained Bloom filter allocation；</li><li> hotness identification and inheritance；</li><li>Bloom filter management in memory；</li></ul><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F4.png" alt="image-20220318212024736"></p><h3 id="0x21-Fine-grained-Bloom-Filter-Allocation"><a href="#0x21-Fine-grained-Bloom-Filter-Allocation" class="headerlink" title="0x21 Fine-grained Bloom Filter Allocation"></a>0x21 Fine-grained Bloom Filter Allocation</h3><p>可以通过减少Bloom Filter 的FP所造成的额外I/O来提高KV Store的读性能。下面将分析如何为SSTable构建多个Bloom Filter，并根据热度动态调整Bloom Filter以减少FP。</p><h4 id="Construction-of-multiple-Bloom-filters"><a href="#Construction-of-multiple-Bloom-filters" class="headerlink" title="Construction of multiple Bloom filters"></a>Construction of multiple Bloom filters</h4><p>ElasticBF为每个SSTable生成多个具有较少bits-per-key的Bloom Filter，每个Bloom Filter采用不同且独立的哈希函数。Elastic将每个Bloom Filter称为filter unit，单个SSTable的所有filter unit构成一个filter group，如图5所示。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F.png" alt="image-20220318213054052"></p><p>一个Filter Group的FPR等于具有相同bits-per-key的单个Bloom Filter（$(0.618^{b/n})^n = 0.618^b$）。</p><h4 id="Finer-grained-design-with-chunking"><a href="#Finer-grained-design-with-chunking" class="headerlink" title="Finer-grained design with chunking"></a>Finer-grained design with chunking</h4><p>前面提到，即使是在同一SSTable中也存在很严重的访问倾斜，因此可以通过进一步区分同一SSTable中不同key的访问热度来减少FP。但是记录每个key的热度会带来很大的CPU和内存开销。权衡之下，将每个SSTable划分为多个区域，每个区域称为segment，以segment的粒度来计算访问热度。如图7所示，每个segment分配一组filter unit。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F7.png" alt="image-20220318214244025"></p><p>需要注意的是，segment的大小设置很重要，过于大了体现不出热度区分，过于小了开销太大。</p><h3 id="0x22-Hotness-Identification-and-Inheritance"><a href="#0x22-Hotness-Identification-and-Inheritance" class="headerlink" title="0x22 Hotness Identification and Inheritance"></a>0x22 Hotness Identification and Inheritance</h3><h4 id="Hotness-identification"><a href="#Hotness-identification" class="headerlink" title="Hotness identification"></a>Hotness identification</h4><p>segment的热度主要由其访问频率和自上次访问以来的持续时间所决定。</p><p>文章提出了一个expiring policy策略来区分segment的cold或hot。该策略表述如下。</p><p>维持一个名为currentTime的全局变量，代表整个KV Store的Get请求次数。每个Segment关联一个expiredTime，表示其被「expired」的时间。$expiredTime = lastAccessedTime + lifeTime$，lastAccessedTime表示其上次被访问的时间，lifeTime是个固定值。每当一个segment被访问时，currentTime加1，并更新该segment的lastAccessedTime，进而更新其expiredTime。</p><p>当currentTime超过一个segment的expiredTime时，该segment被标记为「expired」。也就是，当一个segment在最近的lifeTime次请求中没有被访问时，其被标记为「expired」，也即认为该segment的cold的。</p><h4 id="Hotness-inheritance-after-compaction"><a href="#Hotness-inheritance-after-compaction" class="headerlink" title="Hotness inheritance after compaction"></a>Hotness inheritance after compaction</h4><p>Compaction操作会对SSTable执行归并排序生成新的SSTable。因此，如何对新的SSTable中的Segment热度进行初始化是个很重要的问题。</p><p>Elastic使用旧的segment的热度来估计新的segmented热度，其计算方法如图8所示。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F8.png" alt="image-20220318220340377"></p><h3 id="0x23-Bloom-Filter-Management-in-Memory"><a href="#0x23-Bloom-Filter-Management-in-Memory" class="headerlink" title="0x23 Bloom Filter Management in Memory"></a>0x23 Bloom Filter Management in Memory</h3><p>本小节描述如何管理segment的filter unit。</p><h4 id="Bloom-filter-adjusting-rule"><a href="#Bloom-filter-adjusting-rule" class="headerlink" title="Bloom filter adjusting rule"></a>Bloom filter adjusting rule</h4><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-M1.png" alt="image-20220318220706788"></p><ul><li>E[Extra IO]表示由于FP所导致的预计额外IO次数，来指导Bloom Filter的调整；</li><li>M表示KV Store的总segment数量；</li><li>$f_i$表示segment $i$的访问频率；</li><li>$r_i$表示segment $i$的FPR；</li></ul><p>当一个segment被访问时，更新其访问频率和E[Extra IO]。检查是否可以通过enable某个segment的filter unit并disable其他某个segment的filter unit，在不增加内存占用的情况下减少E[Extra IO]，若可行，则应用该调整。</p><h4 id="Realizing-dynamic-adjustment-with-Multi-Queue"><a href="#Realizing-dynamic-adjustment-with-Multi-Queue" class="headerlink" title="Realizing dynamic adjustment with Multi-Queue"></a>Realizing dynamic adjustment with Multi-Queue</h4><p>如图9所示，ElasticBF在内存中维持一个LRU队列来管理每个segment的元数据。将这些队列依次命名为$Q_0,…Q_n$，其中n表示每个segment可以分配的filter unit数量上限，$Q_i$表示该队列中的segment有$i$个enabled filter unit。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic2-F9.png" alt="image-20220318221906124"></p><p>查找哪个filter unit应该被disable的步骤如下：</p><ul><li>首先，从$Q_m$到$Q_1$查找「expired」segment；</li><li>然后再从每个队列的LRU侧向MRU侧查找；</li><li>找到「expired」segment后检查是否可以通过disable它的filter unit来减少E[Extra IO]，若可行则释放它的一个filter unit，并将其降到下一层队列中；</li></ul>]]></content>
    
    
    <categories>
      
      <category>Key-Value Store</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Key-Value Store</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ElasticBF:Fine-grained and Elastic Bloom Filter Towards Efficient Read for LSM-tree-based KV Stores</title>
    <link href="/2022/03/16/%E8%AF%BB%E8%AE%BA%E6%96%87/ElasticBF/"/>
    <url>/2022/03/16/%E8%AF%BB%E8%AE%BA%E6%96%87/ElasticBF/</url>
    
    <content type="html"><![CDATA[<h2 id="0x10-Background"><a href="#0x10-Background" class="headerlink" title="0x10 Background"></a>0x10 Background</h2><p>在键值数据库中，Bloom Filter通常用来减少读操作中的I/O次数。在LevelDB中，每个SSTable都有一个关联的Bloom Filter。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/ElasticBF-F2.png" alt="image-20220315201539916"></p><p>图2展示了两种不同的工作负载下的文件访问频率。</p><p>可以看到，随着Level的增加，文件的访问频率在降低，因为越高的Level拥有越多的SSTable，访问的SSTable也会增加。</p><p>因此，lower level的SSTable相比heigher level的SSTable需要更低的误报率（False Positive Rate，FPR）。</p><p><a href="https://stratos.seas.harvard.edu/files/stratos/files/monkeykeyvaluestore.pdf">Monkey</a>通过在lower level上为每个Bloom Filter增加更多的bits-per-key来最大化均匀数据分布下的读操作吞吐量。但是，该论文指出，即使是在同一Level中，SSTable的访问频率不一致也是非常普遍的，显然Monkey并没有考虑这种同一Level中的数据访问倾斜。</p><p>因此，从访问局部性的角度来看，为同一Level中不同SSTable的Bloom Filter分配相同的bits-per-key显然不是有效的做法。</p><p>所以，对Hot-SSTable的Bloom Filter分配更多的bits-per-key，并对Cold-SSTable的Bloom Filter减少bits-per-key，可以在占用相同内存空间的情况下减少FPR。</p><h2 id="0x20-ElasticBF"><a href="#0x20-ElasticBF" class="headerlink" title="0x20 ElasticBF"></a>0x20 ElasticBF</h2><h3 id="0x21-Main-Idea"><a href="#0x21-Main-Idea" class="headerlink" title="0x21 Main Idea"></a>0x21 Main Idea</h3><p>Hot-SSTable的数量要远小于Cold-SSTable的数量，因此，可以通过增加Hot-SSTable对应的BF的bits-per-key来减少FP，进而减少由于FP所带来的额外I/O数。</p><p>同时，还可以通过减少Cold-SSTable的BF的bits-per-key来控制整体BF所占用的内存空间。</p><p>问题在于，为每个Filter所分配的bits-per-key是固定大小的，且一旦生成Filter便无法再对其进行调整。因此，无法在运行时态去动态调整Filter的bits-per-key。</p><p>为了解决以上问题，该论文选择在构建每个SSTable时为其分配多个Filter，每个Filter为其分配较少的bits-per-key，将其称为Filter Unit。可以通过使一些Filter Unit生效并将其加载到内存中，或关闭部分Filter unit并将其移出内存，来动态调整每个SSTable的Filter数量（也可以说成调整Filter大小）。</p><p>通过这种方法，能够弹性的去动态调整bits-per-key或着说是FPR，该论文将该实现称为ElasticBF。</p><p>在ElasticBF中，每个SSTable在初始化是为其分配多个Filter Unit，每个Filter Unit采用不同的哈希函数，Filter Unit按顺序放在SSTable的元数据区域。一个SSTable的所有Filter Unit合称为一个Filter Group。</p><p>ElasticBF的结构如图3所示。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic-F3.png" alt="image-20220315215434714"></p><p>因为在一个Filter Group中的所有Filter Unit是相互独立的，因此在查询key时，只要有一个Filter Unit指示不存在此key，便能确定所属SSTable不含此key。只有当所有的Filter Unit都指示可能包含时才会进一步查询。</p><p>假设每个Filter Unit是一个具有b/n bits-per-key的过滤器，所以他的FPR可以表示为$0.618^{b/n}$ ，又因为各个Filter Unit是相互独立的，所以一个具有n个Filter Unit的Filter Group的FPR为$(0.618^{b/n})^n = 0.618^b$。</p><p>所以，我们可以得出结论，一个总共具有b bits-per-key的Filter Group与具有b bits-per-key的单个Filter Bloom有相同的FPR。</p><p>将ElasticBF部署在KV Store 中主要有两个挑战：</p><ul><li><ol><li>如何设计一个调整规则来为每个SSTable选择合适的Filter Unit数量；</li></ol></li><li><ol start="2"><li>如何以较小的开销实现动态调整；</li></ol></li></ul><h3 id="0x22-Adjusting-Rule"><a href="#0x22-Adjusting-Rule" class="headerlink" title="0x22 Adjusting Rule"></a>0x22 Adjusting Rule</h3><p>为SSTable调整Bloom Filter的目标是减少FP（False Positive）所带来的额外I/O开销。因此该论文文使用一个Metric来指导调整Filter Unit，该Metric被定义为FP所带来的预计I/O次数，也即E[Extra_IO]，具体可表示为：</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic-M1.png" alt="image-20220316084351908"></p><ul><li>n 表示KV Store中的SSTable总数量；</li><li>$f_i$表示SSTable i的访问频率；</li><li>$fp_i$表示FPR，它由SSTable i被加载到内存中的Filter Unit的数量所决定；</li></ul><p>ElasticBF仅当在不多占用内存空间且可以减少E[Extra_IO]时才会去为每个SSTable调整其Filter Unit数量。</p><p>在使用相同大小的Bloom Filter时，访问频率较高的SSTable贡献了更多的E[Extra_IO]。因此在固定内存空间大小的情况下减少E[Extra_IO]就需要为Hot-SSTable分配更多的Filter Unit。</p><p>调整BF的步骤如下：</p><ol><li>当一个SSTable被访问时，将他的访问频率加1，并更新E[Extra_IO]；</li><li>检查是否可以通过enable此SSTable的Filter Unit数量，并disable其他SSTable同等数量Filter Unit的前提下减少E[Extra_IO]，也即在不增加内存空间的情况下通过合理调整不同SSTable的Filter Unit数量来减少I/O开销；</li></ol><p>然而这又带来了新的问题，也即如何在不增加开销的情况下快速寻找哪些Filter Unit可以被disable。</p><h3 id="0x23-Dynamic-Adjustment-with-MQ"><a href="#0x23-Dynamic-Adjustment-with-MQ" class="headerlink" title="0x23 Dynamic Adjustment with MQ"></a>0x23 Dynamic Adjustment with MQ</h3><p>如图4所示，该论文维护了多个LRU（Least-Recently-Used）队列来管理每个SSTable的元数据，这些队列被依次命名为$Q_0,…, Q_m$，m是SSTable被分配的Filter Unit数量上限。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/Elastic-F4.png" alt="image-20220316192852860"></p><p>需要注意的是，Filter Group中的所有Filter Unit和SSTable中的其他数据都存储在磁盘中，但并不是所有的Filter Unit都是enable的，只有enabled的Filter Unit才会被用于执行key-existence检查。</p><p>LRU队列中的每个元素都与一个SSTable关联，并记录了该SSTable的元数据，其中就包含其驻于内存中的enabled filter units。$Q_i$管理enabled filter unit的数量为$i$的SSTable，例如$Q_2$中的每个SSTable都有两个enabled filter unit。</p><p>为了确定哪个filter unit应该被disable并将其移出内存，本文采用了一个「expiring」策略。该策略将MQ中的每个item都与一个名为expiredTime的变量关联，该变量表示相应的SSTable应该变为expired，并需要选择一个SSTable来调整其BF的时间点。</p><p>具体来讲，$expiredTime = currentTime + lifeTime$，其中$currentTime$表示到目前为止KV Store的$Get$请求总数，$lifeTime$是一个固定值（实践表明ElasticBF对其取值并不敏感）。</p><p>根据以上定义，当一个SSTable被插入到一个队列时，其$expiredTime$被初始化为$currentTime+lifeTime$。并且，每当读到该SSTable时，其$expiredTime$值都会根据当前的$currentTime$值进行更新。</p><p>当$currentTime$大于某个SSTable的$expiredTime$时，其被标记为expired，这意味在其$liftTime$期间未被访问，此时该SSTable被视为Cold-SSTable，并且将会disable它的部分Filter Unit。</p><p>对于每次访问，我们根据原始的MQ算法来寻找「expired」SStable。为了避免「expired」SSTabkle仍然有大量的enabled filter unit，我们将会垂直按照$Q_m$到$Q_1$，水平按照从LRU到MRU的顺序来查找「expired」 SSTable。当找到一个「expired」SSTable后将会disable它的一个Filter Unit，并将其移到下一层的队列中。重复以上步骤，直到找到足够的内存空间来将Hot-SSTable的Filter Unit加载到内存。若是找不到足够的内存空间则跳过此次调整。</p>]]></content>
    
    
    <categories>
      
      <category>Key-Value Store</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Key-Value Store</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>REMIX:Efficient Range Query for LSM-trees</title>
    <link href="/2021/12/15/%E8%AF%BB%E8%AE%BA%E6%96%87/REMIX:%20Efficient%20Range%20Query%20for%20LSM-trees/"/>
    <url>/2021/12/15/%E8%AF%BB%E8%AE%BA%E6%96%87/REMIX:%20Efficient%20Range%20Query%20for%20LSM-trees/</url>
    
    <content type="html"><![CDATA[<h2 id="0x00-Introduction"><a href="#0x00-Introduction" class="headerlink" title="0x00 Introduction"></a>0x00 Introduction</h2><p>LSM树在内存中缓存数据的更新，并周期性的将它们刷新到磁盘上，生成不可变的table文件，完成数据持久化。但是这也降低了查询效率，因为一个range中的key可能在不同的table文件中，并且由于较高的计算和I/O成本，这可能会潜在的降低查询速度。</p><p>学术界针对此问题已经做了大量工作来加快查询性能。为了加快点查询，每个table文件通常都与内存中的一个布隆过滤器相关联，以此来跳过不含目标key的table文件。但是布隆过滤器不能处理范围查询。</p><p>为了限制查询请求不得不访问的table数量，LSM树会在后台运行一个Compaction线程来不断对table进行归并排序。其中table的选择由Compaction策略来决定。</p><h4 id="Leveled-Compaction"><a href="#Leveled-Compaction" class="headerlink" title="Leveled Compaction"></a>Leveled Compaction</h4><p>Leveled Compaction策略被包括LevelDB和RocksDB在内的大量KV-Store使用。Leveled Compaction将多个较小的有序run归并排序为一个较大的有序run，以保证存在重叠的table文件数量小于指定的阈值。Leveled Compaction通过如上策略提供了较高的读效率，但因为其密集的归并排序策略，这也带来了比较高的「写放大」（Write Amplification，WA）。</p><h4 id="Tiered-Compaction"><a href="#Tiered-Compaction" class="headerlink" title="Tiered Compaction"></a>Tiered Compaction</h4><p>Tiered Compaction压缩策略等待多个大小相似的有序run，将它们合并为一个更大的run。其提供了更低的WA和更高的吞吐量，被Cassandra和ScyllaDB等KV-Store使用。但是Tiered Compaction不能有效降低存在key重叠的table数量，与Leveled Compaction相比这会带来更高的查询成本。</p><h4 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h4><p>其他的一些压缩策略虽然能比较好的平衡读写性能，但都没能同时实现高效的读写性能。</p><p>主要问题在于，为了限制有序run的数量，KV-Store必须进行归并排序和重写数据。<strong>现在的存储技术已经大大提高了随机读的性能。</strong>例如，对于Flash SSD来说，随机读的速度能达到顺序读速度的50%。例如3D-XPoint等新技术，为随机读和顺序读提供了几乎相同的性能。<strong>因此，KV-pairs不需要为了快速访问而进行物理排序；相反，KV-Store可以通过逻辑排序来提供高效的点查询和范围查询，以避免大量的重写操作。</strong></p><p>为此，本文设计了REMIX（Range-query-Efficient Multi-table Index）。传统的解决方案为了提高range query效率而在物理数据重写和昂贵的归并排序之间挣扎，而REMIX利用了节省空间的数据结构来记录跨多个table文件的全局排序视图。通过使用REMIXes，LSM-KVS可以在不牺牲查询性能的前提下，使用具有高写效率的压缩策略。</p><h2 id="0x10-Background"><a href="#0x10-Background" class="headerlink" title="0x10 Background"></a>0x10 Background</h2><p>LSM树是为了在持久化存储设备上实现高效的写速率而设计的。它将所有的更新缓存在内存中一个称为MemTable的数据结构中，以此来实现高效的写性能。</p><ul><li>minor compaction：当MemTable写满后，LSM树会通过minor compaction操作将缓存的所有key进行排序，并将其作为一个run刷新（flush）到持久化的存储设备上。此操作不需要对存储设备上的现有数据进行合并，只需要批量顺序写入，因此实现了高效写性能；</li><li>major compaction：有序的run之间可能会存在重叠的key范围，这时一个点查询（point query）就不得不去检查所有可能的run，这带来了较大的查询开销。为了限制存在重叠的run的数量，LSM树通过major compaction操作将几个存在重叠的run归并排序为一个run。</li></ul><p>压缩策略（compaction strategy）决定了如何选择table进行major compaction。最流行的两种压缩策略是leveled compaction和tiered compaction：</p><p><strong>leveled compaction</strong> ：</p><p>使用此方法的数据库具有多层的结构，每层都维持一个由一个或多个table组成的有序run。其中某一个Level $L_n$的容量是其前一个Level $L_{n-1}$的几倍（通常是10），这使得一个庞大的KV-store被组织为仅有几个Level组成（通常是5～7个）。Leveled Compaction带来了相对高效的读性能，但也会造成写性能较差。Leveled Compaction从相邻的Level（例如$L_n$和$L_{n+1}$）中选择重叠的table进行合并，并在较大的Level（例如$L_{n+1}$）中生成新的table。因为不同Level之间的容量呈指数级增长，因此一个table的键范围通常与下一个Level的多个table重叠。因此大多数写操作是在$L_{n+1}$中重写已有的数据，这在实践中导致了高达40倍的高「写放大比」（write amplification ratio， WA ratio，即实际写入磁盘的数据量与用户请求写入的数据量的比值）。</p><p>图1展示了一个Leveled Compaction的例子，每个table包含1～2个key。如果$L_1$中的第一个table被选择与$L_2$中的前两个table进行归并排序，那么$L_2$中的5个key将被重写（也即<code>table(4,21,38)</code>要与<code>table(6,26)</code>和<code>table(31,40,46)</code>进行归并排序，此时$L_2$两个table中的5个key都需要重写）。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_1.png" alt="image-20211213113120768"></p><p><strong>tired compaction</strong>:</p><p>如图2所示，在使用tired compaction的LSM树中，<strong>在一个level中可以缓存多个存在重叠的有序run</strong>。通常，一个level中run的数量会通过一个阈值$T$来限制（$T&gt;1$）。如果在一个level（例如$L_n$）中的有序run的数量超过阈值$T$，那么**$L_n$中的所有run会被归并排序为$L_{n+1}$中的一个新的run，$L_{n+1}$中的数据不会被重写**。因此，在使用tired compaction的LSM树中，写放大比为$O(L)$，其中$L$是level的数量。但是，由于在每个level中可能会有多个重叠的有序run，一个点查询（point query）可能会需要去检查$T\times L$个table，这也导致了更低的查询性能。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_2.png" alt="image-20211213143711989"></p><p>LevelDB和RocksDB中的范围查询是通过使用一个迭代器结构在多个table中导航实现的，就好像所有的key都在一个有序run中。一个范围查询首先会使用带有搜索键（seek key，也即目标key范围的下边界）的搜索操作（seek operation）来初始化迭代器。「查找操作」首先定位迭代器，使其指向存储中大于等于seek key的最小key，这表示范围查询的目标key。next操作会往前推进迭代器，使其指向有序run中的下一个key。因此，可以使用一系列next操作来检索目标范围内的key，直到满足某个条件（例如达到查询的数量或者到达查询范围的末尾）。由于有序run是按时间顺序生成的，因此一个目标key可能会在任何一个run中，相应的，迭代器必须追踪所有的有序run。</p><p>图1展示了一个使用leveled compaction的LSM树的查找示例。为了查找key 67，需要在每个run中使用二分查找来识别满足$key \geq seek,key$的最小key。每个识别的key都用一个光标（cursor）来标记。然后使用最小堆结果来对这些键进行归并排序，从而选择$L_2$中的key 67。随后，每个next操作都会比较光标标记下的key，返回其中最小的一个key，然后向前移动其对应的光标。如图1右上角所示，此过程会呈现key的全局排序视图。在图1的例子中，所有的3个level都会被访问以进行归并排序。图2使用的是tired compaction，但查询过程类似，不过在这个例子中有6个run需要被访问，其查找代价相对更大。</p><h2 id="0x20-REMIX"><a href="#0x20-REMIX" class="headerlink" title="0x20 REMIX"></a>0x20 REMIX</h2><p>对多个有序run的范围查询会动态构建底层table的排序视图，以便可以按照排序顺序来检索key。事实上，排序视图继承了table文件的不变性，并会在任何table被删除或替代前保持有效。然而现有的基于LSM的KV-Store并没有利用这种不变性的特点，排序视图会在查询时反复重建和丢弃，这会带来密集的计算和I/O操作并导致较差的查找性能。</p><p>REMIX的动机是利用table文件的不变性，保留底层table文件的排序视图，以在将来的查询操作中重用它们。</p><p>如果记录每个key及其位置来保留排序视图，则存储的元数据可能会显著膨胀，从而导致读写性能受损。因此，为了避免这个问题，REMIX的数据结构必须是空间高效的。</p><h3 id="0x21-The-REMIX-Data-Structure"><a href="#0x21-The-REMIX-Data-Structure" class="headerlink" title="0x21 The REMIX Data Structure"></a>0x21 The REMIX Data Structure</h3><p>图3上部展示了一个由三个run组成的排序视图的示例，排序视图用向量将15个key连接起来。</p><p>为了构建一个REMIX，首先将排序视图的key划分到多个segment中，每个segment都包含固定数量的key。</p><p>每个segment都与一个<code>anchor key</code>，一组<code>cursor offset</code>以及一组<code>run selectors</code>关联。其中：</p><ul><li>anchor key：表示segment中的最小key；</li><li>cursors offsets：所有cursor共同组成了排序视图上的稀疏索引，每个cursor offset都与一个run对应，并记录了此run中大于等于anchor key的最小key；</li><li>run selectors：segment中的每个key都有一个对应的run selector，run selector用来指示对应的key位于哪个run上；</li></ul><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_3.png" alt="image-20211213163458320"></p><p>REMIX的迭代器不使用最小堆。在REMIX中，一个迭代器包含「一组cursor」和「一个current pointer」。</p><ul><li>cursors：每个cursor都与一个run相关联，并指向该run中一个key的位置。</li><li>current pointer：选择并指向一个run selector，该run的cursor决定了此时到达的key；</li></ul><p>在REMIX中，使用一个迭代器来查找一个key需要三步：</p><ol><li>找到target segment。在anchor keys上执行二分查找，以确定包含seek key的target segment，也即找到满足anchor_key$\leq$seek_key的segment；</li><li>初始化迭代器。将迭代器初始化为指向anchor key。具体来说就是，用target segment的cursor offsets来初始化迭代器的cursors，并将迭代器的current pointer指向target segment的第一个run selector；</li><li>可以通过线性扫描有序视图来查找 target key。为了移动迭代器，将当前key的cursor前进以跳过当前key，同时，current pointer也需要前进以指向下一个run selector；</li></ol><p>来看一个例子。如图3所示，底部的四个方框代表编码了有序视图的REMIX元数据（需要注意的是括号中的key并不是元数据的一部分）。查找key 17的操作如下：</p><ol><li>查找target segment。通过二分查找，第二个segment被选中，其包含的key为<code>(11,17,23,29)</code>。</li><li>初始化迭代器。根据target segment的cursors offset，也即<code>(1,2,1)</code>，将迭代器的cursors放在$R_0$、$R_1$和$R_2$的键11、17和31上；与此同时，将迭代器的current pointer设置为指向target segment的第一个run selector（图中的第5个run selector，也就是第二个segment的第一个run selector，为0，指向的是第一个run），这意味着current key也即key 11在$R_0$的cursor所在的位置。</li><li>current key 11小于17，迭代器需要向前移动，以查找下一个满足$k\geq17$的最小key。为了向前移动迭代器，$R_0$的cursor向前移动跳过key 11，停在key 23上，此时迭代器的cursors offset为<code>(2,2,2)</code>；然后current pointer向前移动到target segment的第二个run selector（图中的第6个run selector，也就是第二个segment的第二个run selector，为1，指向的是第二个run）。重复此操作最终找到目标key。</li></ol><h3 id="0x22-Efficient-Search-in-a-Segment"><a href="#0x22-Efficient-Search-in-a-Segment" class="headerlink" title="0x22 Efficient Search in a Segment"></a>0x22 Efficient Search in a Segment</h3><p>seek操作通过在anchor keys上执行二分查找来定位target segment以初始化迭代器，然后再在有序视图上向前扫描来查找target key。显然，增加segment的大小能减少anchor key的数量，并进一步加速二分查找。但这也会降低查找target key的速度，因为需要在一个更大的target segment上访问更多的key来查找target key。</p><p>为了解决潜在的性能问题，REMIX在target segment中也使用二分查找来最小化查找开销。</p><p>目前为止，使用二分查找的地方有：</p><ul><li>anchor keys之间：在anchor keys上执行二分查找来定位target segment；</li><li>target segment内部：在target segment上执行二分查找来定位target key；</li></ul><p>但是，<strong>要在segment上使用二分查找则必须能随机访问segment中的每个key</strong>。</p><p>由上文可知，segment中的每个key属于一个run，并用run selector指示其所在的run。为了访问一个key，我们需要将run的cursor放在正确的位置上，可以通过计算在「该key之前」并「与其相同的run selector的出现次数」，然后将cursor移动相应的次数来将cursor放置到正确的位置上。通过这种类似数组的访问模式，我们可以实现segment中每个key的随机访问。</p><p>图4展示了一个有16个key的segment，所有的key位于不同的4个run上。Run Selectors下面的Occurrences表示该segment中某个key之前还有多少个key与它位于同一个run中。例如，key 41是该segment中位于$R_3$上的第3个key，也即在key 41之前还有2个key位于$R_3$上（key 5和key 23），所以其Occurrences值为2。要查找访问 key 41，我们只需要初始化$R_3$的cursor offset，然后向前移动两次跳过key 5和key 23即可，这便实现了key 41的随机访问。</p><p>简单记录一个segment中二分查找的过程，还是例如要查找key 41，过程如下：</p><ol><li>第一次执行二分查找。需要检索的是该segment中的第8个key（总共16个key，所以第一次检索第8个key），该key对应的run selector为3，occurrence值为3，然后初始化$R_3$的cursor offset，然后向前移动3次即可访问该key，该key为43。该key不是我们要找的key 41，且大于key 41；</li><li>第二次执行二分查找。由第一次可知，需要在segment中的第1～7个key进行二分查找，因此第二次二分查找需要检索第4个key，该key对应的run selector为2，occurrence为0，初始化$R_2$的cursor offset，向前移动0次即可访问该key，该key为31，仍不是要查找的key。</li><li>第三次执行二分查找。方法同上，本次检索第6个key，仍不是要查找的key。</li><li>第四次执行二分查找。方法同上，本次检索第7个key，是本次查找的target key，查找结束。</li></ol><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_4.png" alt="image-20211214102822250"></p><p>在segment中使用二分查找可以减少查找过程中key比较的次数，但是，查找路径中的key可能位于不同的run上，而若相应的block没有被缓存的话则必须通过独立的I/O请求来读取这些key。例如，我们上面的查找例子中，只需要进行4次二分查找也即需要比较4次，但是需要访问3个run（4次比较中的key位于3个不同的run上）。事实上，很有可能该segment中位于同一个run上的几个key可能在同一个block中，因此，在一次比较完成后，移动到下一个run之前，可以通过比较该run上位于同一个block中的key来进一步缩小查找区间。例如，假设$R_3$中的key 41和key 43位于同一个block中，且我们要查找的target key也是key 43，则第一次需要检索key 41进行比较，比较完成后，在移动到$R_0$上访问Key 71比较之前，可以顺便比较一下与它位于同一block中的key 43，而这个key正好是我们需要的target key，此次访问直接将查找区间缩小到了target key。</p><h3 id="0x23-Search-Efficiency"><a href="#0x23-Search-Efficiency" class="headerlink" title="0x23 Search Efficiency"></a>0x23 Search Efficiency</h3><p>REMIX在以下三个方面改进了范围查询：</p><ul><li>REMIX使用二分查找来定位target key。REMIX提供了一个由多个run组成的全局视图，只需要一个二分查找就可以在该全局视图中定位到target key。</li><li>REMIX移动迭代器时不需要key的比较。REMIX通过使用预先记录的run selector来更新迭代器的cursors和current pointer，可以直接切换到下一个KV对。此过程不需要任何的key比较。相比之下，传统LSM-KVS的迭代器会维护一个最小堆，以对来自多个重叠run的key进行归并排序，在这种情况下，一个next操作需要从多个run中读取key进行比较。</li><li>REMIX会跳过不在查找路径中的run。seek操作会在target segment中执行二分查找，而且在查询时仅会访问那些包含查找路径上的key的run。</li></ul><p>此外，显著降低的查询成本允许在不使用布隆过滤器的情况下对由REMIX索引的多个有序run进行高效的点查询。</p><h3 id="0x24-REMIX-Storage-Cost"><a href="#0x24-REMIX-Storage-Cost" class="headerlink" title="0x24 REMIX Storage Cost"></a>0x24 REMIX Storage Cost</h3><p>REMIX的元数据由三个组件组成：anchor keys、cursor offsets、run selectors。为了对其存储成本进行评估，现给出如下定义：</p><ul><li>$D$表示一个segment中最多能包含的key的数量，因为每个key都有一个对应的run selector，那么run selector的数量相应的也为D；</li><li>$S$表示cursor offset的大小，单位为字节；</li><li>$H$表示被REMIX索引的run的数量；</li><li>$\bar{L}$表示anchor key的平均大小，单位为字节；</li></ul><p>由上面的定义可得：</p><ul><li>$S \times H$ 表示一个segment中所有的cursor offset所占用的空间大小，单位为字节；</li><li>$\left \lceil log_2(H) \right \rceil/8$ 表示一个run selector所占用的空间大小，单位为字节；</li><li>$D \times \left \lceil log_2(H) \right \rceil/8$ 表示一个segment中所有run selector所占用的空间大小，单位为字节；</li></ul><p>那么由上面的定义和推理可得，REMIX中各个组件占用的空间大小为（单位为字节）：</p><ul><li>anchor keys ：$\bar{L}$个字节；</li><li>cursor offsets：$SH$个字节；</li><li>run selectors：$D \times \left \lceil log_2(H) \right \rceil/8$个字节</li></ul><p>将REMIX所占用的总空间大小摊分到每个key上（也即将占用总空间大小除D），则每个key所额外占用的空间大小为：<br>$$<br>(\bar{L}+SH)/D + \left \lceil log_2(H) \right \rceil/8<br>$$<br>表1展示了在不同工作负载（$D$，也即segment中的key数量不同）下的REMIX空间开销。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_T_1.png" alt="image-20211214203246297"></p><h2 id="0x30-RemixDB"><a href="#0x30-RemixDB" class="headerlink" title="0x30 RemixDB"></a>0x30 RemixDB</h2><p>为了评估REMIX的性能，本文设计实现了一个名为RemixDB的LSM-KVS。RemixDB为了实现最好的的读性能而采用了tiered compaction。现实世界中的工作负载通常表现出高空间局部性。最近的研究表明，分区存储布局可以有效降低实际工作负载下的压缩成本。RemixDB采用了这种方法，将key空间划分到多个不重叠的分区中。每个分区中的table文件由一个REMIX进行索引，以提供分区的排序视图。通过这种方式，RemixDB本质上是一个使用tiered compaction的单层LSM树。RemixDB不仅继承了tiered compaction的写效率，而且在REMIXes的帮助下实现了高效读性能。</p><p>图5显示了RemixDB的系统组件。分区中的压缩会创建一个新版本的分区，其中包含新旧table文件和新的REMIX文件，旧版本在压缩后会被垃圾回收。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_5.png" alt="image-20211214210216968"></p><p>在多层LSM树的设计中，一个MemTable的大小通常只有几十MB，接近SSTable的默认大小。而在分区存储布局中，更大的MemTable可以在触发压缩前吸收更多的更新，这能帮助降低WA（写放大，Write Amplification），且MemTable和WAL的空间成本几乎不变，考虑到现在数据中心的大内存和存储，这是适中的。在RemixDB中，MemTable的最大大小被设置为4GB。</p><h3 id="0x31-The-Structures-of-RemixDB-Files"><a href="#0x31-The-Structures-of-RemixDB-Files" class="headerlink" title="0x31 The Structures of RemixDB Files"></a>0x31 The Structures of RemixDB Files</h3><h4 id="Table-Files"><a href="#Table-Files" class="headerlink" title="Table Files"></a>Table Files</h4><p>图6显示了RemixDB中的table文件格式。</p><ul><li>data block的默认大小为4Kb；</li><li>无法存放在一个data block中的大KV对会存放在整数倍的data block中；</li><li>每个data block在其首部都有一个记录KV数据偏移量的数组，以随机访问它所存储的每个KV数据；</li><li>metadata block是由多个8-bit值所组成的数组，每个值记录了一个4KB的block中所存储的key的数量，因此一个block最多可以存储255个KV对；</li></ul><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_6.png" alt="image-20211214212026005"></p><h4 id="REMIX-Files"><a href="#REMIX-Files" class="headerlink" title="REMIX Files"></a>REMIX Files</h4><p>图7显示了RemixDB中的REMIX文件格式。</p><p>REMIX中的anchor keys被组织在一个类似B+树的不可变索引中，这有助于对anchor key进行二分查找。每个anchor key都与一个segment ID相关联，segment ID标识了该segment的cursor offsets和run selectors。cursor offset由16位的block index和8位的key index索引组成，如图7的blk-id和key-id所示。因为每个cursor offset都与一个run对应，所以图7中的每个segment的查找路径中都只有两个run。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_7.png" alt="image-20211214213100203"></p><p>一个key的多个版本可能存在于同一个分区的不同table文件中，范围查询必须跳过旧版本返回每个key的最新版本。因此，在REMIX中，一个key的多个版本在排序视图上从最新到最旧排序，并且每个run selector的最高位被保留以用来区分旧版本和新版本。在前向扫描过程中总是先遇到最新版本，通过检查run selector的最高位可以在不进行比较的情况下跳过旧版本。</p><h3 id="0x32-Compaction"><a href="#0x32-Compaction" class="headerlink" title="0x32 Compaction"></a>0x32 Compaction</h3><p>在每个分区中，压缩进程根据进入分区的「新数据的大小」和「现有table文件的布局」来估计压缩成本，然后根据该成本执行以下不同的操作：</p><ul><li>Abort：取消分区的压缩，并将新数据保留在MemTable和WAL中；</li><li>Minor Compaction：将新数据写入到一个或多个新的table中，而不重写现有的table文件；</li><li>Major Compaction：将新数据与部分或全部现有table文件合并；</li><li>Split Compaction：将新数据与所有现有数据合并，并将分区拆分为几个新分区；</li></ul><h4 id="Abort"><a href="#Abort" class="headerlink" title="Abort"></a>Abort</h4><p>compaction后，任何看到新table文件的分区都需要重建其REMIX。Minor Compaction后会在一个分区中创建一个小的table文件，这会导致REMIX的重建并带来高I/O开销。</p><p>为了减少I/O开销，如果预估的I/O开销大于阈值，RemixDB可以终止分区的压缩。在这种情况下新的KV数据会被继续保留在MemTable和WAL中，等待下一次压缩。</p><p>但是在极端的情况下，当RemixDB终止了大多数分区的压缩时，压缩过程将无法有效的将数据移动到分区中。为了避免这个问题，RemixDB进一步限制可以留在MemTable和WAL中的新数据的大小，如果超过MemTable大小的15%。因此，在达到此限制之前，RemixDB终止具有高I/O开销的压缩过程，达到上限之后不再继续终止，允许压缩。</p><h4 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h4><p>Minor Compaction将Immutable MemTable中的新KV数据写到分区的新table文件中，然后重建REMIX，这个过程不需要重写分区中现有的table文件。当压缩后的Table文件的数量（现有table加上新建table的数量）低于阈值T时，使用Minor Compaction，在RemixDB的实现中T为10。图8显示了一个minor compaction的例子。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_8.png" alt="image-20211215103811139"></p><h4 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h4><p>当分区中的table文件的预期数量超过阈值T时，进行Major Compaction，将现有的table文件归并排序为较少的table文件。随着table文件数量的减少，后面就可以执行minor compaction。Major Compaction的效率可以通过输入table文件的数量和输出table文件的数量之比来估计。</p><p>图9显示了一个Major Compaction的示例，新数据与现有的三个较小的table文件进行合并，合并后只创建了一个新的table文件，此时$ratio=3/1$。Major Compaction会选择可以产生最高输入输出比的方案进行压缩。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_9.png" alt="image-20211215105042707"></p><h4 id="Split-Compaction"><a href="#Split-Compaction" class="headerlink" title="Split Compaction"></a>Split Compaction</h4><p>当分区中充满了large table时，Major Compaction可能无法有效减少分区中的table数量，这可以通过较低的输入输出比来预测。在这种情况下，应该将分区拆分为多个分区，这样每个分区中的table文件数量都能大大减少。Split Compaction会将新数据与分区中的所有现有table文件进行合并，并生成新的table文件以形成多个新分区。图10显示了一个split compaction的例子。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/REMIX_F_10.png" alt="image-20211215105601167"></p><h3 id="0x33-Rebuilding-REMIXes"><a href="#0x33-Rebuilding-REMIXes" class="headerlink" title="0x33 Rebuilding REMIXes"></a>0x33 Rebuilding REMIXes</h3><p>在具有高空间局部性的现实世界工作负载下，分区存储布局可以有效的最小化压缩成本。具体来说，RemixDB可以在少数分区中吸收大部分更新，并且可以避免接受具有较少更新的分区中的压缩。但是，如果工作负载缺少空间局部性，则不可避免的会有大量分区在较少更新的情况下执行压缩。Tiered Compaction可以最大限度的减少这些分区中的写入，但是在分区中重建REMIX仍然需要读取现有的table。</p><p>在分区中重建REMIX时，现有table已经被现有的REMIX索引，并且可以将这些table视为一个有序run，因此，重建过程相当于对两个已排序的run进行归并排序，其中一个来自现有数据，另一个来自新数据。</p>]]></content>
    
    
    <categories>
      
      <category>Key-Value Store</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Key-Value Store</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++字符串输入的使用及混合数字读取可能出现的问题</title>
    <link href="/2021/12/10/C%E5%92%8CC++/C++%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BE%93%E5%85%A5/"/>
    <url>/2021/12/10/C%E5%92%8CC++/C++%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BE%93%E5%85%A5/</url>
    
    <content type="html"><![CDATA[<h2 id="0x00-字符串输入"><a href="#0x00-字符串输入" class="headerlink" title="0x00 字符串输入"></a>0x00 字符串输入</h2><p><code>cin</code>使用空白来确定字符串的结束位置，这意味着<code>cin</code>在获取字符数组输入时只读取一个单词。读取该单词后，<code>cin</code>将该字符串放到数组中，并自动在结尾添加空字符<code>\0</code>。</p><p>注：C风格字符串以空字符结尾，空字符被写作<code>\0</code>，其ASCII码为0，用来标记字符串的结尾。</p><h2 id="0x10-每次读取一行字符串输入"><a href="#0x10-每次读取一行字符串输入" class="headerlink" title="0x10 每次读取一行字符串输入"></a>0x10 每次读取一行字符串输入</h2><p>大多时候，每次读取一个单词不是最好的选择。</p><p>头文件<code>istream</code>中的类（如<code>cin</code>）提供了一些面向「行」的类成员函数：<code>getline()</code>和<code>get()</code>。这两个函数都读取一行输入，直至到达换行符。然而，随后<code>getline()</code>将<strong>丢弃换行符</strong>，而<code>get()</code>将换行符<strong>保留在输入序列</strong>中。</p><h3 id="0x11-面向行的输入：getline"><a href="#0x11-面向行的输入：getline" class="headerlink" title="0x11 面向行的输入：getline()"></a>0x11 面向行的输入：<code>getline()</code></h3><p><code>getline()</code>函数读取整行，它使用通过<strong>回车键输入的换行符</strong>来确定输入结尾。要调用这个函数，可以使用<code>cin.getline()</code>。</p><p>该函数有两个参数：</p><ul><li>第一个参数是用来存储输入行的数组的名称；</li><li>第二个参数是要读取的字符数；</li></ul><p><code>getline()</code>成员函数在读取指定数目的字符或遇到换行符时停止读取。</p><p>例如，在使用该函数将姓名读取到一个包含20个元素的<code>name</code>数组时，可以这样使用: <code>cin.getline(name, 20);</code></p><h3 id="0x12-面向行的输入：get"><a href="#0x12-面向行的输入：get" class="headerlink" title="0x12 面向行的输入：get()"></a>0x12 面向行的输入：<code>get()</code></h3><p>cin类还有一个名为get()的成员函数，该函数有几种变体。</p><p>其中有一种变体的工作方式与getline()类似，它们接受的参数相同，解释参数的方式也一样，并且都读到行尾。但get并不再读取并丢弃换行符，而是将其留在输入队列中。假设我们连续两次使用get()：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs C++">cin.<span class="hljs-built_in">get</span>(name1, len);<br>cin.<span class="hljs-built_in">get</span>(name2, len); <span class="hljs-comment">// 出现问题，上一个get将换行符留在了输入队列，导致此get看到的第一个字符就是换行符，不能继续读取想要读取的内容</span><br></code></pre></td></tr></table></figure><p>由于第一次调用后，将换行符留在了输入队列中，因此第二次调用时看到的第一个字符便是换行符，此时，因为<code>get(name2，len)</code>并不能读取换行符，所以它会认为已经到达行尾了，并没有发现任何可以读取的内容。因此，如果不借助其他帮助，第二次调用将无法跨过换行符来读取内容。</p><p>而get()函数的另一种变体，使用不带任何参数的cin.get()调用可以读取下一字符（可以是换行符）。因此可以使用它来处理换行符。例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C++">cin.<span class="hljs-built_in">get</span>(name1, len);<br>cin.<span class="hljs-built_in">get</span>();  <span class="hljs-comment">// 读取换行符</span><br>cin.<span class="hljs-built_in">get</span>(name2, len); <br></code></pre></td></tr></table></figure><p>另一种方式是将两个类成员函数变体拼接起来，如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs C++">cin.<span class="hljs-built_in">get</span>(name1, len).cin.<span class="hljs-built_in">get</span>(); <span class="hljs-comment">// 读取字符串后继续读取掉换行符</span><br>cin.<span class="hljs-built_in">get</span>(name2, len); <br></code></pre></td></tr></table></figure><p>之所以可以这样使用是因为<code>cin.get(name1, len)</code>返回一个<code>cin</code>对象，该对象可以用来继续调用<code>get()</code>函数。</p><h2 id="0x20-混合输入字符串和数字所带来的问题"><a href="#0x20-混合输入字符串和数字所带来的问题" class="headerlink" title="0x20 混合输入字符串和数字所带来的问题"></a>0x20 混合输入字符串和数字所带来的问题</h2><p>C++中混合输入<strong>面向行的字符串</strong>和<strong>数字</strong>会导致问题。例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">int</span> age;<br><span class="hljs-keyword">char</span> name[<span class="hljs-number">30</span>];<br>cin&gt;&gt;age;<br>cin.<span class="hljs-built_in">getline</span>(name, <span class="hljs-number">30</span>);<br></code></pre></td></tr></table></figure><p>这样使用会导致<code>cin.getline()</code>读取到一个空字符串，原因在于当<code>cin</code>在读取<code>age</code>时会将回车键生成的换行符留在了输入队列，而后面的<code>cin.getline()</code>在看到换行符后，将认为这是一个空行，并将一个空字符串数组赋给<code>name</code>数组。</p><p>解决方法是：在使用<code>cin.getline(name, 30)</code>读取整行字符串之前，先使用<code>cin.get()</code>读取并丢弃换行符。</p>]]></content>
    
    
    <categories>
      
      <category>C/C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
      <tag>编程语言</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AC-Key:Adaptive Caching for LSM-based Key-Value Stores</title>
    <link href="/2021/12/10/%E8%AF%BB%E8%AE%BA%E6%96%87/AC-Key%E2%80%94%E2%80%94Adaptive%20Caching%20for%20LSM-based%20Key-Value%20Stores/"/>
    <url>/2021/12/10/%E8%AF%BB%E8%AE%BA%E6%96%87/AC-Key%E2%80%94%E2%80%94Adaptive%20Caching%20for%20LSM-based%20Key-Value%20Stores/</url>
    
    <content type="html"><![CDATA[<h2 id="0x00-Introduction"><a href="#0x00-Introduction" class="headerlink" title="0x00 Introduction"></a>0x00 Introduction</h2><p>大多数现有的KVS都采用了Log-Structured Merge(LSM) tree来提高写操作的性能，然而LSM的结构特性使得读操作的性能受到了很大的影响。当在多个Level中查找一个key时会引起多次磁盘的I/O操作，带来较大的性能开销。</p><p>而大部分工作负载都有访问局部性的特征，缓存便是利用这一特性来提高读操作性能的主要技术。针对企业级工作负载的研究发现，无论是「point lookup」还是「range query」都展现出了「hot spots」的现象。</p><p>因此，为基于LSM的KV-Store设计高性能的缓存方案主要有两个技术挑战：</p><ul><li>首先，LSM分层的设计使得缓存不同Level的KV数据所带来的收益不同，也即能够节省的磁盘I/O次数不同；</li><li>其次，两种读操作「point lookup」和「range query」对缓存的需求不一致。「Point lookup」更偏向于缓存一个「key-value pair」，这种方式相对节省空间；当value过大时，一种折中的方案是选择缓存「key- pointer pair」，也即缓存「key」和「value的磁盘指针」，指针相对value所占用的空间更小。而缓存单个零星的「key-value pair」无法为「range query」服务，因此只能通过缓存「block」来支持「range query」；</li></ul><p>因此，很难在缓存KV、KP和Block之间进行权衡，它们都有其各自适合的工作负载。此外，设计一种可以根据工作负载进行自适应的缓存方案是困难的。</p><p>现有的缓存方案通常只选择缓存KV、KP和Block中的一种或两种，而且为每种缓存类型都分配了固定大小的缓存空间。因此，这些缓存方案无法适应多样的工作负载，也不能根据工作负载的变化来调整缓存空间的大小。此外，目前还没有针对LSM中特有的异构缓存成本的解决方案。</p><p>本文全面分析研究了对缓存KV、KP和Block之间的权衡，并提出了「 AC-Key, Adaptive Caching for LSM-based Key-Value Stores」来结合它们在面临各种工作负载时的优势。AC-Key为每种类型的条目（KV、KP和Block）都使用专门设计的单独缓存组件。每个缓存组件的大小可以根据文章提出的「 <em>hierarchical adaptive caching</em> algorithm，分层自适应缓存算法」进行调整（使用「ghost cache」来指导其大小调整）。</p><p>此外，AC- Key利用一种新颖的缓存效率因子来评估不同的<strong>缓存成本</strong>和<strong>收益</strong>，以指导<strong>不同缓存组件之间的边界调整</strong>以及<strong>缓存组件内部的替换策略</strong>。</p><h2 id="0x10-Background-amp-Related-work"><a href="#0x10-Background-amp-Related-work" class="headerlink" title="0x10 Background &amp; Related work"></a>0x10 Background &amp; Related work</h2><h3 id="0x11-LSM-Tree-Based-Key-Value-Store"><a href="#0x11-LSM-Tree-Based-Key-Value-Store" class="headerlink" title="0x11 LSM-Tree-Based Key-Value Store"></a>0x11 LSM-Tree-Based Key-Value Store</h3><p>基于LSM tree的Key-Value store（LSM- KVS）的流行实现，例如LevelDB和RocksDB，都由两部分组成：</p><ul><li>Memory Component，或者说MemTable，通常使用原地排序（in-place sorted）的数据结构来实现，例如「skip-list」或「$B^+$ tree」；</li><li>Storage Component，通常被实现为存储有序run（压缩的Key-Value对组成）的多层文件；</li></ul><p>如图1所示，每个Level被划分为多个「sorted string table files」也即SSTs，每个SST都有配置的大小限制，通常为2MB～64MB。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC-Key_F_1.png" alt="image-20211210110007408"></p><p>除了$L_0$之外，每个Level都是一个单独的有序run，其中，SST之间具有不相交的key范围。在有序run中，一个SST的所有key-value对被划分到多个数据块（data block）中。SST中每两个相邻数据块之间的边界key存储在索引数据块（index block）中，索引数据块在SST中有相应的数据块偏移量（data block offset）。此外，每个SST还包含一个「bloom filter block」（BF block，布隆过滤块）来确定SST中是否存在某个key，以避免不必要的磁盘I/O操作。「Block」是LSM- KVS中的基本磁盘I/O单元。</p><p>在LSM-KVS中有两种类型的读操作，分别是「point-lookup」（也即<code>Get</code>）和「range query」（也即<code>Scan</code>）。<code>Get</code>按照下面的顺序来查找指定key的value：先是检查内存中的MemTable，然后是磁盘上$L_0$中从新到旧的每个SST，$L_0$中查找失败则继续查找$L_1$~$L_N$。</p><p>如果在内存MemTable中就找到了要找的key，则不需要任何的磁盘访问就可以返回相应的value。否则，则需要在磁盘组件中查询SST文件。查询SST时会先检查对应的布隆过滤器，如果布隆过滤器指示该SST不存在指定key的话则跳过此SST。反之，则读取索引块来定位key所在的具体数据块，最后读取相应数据块来查找此key。因此，在一个SST中查找一个key最多需要三次磁盘I/O操作：</p><ul><li>第一次读Bloom filter block；</li><li>第二次读Index block；</li><li>第三次读data block；</li></ul><h3 id="0x12-Related-Work"><a href="#0x12-Related-Work" class="headerlink" title="0x12 Related Work"></a>0x12 Related Work</h3><h4 id="a-Caching-Schemes-in-LSM-KVS-LSM-KVS中的缓存方案"><a href="#a-Caching-Schemes-in-LSM-KVS-LSM-KVS中的缓存方案" class="headerlink" title="a. Caching Schemes in LSM-KVS (LSM-KVS中的缓存方案)"></a>a. Caching Schemes in LSM-KVS (LSM-KVS中的缓存方案)</h4><p>如前文所述，在LSM-KVS中有三种类型的条目可以被缓存：KV，KP和Block（如图2所示）。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC.png" alt="image-20211209162834502"></p><p>LevelDB仅采用了「Block Cache」（如图2a所示），这里的「Block」可以是：data block，index block，以及Bloom Filter block。「Block Cache」中的「block」使用<code>SST file ID</code>和<code>block offset</code>（例如，<code>&lt;SstID | BlockOffset&gt;</code>）来索引。「Block Cache」可以同时服务「point lookup」和「range query」。虽然Block Cache也能够服务point lookup，但是空间成本太高，因为只有「Block」中的小部分「key-value」才会被频繁访问。</p><p>RocksDB同时支持<code>Block Cache</code>和<code>KV Cache</code>（如图2b所示）。<code>KV Cache</code>缓存的KV对可以服务于<code>point lookup</code>。但是RocksDB中<code>Block Cache</code>和<code>KV Cache</code>的缓存大小都是预定义好的，一旦配置完成就无法动态调整。</p><p>Cassandra支持<code>KV Cache</code>和<code>KP Cache</code>（如图2c所示），但是不支持<code>Block Cache</code>。在KP Cache中，<code>value</code>在磁盘中的位置作为指针被缓存到内存中。一旦命中了<code>KP Cache</code>，因为<code>KP Cache</code>中已经保存了<code>value</code>在磁盘中的位置，所以仅需要一次额外的磁盘I/O就可以完成「point lookup」。与<code>KV Cache</code>相比，在面临较大的<code>value</code>时，<code>KP Cache</code>以一次额外的磁盘I/O为代价带来了更低的内存空间成本（也即空间效率更高）。但是，与<code>KV Cache</code>相似，<code>KP Cache</code>也不支持「range query」。</p><h4 id="b-General-Caching-Algorithms-通用的缓存算法"><a href="#b-General-Caching-Algorithms-通用的缓存算法" class="headerlink" title="b. General Caching Algorithms (通用的缓存算法)"></a>b. General Caching Algorithms (通用的缓存算法)</h4><p>Adaptive Replacement Cache (ARC，自适应替换缓存)是为管理DRAM中的「页缓存」而设计的「动态页面替换算法」。如图3所示，ARC将缓存空间划分为两个部分：「recency cache」 和 「frequency cache」，它们每个都是一个LRU（Least Recently Used，最近最少使用）缓存。 在ARC中，当一个页面第一次被访问时，将会被放到「recency cache」中，如果此页面在被移出「recency cache」前（也即被替换前）得到了第二次访问，则此页面会被认为是一个「frequently accessed page」，然后会将其进一步迁移到「frequency cache」。</p><p>recency cache和frequency cache之间的空间分配是动态的。ARC使用两个ghost cache来分别存储从recency cache和frequency cache 中替换出来的页面的元数据。ghost cache中缓存的页面元数据将会作为将来调整各部分缓存空间的参考。与real cache（也即存储完整页面的cache）相比，ghost cache的空间大小几乎可以忽略不计，因为它们只存储页面编号。</p><p>recency ghost cache的命中意味着recency cache的缓存空间应该更大，如图3上部所示，目标边界应该向左移动，反之亦然。因此，相应的real cache会根据工作负载来增大或减小。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC-Key_F_3.png" alt="image-20211209175114565"></p><p>但是，像ARC这种基于页面的缓存算法都不很适合LSM- KVS，因为它们都基于「页面大小」和「缓存收益」一致的假设。而在LSM- KVS中，不同的key-values的「大小」以及「缓存它们所带来的收益」是不一样的，也即「缓存成本」和「缓存收益」不统一（缓存成本为缓存条目所占用的内存空间，缓存收益为缓存条目所能节省的磁盘I/O次数）。</p><p>因此，在LSM-KVS的缓存方案设计中，「缓存成本」和「缓存收益」应该和「访问频率」一块被考虑。</p><h2 id="0x20-Motivation"><a href="#0x20-Motivation" class="headerlink" title="0x20 Motivation"></a>0x20 Motivation</h2><h3 id="0x21-Unique-Challenges-in-Caching-for-LSM-面临的挑战"><a href="#0x21-Unique-Challenges-in-Caching-for-LSM-面临的挑战" class="headerlink" title="0x21 Unique Challenges in Caching for LSM (面临的挑战)"></a>0x21 Unique Challenges in Caching for LSM (面临的挑战)</h3><p>首先，与页面缓存替换问题相比，页面缓存替换问题中的页面大小是固定的，而LSM树中的key-values大小不是一致的。因此，在LSM中的缓存算法在设计替换算法时，应该将key-values大小的不一致性纳入考虑范围。</p><p>此外，LSM-KVS有两种截然不同的读取操作，也即point lookup和range query，对缓存的需求不一致，这也在设计LSM缓存算法时也带来了额外的挑战。</p><p>最后，LSM-KVS的Compaction和Flush操作会使缓存的条目失效，在设计缓存方案时也要进行特殊处理。</p><h3 id="0x22-What-to-Cache-in-LSM-KVS-缓存什么的问题"><a href="#0x22-What-to-Cache-in-LSM-KVS-缓存什么的问题" class="headerlink" title="0x22 What to Cache in LSM-KVS (缓存什么的问题)"></a>0x22 What to Cache in LSM-KVS (缓存什么的问题)</h3><p>将缓存KV和KP进行比较，命中KV能节省更多次数的磁盘I/O，因为命中KP仍然需要一次额外的磁盘I/O操作。但是，另一方面，当value过大时，缓存KP的成本更低，空间利用更高效。</p><p><strong>Lesson 1: 应该结合缓存KV和KP条目的优点，来更高效的服务「point lookup」。</strong></p><p>但是遗憾的是，缓存KV和KP都不能支持「range query」，因此LevelDB和RocksDB都选择缓存「data block」来为「range query」服务。</p><p><strong>Lesson 2: 缓存block或者KV/KP都有它们各自的优势来支持「range query」或「point lookup」。也即每种缓存条目都有其适用的工作负载。</strong></p><h3 id="0x23-How-to-Perform-Replacement-如何执行替换的问题"><a href="#0x23-How-to-Perform-Replacement-如何执行替换的问题" class="headerlink" title="0x23 How to Perform Replacement (如何执行替换的问题)"></a>0x23 How to Perform Replacement (如何执行替换的问题)</h3><p>从上文的讨论可知，每种缓存条目都有其适应的工作负载场景。表1列出了各种缓存条目的比较。但是设计一个由三种缓存条目组成的替换算法是极具挑战的。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC-Key_T_1.png" alt="image-20211209183758144"></p><p>现有的成本感知缓存方案（cost-aware caching schemes）并没有针对LSM-KVS的场景做缓存成本和收益的分析。</p><p><strong>Lesson 3: 缓存算法应该根据LSM-KVS独特的分层结构，考虑不同缓存条目所「占用DRAM空间大小的不同」，以及「节省的I/O次数的不同」。</strong></p><p>通常，现有缓存算法会为各种缓存条目设置固定大小的缓存空间，但这会带来一系列问题。首先，很难设置最优的缓存空间分配；其次，即使一开始设计好了最优的缓存空间分配，但随着工作负载发生变化，之前设置的缓存空间分配便不再适用。</p><p><strong>Lesson 4：缓存算法应该能够自适应工作负载的变化。</strong></p><h2 id="0x30-Technique-AC-Key-Design"><a href="#0x30-Technique-AC-Key-Design" class="headerlink" title="0x30 Technique: AC-Key Design"></a>0x30 Technique: AC-Key Design</h2><p>AC-Key同时支持缓存三种类型（KV，KP和Block）的条目，并为它们设计了单独的缓存组件。此外，各个缓存组件的空间大小会根据「分层自适应缓存算法」（<em>hierarchical adaptive caching</em> algorithm，HAC）来调整，该算法考虑了不同缓存条目的异构成本和收益，并使用一个「缓存效率因子」（<em>caching efficiency factor</em>）来指导缓存组件大小的调整。</p><h3 id="0x31-AC-Key-Caching-Components"><a href="#0x31-AC-Key-Caching-Components" class="headerlink" title="0x31 AC-Key Caching Components"></a>0x31 AC-Key Caching Components</h3><p>AC-Key的系统架构如图4所示。Block，KP和KV缓存，通过E-LRU进行管理，E-LRU是一种改进的LRU（基于缓存效率因子来选择缓存条目进行逐或者说是替换）。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC-Key_F_4.png" alt="image-20211209191340705"></p><p>在一个point lookup中，如果一个lookup-key是首次被访问，则会先将它存到KP Cache中。缓存到KP Cache中的key被称为「warm key」。如果KP Cache中的一个「warm key」被再次命中，我们会将其视为一个「hot key」。我们预计将来访问它的可能性更高。因此，我们会将其提升到KV Cache中，来为将来的访问减少潜在的磁盘I/O次数。</p><p>一种优化方式是，如果KV对比KP对还要小，我们会将key-value缓存到<strong>KP Cache</strong>中，而不是选择将KP缓存到KP Cache中，这样既能避免额外的磁盘I/O，还能节省缓存空间。不过这个KV对仍然需要再次命中后才会被移动到KV Cache中。</p><h4 id="a-Get-Handling"><a href="#a-Get-Handling" class="headerlink" title="a. Get Handling"></a>a. Get Handling</h4><p>查询一个Store中存在的Key时（也即point lookup操作）。首先会查询MemTable，因为MemTable中可能存在最新版本的Value。如果没有在MemTable中查询到，则会在KV和KP缓存中查询，将会发生以下情形：</p><ul><li>Case I：命中KV Cache。不需要磁盘I/O，直接返回相应Value值即可；</li><li>Case II：没有命中KV Cache，但是命中KP Cache。此时，先检查指针指向的数据块是否被缓存到Block Cache中，如果没有则将此数据块加载到Block Cache中，然后在该数据块中使用二分查找定位KV对。此外，还需要将此Key从KP Cache提升到KV Cache中；</li><li>Case III：既没有命中KV Cache，也没有命中KP Cache。将会一个Level一个Level的查询每个有序run，查找完成后将其缓存到KP Cache中（需要注意的是，在检索SST时会使用到BF block以及Index block，如果它们不在Block Cache中，也要将它们缓存到Block Cache）；</li></ul><h4 id="b-Flush-Handling"><a href="#b-Flush-Handling" class="headerlink" title="b. Flush Handling"></a>b. Flush Handling</h4><p>Flush会将包含最新KV数据的MemTable写入到磁盘组件$L_0$中。需要注意的是，MemTable中的某个Key的旧数据此前可能已经缓存到KV或KP Cache中。如果包含最新数据的MemTable还没有Flush到磁盘上，则在执行<code>Get</code>时会先检查MemTable，KV或KP Cache中的旧数据不会对<code>Get</code>造成影响，但是如果将MemTable Flush到磁盘上，则在执行<code>Get</code>操作时可能得到的是缓存中的旧版本的数据。因此，必须在Flush前完成MemTable和缓存中重叠Key的同步（只要有缓存就有可能存在缓存不一致的问题）。</p><p>有两个可以进行同步的时间点，一种是在<code>Put</code>期间同步，一种是在<code>Flush</code>期间同步。</p><p>如果在<code>Put</code>期间进行同步，则在每次<code>Put</code>操作时都需要检查缓存中的条目，会带来额外的开销；此外，在此期间无法更新KP Cache，因为MemTable还没写到SST中，无法获得指针。</p><p>因此，AC-Key选择仅在<code>Flush</code>时进行同步，这时只需要同步一次，并且可以在此时计算出指针地址来更新KP缓存。</p><h4 id="c-Compaction-Handling"><a href="#c-Compaction-Handling" class="headerlink" title="c. Compaction Handling"></a>c. Compaction Handling</h4><p>Compaction操作会影响KP和Block Cache。因为此操作会删除旧的SST，而旧的SST中的数据可能已经缓存到了KP或Block Cache中。需要注意的是此操作不会影响KV Cache，因为<code>Compaction</code>操作不会修改数据，只会进行重排和合并。</p><p>AC-Key会更新受到到<code>Compaction</code>影响的KP或Block Cache。</p><h3 id="0x32-Caching-Efficiency-Factor"><a href="#0x32-Caching-Efficiency-Factor" class="headerlink" title="0x32 Caching Efficiency Factor"></a>0x32 Caching Efficiency Factor</h3><p>为了对缓存条目的成本和收益进行定量分析和权衡，本文根据LSM-KVS独特的分层结构提出了一个「缓存效率因子」。使用此缓存效率因子，AC-Key将LRU改进为E-LRU来管理每个缓存组件内部的替换操作。此外，AC-Key还通过这个缓存效率因子将ARC改进为E-ARC来调整各个缓存组件的大小。</p><p>本文将一个缓存条目的缓存效率因子$E$（$E$代表Efficiency）定义为如下等式：</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/image-20211209202701009.png" alt="image-20211209202701009"></p><p>其含义是每字节的DRAM空间所节省的I/O次数。</p><p>其中，$b$代表如果此条目被缓存，其潜在所能节省的I/O次数，它由如下等式给出：</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC-Key_E_2.png" alt="image-20211209203050655"></p><p>函数式$f(m)$依赖于LSM-KVS的实现，通常$f(m) = m+2$，也即需要读$m个BF + 1个index\ block + 1个data \ block$    。</p><p>传统的LRU仅考虑了访问模式，而没有考虑缓存条目的收益和成本不同。将LRU与缓存效率因子结合所得的E-LRU便是为了解决这一问题。E-LRU检查最少使用的a个缓存条目，并从中选出缓存效率因子最小的那个条目进行替换。$a$的值取决于缓存条目的缓存效率因子$E$的方差，它由$a= e^{v}$给出，其中$v$是缓存条目的缓存效率因子$E$的标准偏差。</p><p>当$v=0$时，所有缓存条目具有相同的缓存效率，此时$a=1$，E-LRU退化为LRU。此外，$a$有一个上限值，以避免在做出替换决定时需要检查过多的条目。</p><h3 id="0x33-HAC-Hierarchical-Adaptive-Caching"><a href="#0x33-HAC-Hierarchical-Adaptive-Caching" class="headerlink" title="0x33 HAC: Hierarchical Adaptive Caching"></a>0x33 HAC: Hierarchical Adaptive Caching</h3><p>Hierarchical Adaptive Caching (HAC)具有两级层次结构来管理不同的缓存（如图5所示）。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/AC-Key_F_5.png" alt="image-20211209211404375"></p><p>在上层，缓存被分为两个组件：<code>Point Cache</code>以及<code>Block Cache</code>，两个组件之间的边界可以动态调整。</p><p>在下层，<code>Point Cache</code>被进一步分为<code>KV Cache</code> 和<code>KP Cache</code>，同样也有一个动态调整的边界。</p><p>HAC通过维持<code>ghost caches</code>来保存从<code>KV Cache</code>、<code>KP Cache</code>和<code>Block Cache</code>中替换出来条目的记录。在上层和下层各有两个<code>ghost cache</code>。与<code>ghost cache</code>相对应，原始的<code>KV Cache</code>、<code>KP Cache</code>和<code>Block Cache</code>被称为<code>real cache</code>。在这里，<code>KV Real Cache</code>和<code>KP Real Cache</code>组成<code>Point Real Cache</code>。</p><p><code>ghost cache</code>并不保存真正的条目，只保存相关条目的元数据。一个<code>ghost cache</code>的命中意味着本应该命中对应的<code>real cache</code>的，如果<code>real cache</code>足够大的话。通过使用<code>ghost cache</code>和缓存效率因子，文章设计了E-ARC来调整相应的<code>real cache</code>的大小。</p><h4 id="a-Lower-Level-HAC"><a href="#a-Lower-Level-HAC" class="headerlink" title="a. Lower-Level HAC"></a>a. Lower-Level HAC</h4><p>在下层HAC，<code>Point Cache</code>被划分为<code>KV Real Cache</code>($R_{KV}$)和<code>KP Real Cache</code>（$R_{KP}$），这里有<br>$$<br>\left | R_{KV} \right |+\left | R_{KP} \right | = \left | S_{point} \right |<br>$$<br>其中$\left | S_{point} \right |$表示<code>Point Cache</code>的大小。AC-Key维护<code>KV Ghost Cache</code>，就好像$R_{KV}$ 加上$G_{KV}$的缓存大小就等于整个<code>Point Cache</code>的大小（这是用于暗示$R_{KV}$最大可以扩展到整个<code>Point Cache</code>的大小，而此时相应的$R_{KP}$的大小为0）。因此，在这个前提下，下面的等式成立：<br>$$<br>\left | S_{point} \right |=\left | R_{KV} \right |+\left | R_{KP} \right | = \left | R_{KV} \right |+\left | G_{KV} \right |=\left | R_{KP} \right |+\left | G_{KP} \right | \ \ \ Eqn.4<br>$$<br>下面展示E- ARC处理缓存命中和未命中的几种情况：</p><ul><li>Case I：命中<code>Real Cache</code>。缓存命中$R_{KV}$或$R_{KP}$，将该条目移动到$R_{KV}$的MRU端。特殊的，如果命中发生在$R_{KP}$则需要一次额外的磁盘I/O来获取<code>Value</code>，然后将该<code>key-value</code>对提升到$R_{KP}$中。</li><li>Case II：命中<code>KV Ghost Cache</code>。这意味着$R_{KV}$应该更大，因此向<code>KP Cache</code>方向调整目标边界，调整步幅为$\delta = kE$，$E$代表$G_{KV}$中命中条目的缓存效率因子，$k$是配置的学习率。从磁盘中读完数据后将其插入到$R_{KV}$的MRU端。为了给该条目腾出空间，如果目标边界在$R_{KV}$内部的话，这意味着<code>KV Cache</code>的目标大小比当前大小还要小，不能扩充，只能在<code>KV Cache</code>内部通过E-LRU算法进行替换。</li><li>Case III：命中<code>KP Ghost Cache</code>。这意味着$R_{KP}$应该更大，因此调整目标边界，同Case II类似。</li><li>Case III：未命中缓存。此时需要检索磁盘，然后将读取的数据缓按照KP的格式存到$R_{KP}$中。此外，$R_{KP}$同样需要为该条目腾空子，需要根据目标边界的实际情况来确定是调整$R_{KP}$的大小来腾空子还是通过缓存替换来腾空子。</li></ul><p>$R_{KV}$和$R_{KP}$之间的目标边界指示着实际边界应该移动的方向，但是需要注意的是，实际边界总是滞后于目标边界的。</p><p>高层的操作顺序如下：</p><ol><li>命中<code>ghost cache</code>则调整目标边界；</li><li>需要缓存的条目的插入或提升（从<code>KP Cache</code>提升到<code>KV Cache</code>）使得实际边界向目标边界方向调整，相应的，$R_{KV}$和$R_{KP}$的大小得到更新；</li><li>基于新的<code>Real Cache</code>的大小和Eqn.4（上文的等式4）来调整对应的<code>Ghost Cache</code>的大小；</li><li><code>Real Cache</code>和<code>Ghost Cache</code>在需要适配更新后的大小时通过E-LRU算法来执行替换；</li></ol><h4 id="b-Upper-Level-HAC"><a href="#b-Upper-Level-HAC" class="headerlink" title="b. Upper-Level HAC"></a>b. Upper-Level HAC</h4><p>在HAC的上层，我们重新应用E-ARC来调整<code>Point Cache</code>和<code>Block Cache</code>之间的边界。<code>Block Cache</code>和<code>Point Cache</code>各自都有一个 <code>Real Cache</code>和一个<code>Ghost Cache</code>。需要注意的是，从$R_{point}$中替换出来的条目不光要插入到$G_{point}$还要插入到下层的$G_{KV}$或$G_{KP}$中。与下层相似，上层的Cache空间也存在类似的等价关系：<br>$$<br>\left | S_{total} \right |=\left | R_{point} \right |+\left | R_{block} \right | = \left | R_{block} \right |+\left | G_{block} \right |=\left | R_{point} \right |+\left | G_{point} \right | \ \ Eqn.5<br>$$<br><strong>目标边界的调整：</strong></p><p>命中$G_{block}$需要将目标边界从$R_{block}$移向$R_{point}$，移动步幅$\Delta = kE$。相应的，$R_{point}$的目标大小将会减少$\Delta$。在下层，调整量将按照$R_{KV}$和$R_{KP}$的当前目标大小的比率按比例分配。例如，当前$R_{KV}$和$R_{KP}$的目标大小分别为$\left | R_{KV}^* \right |$和$\left | R_{KP}^* \right |$，则它们将按照如下方式进行更新：<br>$$<br>\begin{matrix}<br>\left | R_{KV}^* \right | \leftarrow \left | R_{KV}^* \right | - \Delta \frac{\left | R_{KV}^* \right |}{\left | R_{KV}^* \right | + \left | R_{KP}^* \right |}<br>\\<br>\left | R_{KP}^* \right | \leftarrow \left | R_{KP}^* \right | - \Delta \frac{\left | R_{KP}^* \right |}{\left | R_{KV}^* \right | + \left | R_{KP}^* \right |}<br>\end{matrix}<br>$$<br>另一方面，如果命中的是$G_{point}$，则需要将目标边界向$R_{block}$方向移动，移动步幅同样为$\Delta = kE$。需要注意的是，这里的$E$会比命中$G_{block}$时的缓存效率因子更大，因为与缓存Block相比，缓存KV和KP在占用相同空间的情况能节省更多的I/O次数。此外，在HAC的上层命中$G_{point}$则意味着会在下层命中$G_{KV}$或$G_{KP}$，在这种情况下会先调整下层的目标边界，再调整上层的目标边界。</p><p><strong>实际边界的调整：</strong></p><p>当一个block需要插入到<code>Block Cache</code>中（也即<code>Block Cache</code>潜在需要更大的空间时），而<code>Block Cache</code>的实际大小加上此block的大小比其目标大小要大时，<code>Block Cache</code>不会扩容，只能通过E-LRU算法从<code>Block Cache</code>中选择一个block进行替换。而如果<code>Block Cache</code>的实际大小加上此block的大小要比其目标大小要小时，此时就可以对<code>Block Cache</code>进行扩容了（相对应的<code>Point Cache</code>会收缩缓存空间），扩容后就可以将此block插入到<code>Block Cache</code>。</p><p>另一方面，如果<code>Point Cache</code>需要更大的容量，HAC会估计其进行扩容后的大小，然后将该大小与其目标大小进行比较，如果小于其目标大小的话，则可以对其进行扩容，相应的，<code>Block Cache</code>需要通过逐出block来收缩缓存空间以给Point Cache提供空间；如果预估的新的<code>Point Cache</code>的大小要大于其目标大小的话，则不能对其进行扩容，只能通过E-LRU算法在<code>Point Cache</code>内部通过替换来为新的缓存条目腾出空间。</p><h4 id="c-Reduce-Ghost-Cache-Size"><a href="#c-Reduce-Ghost-Cache-Size" class="headerlink" title="c. Reduce Ghost Cache Size"></a>c. Reduce Ghost Cache Size</h4><p>在ARC算法的设计中，从<code>Real Cache</code>中逐出的页面，其内容会被丢弃，仅需要将<code>page number</code>保存在<code>Ghost Cache</code>中。这里，<code>page number</code>的大小与<code>page content</code>相比是可以忽略不计的。</p><p>类似的，在AC-Key中<code>Ghost Block  Cache</code>的大小与<code>Real Block Cache</code>的大小相比也是可以忽略的，因为<code>Ghost Block Cache</code>中以<code>&lt;SstID | BlockOffset&gt;</code>形式存储的<code>block handle</code>与<code>Real Block Cache</code>中存储的Block相比也是可以忽略的。但是<code>Ghost KV Cache</code>、<code>Ghost KP Cache</code>以及<code>Ghost Point Cache</code>的大小与其对应的<code>Real Cache</code>相比是无法忽略的，这会带来较大的空间开销。  </p><p>AC-Key通过两种方式来减少<code>Ghost Cache</code>的空间开销：</p><ul><li>首先，AC- Key不使用从<code>KV Cache</code>和<code>KP Cache</code>中逐出来的条目的原始Key，而是使用原始Key的哈希值；</li><li>其次，可以在自适应缓存方案已经成功建立了一个在<code>KV Cache</code>、<code>KP Cache</code>和<code>Block Cache</code>之间比较有利的空间分配时关闭掉<code>Ghost Cache</code>，来消除其带来的开销。此外，还可以根据当前缓存组件的命中率来判断是否需要打开<code>Ghost Cache</code>以重新指导空间分配；</li></ul>]]></content>
    
    
    <categories>
      
      <category>Key-Value Store</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Key-Value Store</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TRIAD:Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores</title>
    <link href="/2021/12/09/%E8%AF%BB%E8%AE%BA%E6%96%87/TRIAD%EF%BC%9ACreating%20Synergies%20Between%20Memory,%20Disk%20and%20Log%20in%20Log%20Structured%20Key-Value%20Stores/"/>
    <url>/2021/12/09/%E8%AF%BB%E8%AE%BA%E6%96%87/TRIAD%EF%BC%9ACreating%20Synergies%20Between%20Memory,%20Disk%20and%20Log%20in%20Log%20Structured%20Key-Value%20Stores/</url>
    
    <content type="html"><![CDATA[<h2 id="0x00-Introduction-amp-Background"><a href="#0x00-Introduction-amp-Background" class="headerlink" title="0x00 Introduction &amp; Background"></a>0x00 Introduction &amp; Background</h2><p>LSM通常由两部分组件组成：</p><ul><li>内存组件（Memory Component）：主要用来absorb update（在内存组件中absorb update的同时会将数据写入到磁盘日志中，以用于数据恢复）；</li><li>磁盘组件（Disk Component）：用于持久化数据，内存组件中的数据超过上限后会flush到磁盘，磁盘组件按照Level的形式进行组织，接近内存组件的Level保存着更新的数据，当某个$L_i$超过上限时会与$L_{i+1}$进行归并压缩，也即在后台执行$Compaction$操作；</li></ul><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_1.png" alt="image-20211208161344551"></p><p>$Compaction$和$Flush$是非常关键的操作，负责维护$LSM$的结构和属性，同时这也会占用大量的可用资源。</p><p>作者在$Nutanix$的生产环境负载测试中，顶峰时$Compaction$操作对$CPU$的占用率会达到45%。此外，单个集群平均每天要花费两个小时在$Compaction$操作上，以维护元数据存储映射。</p><p>文章提出了三种新的互补技术来弥补这些不足。这些技术同时减少了$Compaction$和$Flush$操作所占用的时间和空间资源，并带来了吞吐量的提升。</p><ol><li>第一项技术减少了倾斜工作负载（skewed workload）下的$Compaction$开销。将频繁更新的$KV$对（也即hot entries）保留在内存组件中，仅对cold entries执行$Flush$操作。这个分离操作减少了hot entry所触发的频繁Compaction操作。</li><li>第二项技术的主要思想是推迟对文件的Compaction操作，只有当文件的重叠部分足够大时才进行Compaction。</li><li>第三项技术主要是改变提交日志（commit log）在LSM中的角色，以类似SSTable的形式来使用它们，来避免双写（第一次写到日志，第二次是flush操作所引起的第二次写操作）；</li></ol><h2 id="0x10-Motivation"><a href="#0x10-Motivation" class="headerlink" title="0x10 Motivation"></a>0x10 Motivation</h2><p>尽管I/O操作不在面向用户操作的关键路径中，但是Flush、Compaction、Log等操作仍然会占用大量的计算资源。CPU协调这些操作会占用大量的处理能力，而这些处理能力本来是可以用于为用户提供更好性能体验的。因此I/O操作的频率和长度会对用户感知的最终性能有较大的影响。</p><p>为证明I/O操作会导致性能下降，本文设计了相关实验进行验证。选择了两个方面具有负载倾斜的工作负载：</p><ul><li>数据流行度：skewed和uniform</li><li>读写混合：write dominated 和 balanced</li></ul><p>将上述工作负载运行在普通RocksDB和关闭了后台I/O的RocksDB（例如，可以关闭$Flush$和$Compaction$）中，实验结果绘图如下：</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_2.png" alt="image-20211208171104923"></p><p>可以看到在各个负载下，关闭了后台I/O的RocksDB都表现出了更优的性能。在此结果的驱动下，本文确定了触发频繁和密集I/O的三个主要原因：</p><ul><li> data-skew unawareness, at the memory component level，也即在内存组件层面上的无意识的数据倾斜（存在冷热键）;</li><li> premature and iterative compaction, at the LSM tree level，也即在LSM树层面过早的迭代$Compaction$操作;</li><li>duplicated writes at the logging level，也即在日志层面的双写操作； </li></ul><h3 id="0x11-Data-skew-unawareness-（数据倾斜）"><a href="#0x11-Data-skew-unawareness-（数据倾斜）" class="headerlink" title="0x11 Data skew unawareness （数据倾斜）"></a>0x11 Data skew unawareness （数据倾斜）</h3><p>很多KV Store的工作负载都表现出数据倾斜的特征，其中hot key的更新频率要远远高于cold key。</p><p>数据倾斜导致commit log的增长速度远远大于$C_m$（也即内存中的MemTable和Immutable Memtable）。因为对相同key的更新，日志是以追加的方式存储的，而$C_m$采取的是就地吸收（absorbed in-place）的方式。这会导致$C_m$在达到其上限之前触发$Flush$操作，因为commit log过大会导致在数据恢复时所耗费的时间更长，所以MemTable必须频繁的$Flush$，从而使commit log可以被及时清理掉，通过减小commit log的大小来缩短数据恢复的时间。这不仅会增加$C_m$的$Flush$频率，而且由于其大小是小于其能达到的最大值的，导致$L_0$中打开和存储文件的固定成本并没有被实际写入数据更好的摊分。</p><h3 id="0x12-Premature-and-iterative-compaction-（过早Compaction）"><a href="#0x12-Premature-and-iterative-compaction-（过早Compaction）" class="headerlink" title="0x12 Premature and iterative compaction （过早Compaction）"></a>0x12 Premature and iterative compaction （过早Compaction）</h3><p>现有的基于LSM的KV-Store在Compaction过程中表现出了两方面的限制。</p><p>一些KV-store在$L_0$中仅保留一个SSTable，以加快读速率。但这样会导致每次内存组件的Flush操作都会触发一次$L_0$和底层Level的Compaction操作，也即导致了频繁的Compaction操作。这便是第一种限制。</p><p>另外一些LSM的方案是在$L_0$保存多个SSTable，这会导致第二种限制。主要表现在，当$L_0$中有多个SSTable时，LSM如何将$L_0$ Compaction到$L_1$。事实上，$L_0$中的多个文件是一次性Compaction到更高的Level的，这从而也会导致多个连续的Compaction操作。也即如果$L_0$中的两个SSTable都有一个相同的key，那么这个key将会在底层的LSM树中执行两次Compaction操作。而数据倾斜会加剧这个问题，因为它增加了$L_0$中多个SSTable拥有共同key的概率。显然，当系统的负载越高时，这种事件发生的概率也会越高。</p><h3 id="0x13-Duplicate-writes（双写）"><a href="#0x13-Duplicate-writes（双写）" class="headerlink" title="0x13 Duplicate writes（双写）"></a>0x13 Duplicate writes（双写）</h3><p>当$C_m$被Flush到$L_0$中后，相应的commit log便会被删除掉，因为$Flush$操作已经能够保证数据的持久化。Flush到$L_0$的每个KV对都是最新的版本，都对应了一个commit log，因此$Flush$操作不过是重放了在追加commit log时已经执行过的I/O操作。</p><h2 id="0x20-Technique——TRIAD"><a href="#0x20-Technique——TRIAD" class="headerlink" title="0x20 Technique——TRIAD"></a>0x20 Technique——TRIAD</h2><p>文章用来解决I/O开销的方法体现在三个方面，每个解决方案都对应了前面提到的一个挑战：</p><ul><li> TRIAD-MEM 通过冷热键分离来解决内存组件中的data skew问题；</li><li>TRIAD- DISK 通过推迟和批量Compaction来解决磁盘组件中的premature and iterative compaction问题；</li><li>TRIAD- LOG 通过绕过$Flush$过程中创建新SSTable来解决日志层面中的duplicate write问题；</li></ul><h3 id="0x21-TRIAD-MEM"><a href="#0x21-TRIAD-MEM" class="headerlink" title="0x21 TRIAD-MEM"></a>0x21 TRIAD-MEM</h3><p>TRIAD-MEM的目标是利用大多数工作负载所表现出的数据倾斜的特点来减少Flush，并进一步减少Compaction的频率。为了做到这一点，TRIAD-MEM仅将cold key flush到磁盘上，而将hot key保留在内存中（但也要写commit log）。这能避免触发大量的Compaction操作，从而降低磁盘中重叠Key的数量。</p><p>将hot key保留在内存中，便可以在内存中完成更新操作，这可以避免在磁盘上触发大量的Compaction操作。</p><p>图3展示了Flush期间冷热键分离的过程，图4展示了Flush完成后的状态。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_3_4.png" alt="image-20211208204615405"></p><p>算法2展示了冷热键是如何分离的。旧$C_m$中的前K个条目被选中，其中K是系统的参数。理想情况下，K的取值应该既能保存尽量多的hot key，还能避免引起较高的内存开销。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_A_2.png" alt="image-20211208205815580"></p><p>保留在内存中的hot key 不需要Flush到磁盘上，但在更新时仍然需要写commit log（如图3所示），以保证在宕机时能完成数据恢复。</p><p>当$C_m$的大小不超过某个阈值（算法1中的<code>FLUSH_TH</code>）时，分离冷热键时不会进行$Flush$。因为在工作负载不均衡时，$Flush$ 可能是因为commit log满了而不是$C_m$满了所触发的（commit log太多会造成数据恢复时间过长，所以commit log过多时也会触发$Flush$）。所以，为了避免$Flush$小的$C_m$文件，算法会将所有条目都保存在内存中，并根据这些条目创建新的commit log，丢弃旧的commit log。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_A_1.png" alt="image-20211208211005386"></p><h3 id="0x22-TRIAD-DISK"><a href="#0x22-TRIAD-DISK" class="headerlink" title="0x22 TRIAD-DISK"></a>0x22 TRIAD-DISK</h3><p>TRIAD-DISK会推迟Compaction操作，直到需要Compaction的文件有足够多的key重叠。为了估计文件之间的key重叠，文章使用了HyperLogLog (HLL)概率基数估计器。</p><p>为了计算一组文件之间的重叠，文章定义了一个重叠率（overlap ratio），假设在$L_0$中有$n$个文件，则重叠率可以定义为：<br>$$<br>1-\frac{ UniqueKeys(file_1, file_2,… ,file_n))}{sum(Keys(file_i))}<br>$$<br>其中：</p><ul><li>$Keys(file_i)$表示第$i$个SSTable中的key数量；</li><li>$UniqueKeys(file_1, file_2,… ,file_n))$表示合并$n$个文件后的唯一key的数量；</li></ul><p>图5展示了overlap ratio 是如何来推迟Compaction的。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_F_5.png" alt="image-20211208212910135"></p><p>在$L_0$中执行每次Compaction之前，我们会先计算出$L_0$中所有文件的overlap ratio，如果overlap ratio小于阈值，则推迟Compaction（除非$L_0$中文件的数量超过允许的最大值，如果超过，那么不再考虑overlap ratio，强制允许Compaction）。</p><h3 id="0x23-TRIAD-LOG"><a href="#0x23-TRIAD-LOG" class="headerlink" title="0x23 TRIAD-LOG"></a>0x23 TRIAD-LOG</h3><p>TRIAD-LOG的主要思路是，内存中需要Flush到磁盘中的数据已经在commit log中了，可以对commit log进行利用而不必通过Flush操作再重写一次。主要思想就是将CL转为$L_0$中一种特殊的SSTable，也即CL-SSTable，这种方式可以避免完整的Flush操作。</p><p>TRIAD-LOG增强了commit log角色的能力。当向$C_m$写入数据时，commit log就扮演其普通WAL的角色。当触发Flush操作时，将commit log转为CL-SSTable而不是将$C_m$重写到$L_0$。</p><p>将commit log作为$L_0$中的SSTable可以避免Flush操作所带来的I/O开销，但SSTable是有序的，而commit log是追加生成的、是无序的。SSTable有序的特性可以加速Compaction操作和检索操作。</p><p>为了避免在$L_0$中查找某个条目时需要扫描整个CL-SSTable，TRIAD-LOG在$C_m$中保存每个KV对应的最近更新的commit log文件的偏移量，以帮助构建有序的CL-SSTable。一旦Flush操作被触发，只需要将与最新的commit log偏移量相关联的索引写到磁盘上（索引也即index的大小与整个KV相比是很小的，所以仅刷新index的开销很小，文章并没有对index有明确说明，我觉的这里的index可以是<code>(key, CL name, offset)</code>的组合，通过这个index再加上CL就可以组成有序的CL-SSTable了）。</p><p>TRIAD-LOG并没有改变写操作的流程，不同之处仅在于，在$C_m$中执行更新时会把对应的commit log的偏移量和文件名也写入到$C_m$中（例如，<code>(key, value, offset, CL name)</code>）。其流程入下图所示。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/TRIAD_F_6.png" alt="image-20211209093221560"></p>]]></content>
    
    
    <categories>
      
      <category>Key-Value Store</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Key-Value Store</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>事务实现算法</title>
    <link href="/2021/10/20/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <url>/2021/10/20/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="私有工作空间"><a href="#私有工作空间" class="headerlink" title="私有工作空间"></a>私有工作空间</h2><p>在概念上，当一个<strong>进程</strong>开始一个事务时，它被分配一个私有工作空间，该工作空间包含所有它有权访问的文件。在事务提交或中止前，它的所有读写操作都在私有空间内进行，而不是直接对文件系统进行操作。这就直接导致了第一种实现方法的产生；在进程开始一个事务的时刻，实际上为该进程分配了一个私有工作空间。</p><p>此技术带来的问题是把所有的东西都<strong>复制到私有工作空间的开销</strong>是十分大的，但是各种各样的优化方法使这种方法可行。</p><p>第一种优化方法是基于这样的认识，即<strong>当一个进程只读取一个文件而不对它做修改时，就不需要私有拷贝</strong>。该进程可以直接使用真正的文件（除非自事务开始以来文件已被改动）。因此，当进程开始一个事务时，就为它创建一个私有的工作空间，该空间是空的，除非当一个指针回指到它的父辈工作空间。当<strong>进程为了读取而打开文件时，指针将回指，直到可以在父辈（或者更老的祖先）工作空间中找到文件为止。</strong></p><p>第二种优化方法可以大大减少复制工作量。因为它不是复制整个文件，而是<strong>只将索引复制到私有工作空间</strong>。索引是与判断文件所在磁盘块位置有关的数据块。在UNIX系统中，索引是$i$节点（index node，即索引节点）。通过<strong>私有索引</strong>，文件可以按通常方式读取，这是因为索引中所包含的地址指向的是文件所在的原始磁盘块。然而，<strong>当一个文件块第一次被修改时，将生成该块的副本，其地址也被插入索引中</strong>（如下图所示）。然后就可以在不影响原始块的情况下更新这个块。添加块也是用这种方法解决。新块有时会被称为影像块。（这是一种写时复制技术，即copy-on- write）</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6.drawio.png" alt="写时复制.drawio"></p><p>在上图中，运行事务的进程看到了修改的文件，但是其他所有进程看到的仍是原始的文件。在更复杂的事务中，私有工作空间可能包含大量的文件而不仅仅是一个。<strong>如果事务中止，私有工作空间就被简单的删除，它所指向的私有块也将被释放回自由列表（free list）中。如果事务被提交了，那么私有索引被移到父辈工作空间中。</strong></p><h2 id="写前日志"><a href="#写前日志" class="headerlink" title="写前日志"></a>写前日志</h2><p>另一个实现事务的常用方法是写前日志（write ahead log，WAL）。使用这种方法时，<strong>文件将真正被修改，但是在任何一个数据块被修改前，一条记录被写到了日志中以说明哪个事务正在对文件进行修改，哪个文件和哪个数据块被改动了，旧值和新值是什么。只有当日志被写入成功后，此改动才可以被写入文件。</strong></p><p>如果事务执行成功并被提交，那么一条提交记录被写进日志，但是数据结构不需要变动，这是因为它们已经被更新了。如果事务中止，那么可以使用日志来回退到原来的状态。<strong>从日志的末尾开始向前读取每条记录，同时将在每条记录中描述的改动撤销</strong>（这也被称为「回退」或「回滚」，也即rollback）。</p><p>注：本文内容摘自「分布式系统原理与范型」，供本人学习回顾使用。</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>分布式系统原理与范型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>事务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发控制</title>
    <link href="/2021/10/20/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/"/>
    <url>/2021/10/20/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>并发控制算法通常根据<strong>读写操作同步的方式</strong>来分类。同步可以通过<strong>共享数据上的互斥机制</strong>（例如，锁🔒），或者通过显式地使用<strong>时间戳排序</strong>来实现。</p><p>并发控制算法可以进一步区分为<strong>悲观算法</strong>和<strong>乐观算法</strong>。</p><p>悲观算法（pessimistic approaches）的基本原则是Murphy定律（墨菲定律）：<strong>如果某事物可以出错，那么它就会出错。在悲观算法中，操作时在它们被执行前同步的，这意味着冲突在允许发生之前就解决了</strong>。</p><p>相反，乐观算法（optimistic approachs）是<strong>基于错误一般不会发生的观点</strong>。所以操作被简单地执行，在事务结束的时候再进行同步。如果那是确实发生了冲突，一个或更多的事务将被迫终止。</p><p>下面将讨论两个悲观算法和一个乐观算法。</p><h2 id="两阶段锁定"><a href="#两阶段锁定" class="headerlink" title="两阶段锁定"></a>两阶段锁定</h2><p>最古老最简单也是最广泛使用的并发控制算法是锁定（locking🔒）。</p><p>当一个进程要作为事务的一部分来读或写一个数据项时，它请求调度管理器允许它给该数据项加锁。同样，当它不再需要一个数据项时，就请求调度管理器释放该锁。</p><p><strong>调度管理器的任务</strong>是以一种可以得到正确调度结果的方式来允许加锁和释放锁，即需要使用一种<strong>可以提供串行调度的算法</strong>。这样一个算法是两阶段锁定算法。</p><p>如下图所示的两阶段锁定（two-phase locking，2PL）中，调度管理器先在增长阶段（growing phase）获得它所需要的所有锁，然后在收缩阶段（shrinking phase）释放它们。尤其要遵守下面三个规则：</p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/2PL.png" alt="17105307_MZJc" style="zoom: 50%;" /><ol><li>当调度管理器收到来自事务管理器的<code>open(T,x)</code>操作时，它检测该操作是否跟它已经允许锁定的另一个进程冲突。如果存在冲突，操作<code>open(T,x)</code>被延迟（这样事务$T$也被延迟）。如果没有冲突，调度管理器就允许对数据项$x$加锁，并将这个操作传递给数据管理器。</li><li>直到数据管理器通知它已经完成了对锁定数据项x的操作，调度管理器才会释放数据项x的锁。</li><li>一旦调度管理器为事务$T$释放了锁，那么无论事务T请求为哪个数据项加锁，调度管理器都不会允许T加另外一把锁（即只能一次获取到所需的所有锁）。$T$获取另外一把锁的任何企图都是一个程序错误，都会终止事务$T$。</li></ol><p>在许多系统中，收缩阶段是在事务运行结束之后，要么提交、要么终止时出现，它导致锁的释放（<strong>同时释放</strong>），如下图所示。这种策略被称为严格的两阶段锁定。</p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/strict-2PL.png" alt="17105326_2MZl" style="zoom:50%;" /><p>严格的两阶段锁定有两个主要的优点：</p><ul><li>事务总是读提交事务写入的值，所以我们从来都不会因为事务的计算是基于一个它不应该看到的数据项而终止它。</li><li>所有锁的获得和释放都可以由系统来处理而无需事务关心。要访问一个数据项就要获得锁，当事务完成时就释放锁。这种策略消除了瀑布型终止（cascaded aborts），即不得不撤销一个已经提交的事务，因为它看到了它不该看见的数据项。</li></ul><h2 id="悲观的时间戳排序"><a href="#悲观的时间戳排序" class="headerlink" title="悲观的时间戳排序"></a>悲观的时间戳排序</h2><p>一个完全不同的并发控制方法是在<strong>每个事务$T$开始时给它分配一个时间戳$ts(T)$。</strong></p><p>使用Lamport算法，我们可以保证时间戳是惟一的。<strong>事务$T$的每个操作都被盖上时间戳$ts(T)$，并且系统中的每个数据项$x$都有一个相关的读时间戳$ts_{RD}(x)$和写时间戳$ts_{WR}(x)$。</strong>读时间戳被设置为<strong>最近</strong>读$x$的事务的时间戳，而写时间戳是<strong>最近</strong>修改$x$的事务的时间戳。使用时间戳排序，如果两个操作冲突，则数据管理器先处理时间戳最早的操作。</p><p>现在假设调度管理器从具有时间戳$ts$的事务$T$收到一个操作，<code>read(T,x)</code>。但是$ts&lt;ts_{WR}(x)$。**换句话说，调度管理器发现一个对$x$的写操作在事务开始后已经完成（也即，在事务$T$启动到开始读之间，调度管理器发现一个对x的写操作在此期间完成了）。在这种情况下，事务$T$简单的被终止。**相反，如果$ts&gt;ts_{WR}(x)$，那么让读操作发生（即上一个对$x$的写操作是在事务$T$之前完成的）。此外，$ts_{RD}(x)$被设置为$max{ts, ts_{RD}(x)}$。</p><p>同样，假设调度管理器收到一个具有时间戳$ts$并包含写操作<code>write(T, x)</code>的事务$T$。**如果$ts&lt;ts_{RD}(x)$，那么它只能取消事务$T$，这是因为$x$的当前值已经被更晚的事务读过**（也即，在事务$T$启动到开始写之前完成了一个事物对$x$的读操作，实际上应该事务$T$先来的，但是被别人插队了，为了大局，事务$T$只能取消）。另一方面，如果$ts&gt;ts_{RD}(x)$，那么它改变$x$的值，因为没有更晚的事务读过它。$ts_{WR}$也被设置为$max{ts, ts_{WR}(x)}$。</p><p>时间戳具有与锁定不同的特性。当事务遇到一个更大（或更晚）的时间戳时，它中止，而在同样的情况下，如果使用锁定方法，事务将等待或立即执行（也即，要是被人插了队自己就中止退出）。另一方面，它不会造成死锁，这是一个很大的优点。</p><h2 id="乐观的时间戳排序"><a href="#乐观的时间戳排序" class="headerlink" title="乐观的时间戳排序"></a>乐观的时间戳排序</h2><p>第三种处理多个事务同时执行的方法是乐观的并发控制（optimistic concurrency）。此技术的思想是：不关心别人在干什么，继续做自己要做的事情。如果有问题，等到后面再考虑（许多政客也使用这个算法，注：个人认为西方政客会这样做，咱们中国的政客都是特别怕出事情担责任的）。实际上，相对来讲冲突是很少的，所以系统大部分时间都运行正常。</p><p>尽管冲突可能很少发生，但也不是不会发生，因此仍需要某种方法来处理冲突。乐观的并发控制所做的事情是跟踪哪些数据项被改写了。<strong>在某个事务被提交的时候，它检查其他所有事务，看看是否有某些数据项从这个事务开始后被改变了（即在某个事务提交的时候检查其数据项是否被其他事务改变了）。如果被改变了，该事务被终止；如果没有被改变，则该事务提交。</strong></p><p>乐观的并发控制算法最适合基于<strong>私有工作空间</strong>的实现。在这种方式下，每个事务私下改变自己的数据，不受别的事务的干涉。最终，新数据要么被提交、要么被释放，这是一个相对简单直接的方法。</p><p>乐观的并发控制的最大优点是它不会发生死锁，允许最大的并行性。这是因为没有进程需要等待一个锁。缺点是有时它可能会失败，那时事务将不得不再次执行。在负载较重的情况下，失败的可能性比较大，使得乐观的并发控制成为了一个较差的选择。</p><p>此外，对乐观的并发控制的研究主要集中在非分布式系统中。</p><p>注：本文内容摘自「分布式系统原理与范型」，供本人学习回顾使用。</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>分布式系统原理与范型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>并发控制</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式快照捕获算法</title>
    <link href="/2021/10/14/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%85%A8%E5%B1%80%E7%8A%B6%E6%80%81/"/>
    <url>/2021/10/14/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%85%A8%E5%B1%80%E7%8A%B6%E6%80%81/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在许多情况下，知道分布式系统所处的全局状态是很有用的。<strong>分布式系统的全局状态（Global State）包括每个进程的本地状态和当前正在传输中的消息，所谓正在传输中的消息即该消息已经被发送但还没有被交付。</strong></p><p>有很多原因表明，知道分布式系统的状态是很有用的。例如，当已知本地计算已经停止并且也没有消息在传输时，系统显然进入了一个不能继续前进的状态。此时，通过分析全局状态我们就能得知系统是进入了死锁还是分布式计算已经正确的结束了。</p><p>注：本文内容主要摘自「分布式系统原理与范型」，主要用于本人学习回顾。</p><h2 id="关于全局状态和分布式快照"><a href="#关于全局状态和分布式快照" class="headerlink" title="关于全局状态和分布式快照"></a>关于全局状态和分布式快照</h2><p>Chandy和Lamport在其1985年发表的论文<a href="https://lamport.azurewebsites.net/pubs/chandy.pdf">Distributed Snapshots：Determining Global States of Distributed Systems </a>中提出了一个简单直接的<strong>记录分布式系统全局状态</strong>的方法，该方法引入了<strong>分布式快照</strong>（Distribute Snapshot）的概念。</p><p><strong>分布式快照反映了该分布式系统可能处于的状态，且重要的是，该记录的状态是全局一致的。</strong>这意味着，如果快照已经记录了进程P收到了来自进程Q的一条信息，那么应该也记录了进程Q确实发送了这个消息。否则，快照将会记录一个已经被接受但从未被发送的消息。需要注意的是，相反的情况是可以接受的，也即快照可以记录一个已经被发送但还尚未被接受的消息。</p><p>全局状态的概念可以用一个被称为切口（cut）的示意图来表达。如下图所示，穿越进程P1、P2和P3时间轴的虚线表示的是一个一致的切口。该切口表示了「为每个进程记录的最后事件」，记录了事件$m_1$的发送和接受，以及事件$m_2$的发送。</p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/IMG_6746735F12FC-1.jpeg" alt="IMG_6746735F12FC-1" style="zoom: 50%;" /><p>作为对比，下图是一个不一致的切口，快照中记录了事件$m_1$的发送和接受，但是仅记录了事件$m_3$的接受而未记录其发送。</p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/IMG_CC2C77FC7968-1.jpeg" alt="IMG_CC2C77FC7968-1" style="zoom:50%;" /><h2 id="分布式快照捕获算法的描述"><a href="#分布式快照捕获算法的描述" class="headerlink" title="分布式快照捕获算法的描述"></a>分布式快照捕获算法的描述</h2><p>为了简化对分布式快照捕获算法的解释，我们假设分布式系统可用一个彼此通过<strong>单向点对点通信通道</strong>相连的进程集合来表示。例如，进程可能在任何进一步通信发生前首先建立TCP连接。</p><p>任何进程都可以启动该算法来捕获一个分布式快照。启动算法的<strong>进程P</strong>通过记录它自己的本地状态而启动。然后，它可以通过每个<strong>流出通道</strong>发送一个<strong>标记</strong>，表明接受者应该参与记录全局状态。</p><p>当<strong>进程Q</strong>通过一个<strong>进入通道C</strong>接收到一个<strong>标记</strong>，该进程根据它是否已经保存了本地状态来决定下一步动作。</p><ul><li>如果进程Q尚未保存其本地状态，它就先记录本地状态，然后也通过它自己的每个流出通道发送一个标记。</li><li>如果进程Q已经保存了其本地状态，则通道C上的标记表明Q应该记录该通道的状态。该状态是从进程Q上次记录了它自己的本地状态开始，到它接受了该标记为止，Q所接受到的消息序列组成。</li></ul><p>当一个进程接受并处理了它的所有进入通道的标记时，就认为该进程已经完成了算法中与它有关的部分。此时可以将它记录的本地状态和它为每个进入通道记录的状态收集起来，发送给发起此快照的进程P。后者随后分析当前状态。需要注意的是，与此同时，分布式系统可以作为一个整体继续正常运行，也即分布式快照算法不会影响分布式系统的正常运行。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/cut.drawio.png" alt="cut.drawio"></p><p>还有一个需要注意的地方是，因为任何进程都能发起该算法，所以可能同时存在几个快照。为此，标记上附有发起该快照的进程的标识符（可能还有一个版本号）。只有在进程已经通过它的每个进入通道接收到了某个标记后，它才能完成与该标记相关的快照的创建。</p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>分布式系统原理与范型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>全局状态</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>逻辑时钟（Logical Clock）</title>
    <link href="/2021/10/13/%E5%88%86%E5%B8%83%E5%BC%8F/%E9%80%BB%E8%BE%91%E6%97%B6%E9%92%9F/"/>
    <url>/2021/10/13/%E5%88%86%E5%B8%83%E5%BC%8F/%E9%80%BB%E8%BE%91%E6%97%B6%E9%92%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文内容主要摘自《分布式系统原理与范型》，主要用于本人后续回顾学习用，建议阅读原书。</p><h2 id="关于时钟"><a href="#关于时钟" class="headerlink" title="关于时钟"></a>关于时钟</h2><p>几乎所有的计算机都有一个计时电路，我们一般会称这个计时电路为「时钟」（但它们并不是通常意义上的时钟，我们将其称为「计时器」可能会更恰当一些）。「时钟」与进程之间的协作和同步有密切的关系，多个进程之间是通过「事件」发生的「时间」来就「事件」的发生顺序达成一致的。在单机单时钟的情况下，如果这个时钟存在少许偏差是不会出现问题的，因为这台机器上的所有进程都使用同一个时钟，所以它们的内部仍然会保持一致。</p><h2 id="逻辑时钟"><a href="#逻辑时钟" class="headerlink" title="逻辑时钟"></a>逻辑时钟</h2><p>在许多应用中，只要所有的机器能维持一个全局统一的时间就够了，这个时间并不需要与真实时间一致。对于某类算法而言，重要的是时钟的内部一致性，而不是它们是否与真实时间接近。这类算法通常将时钟称为「逻辑时钟」（logical clock）。</p><p>Lamport在其著名的论文<a href="http://lamport.azurewebsites.net/pubs/time-clocks.pdf">「Time, Clocks, and the Ordering of Events in a Distributed System 」</a>中阐明了「尽管时钟同步是可能的，但它不是绝对必要」的观点。如果两个进程不进行交互，那么他们的时钟也无须同步，这是因为即使没有进行同步也察觉不出来，并且也不会产生问题。他指出，<strong>通常重要的不是所有的进程在时间上完全一致，而是它们在事件的发生顺序上要达成一致</strong>。</p><h2 id="Lamport时间戳"><a href="#Lamport时间戳" class="headerlink" title="Lamport时间戳"></a>Lamport时间戳</h2><p>为了同步逻辑时钟，Lamport定义了一个称为「先发生」（happens-before）的关系。表达式$a \rightarrow b$读作「a在b之前发生」，意思是所有进程一致认为事件a先发生，然后事件b才发生。这种「先发生」关系有两种情况：</p><ul><li>如果a和b是同一个进程中的两个事件，且a在b之前发生，则$a \rightarrow b$为真；</li><li>如果a是一个进程发送消息的事件，而b为另一个进程接受该消息的事件，则$a \rightarrow b$也为真。消息不可能在发送之前就被接受，也不可能在发送的同时被接受，这是因为消息需要一定时间才能到达接收端。</li></ul><p>「先发生」关系是一种传递关系，所以如果$a \rightarrow b$且$b \rightarrow c$，则有$a \rightarrow c$。如果事件x和y发生在两个互不交换消息的进程中（也不通过第三方间接交换消息），那么无论是$x \rightarrow y$还是$y \rightarrow x$都不为真。这两个事件被称为「并发的」（concurrent），这意味着无法说或者不必说这两个事件什么时候发生，哪个事件先发生。</p><p>我们需要一种测量事件的方法，使得对于每个事件a，我们都能为它分配一个所有进程都认可的时间值$C(a)$。同时这些时间值必须具有如下性质：</p><ul><li><p>如果$a \rightarrow b$，那么$C(a) &lt; C(b)$；</p></li><li><p>时钟时间值$C$必须总是前进（增加），不能倒退（减少），校正时间的方法是给时间加上一个正值而不是减去一个正值；</p></li></ul><p>如下图所示，三个进程运行在不同的机器上，每个机器以各自的速率工作。当进程A的时钟「滴答」了6次时，进程B的时钟「滴答」了8次，进程C的时钟「滴答」了10次。我们下面描述一个从进程A到B再到C的消息传递及响应过程：</p><ol><li><p>在0时刻，进程A将消息a发送给进程B，消息的传输时间取决于信任哪个时钟。不管怎样，当它到达进程B时，进程B的时钟为16。如果消息a上携带了其在进程A上打包的时钟值0，则进程B会推算其传输时间为$16 - 0 = 16$个时钟值。</p></li><li><p>进程B在其时钟值为24时，将消息b发送给进程C，在进程C的时钟值为40时到达进程C。</p></li><li><p>进程C在其时钟值为50时，将响应消息c发送给进程B，在进程B的时钟值为48时到达进程B。</p></li><li><p>进程B在其时钟值为56时，将响应消息d发送给进程A，在进程A的时钟值为54时到达进程A。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/logical_clock2.png" alt="logical_clock"></p></li></ol><p>分析以上过程，我们可以发现一个有意思的现象，响应消息从进程C时钟值为50时刻出发，却在进程B时钟值为48时刻到达进程B，响应消息d也有类似的现象——<strong>消息的到达时刻竟然比消息的发送时刻还要早</strong>，这显然是不合理的，必须避免这种情况发生。</p><p>Lamport给出的解决方案是直接遵循「先发生关系」。消息c在时钟值为50时离开，那么它只能在时钟值为51或更晚时到达。所以每个消息都应该携带发送者时钟的「发送时间」。<strong>当消息到达，并且接受者时钟显示的时间值比消息的发送时间早时，接受者就把它的时钟调到一个比发送时间大1的值</strong>。调整后的过程图如下所示。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/lamport_logical_clock.png" alt="lamport_logical_clock"></p><p>对这个算法稍作补充就可以满足全局时间的需要，即在每两个事件之间，时钟必须至少「滴答」一次。如果一个进程以相当快的速度连续发送或接收两个消息，那么它的时钟必须在这之间至少「滴答」一次。</p><p><strong>在某些情况下还需要一个附加条件，即两个事件不会精确的同时发生。为了达到这个目标，我们可以将事件发生的进程号附加在时间的低位后，并用小数点分隔开。</strong>使用这种方法，如果进程1和进程2同时在40时刻发生了一个事件，那么前者可以标记为「40.1」，后者可以标记为「40.2」。</p><p>通过使用这种方法，我们现在有了一个为分布式系统中的所有事件分配时间的方法，这遵循下面的规则：</p><ol><li>若在同一进程中a在b之前发生，则$C(a)&lt;C(b)$；</li><li>若a和b分别代表发送一个消息和接受该消息的事件，则C(a)&lt;C(b)；</li><li>对于所有不同的事件a和b，$C(a) \neq C(b)$；</li></ol><p>这个算法为我们提供了一种对系统中所有的事件进行完全排序的方法。许多其他的分布式算法都需要这种排序以避免混淆，所以此算法在各种文献被广泛引用。</p><h2 id="向量时间戳"><a href="#向量时间戳" class="headerlink" title="向量时间戳"></a>向量时间戳</h2><p>Lamport时间戳导致分布式系统中的所有事件都要经过排序以具有这样的性质：如果事件a发生在事件b之前，那么a也应该排在b之前，即$C(a) &lt; C(b)$。</p><p>然而，使用Lamport时间戳后，只通过比较事件a和b各自的时间值$C(a)$和$C(b)$，无法说明它们之间的关系。换句话说，$C(a) &lt; C(b)$不能说明事件a就是在事件b之前发生的。问题在于Lamport时间戳不能捕获因果关系（causality）。</p><p>因果关系可以通过向量时间戳（Vector Timestamp）来捕获。分配给<strong>事件a</strong>的**向量时间戳 $VT(a)$**具有下列性质：如果对于某一事件b，有 $VT(a) &lt; VT(b)$，那么认为事件a在因果关系上处于事件b之前。</p><p>向量时间戳的创建是通过让**每个进程$P_n$维护一个向量$V_n$**来实现的，该向量具有下面两个性质：</p><ul><li>$V_i[i]$是到目前为止<strong>进程</strong>$P_i$发生的事件的数量；</li><li>如果$V_i[j] = k$，那么<strong>进程</strong>$P_i$知道<strong>进程</strong>$P_j$中已经发生了$k$个事件；</li></ul><p>第一个性质是通过在**进程$P_i$中的新事件发生时递增$V_i[i]$**来维护的。</p><p>第二个性质是通过在所发送的消息中携带向量时间戳来维护的，<strong>当进程$P_i$发送消息$m$时，它将自己的当前向量作为时间戳$vt(m)$一起发送。</strong></p><p>通过使用这种方式，接受者可以得知进程$P_i$中已经发生的事件数。更重要的是，接受者可以得知在进程$P_i$发送消息$m$之前其他进程已经发生了多少个事件。<strong>换句话说，消息$m$的时间戳$vt(m)$告诉接受者其他进程中有多少事件发生在消息$m$之前，并且$m$可能在因果关系上依赖于这些事件。</strong></p><p>进程$P_j$依赖于其接收到的消息来调整自己所维护的向量。<strong>当进程$P_j$在接收到消息$m$时，它调整自己的向量，将每项$V_j[k]$设置为$max{V_j[k], vt(m)[k]}$。该向量现在反映了进程$P_j$所必须接受到消息数目，该消息数目至少是在发送$m$之前见到的消息。此后将$V_j[i]$增1，这表示接受消息$m$的事件是来自于进程$P_i$的下一个事件。</strong></p><p>只在不违背因果关系限制时，才能使用向量时间戳来传递消息。</p><p><strong>示例：</strong></p><p>我们来考虑一个电子公告板的例子。当进程$P_i$张贴一篇文章时，它将改文章作为消息$a$广播出去，并且在该消息上附加一个时间戳$vt(a)$，其值等于$V_i$。当另一个进程$P_j$接收到消息$a$时，它将根据其携带的时间戳$vt(a)$来调整自己的向量，以使$V_j[i] &gt; vt(a)[i]$。</p><p>假设进程$P_j$在收到消息$a$后广播了一个该文章的回复消息$r$，消息$r$携带值等于$V_j$的时间戳$vt(r)$。需要注意的是$vt(r)[i] &gt; vt(a)[i]$。假设通信是可靠的，包含文章的消息$a$和包含回复的消息$r$最终都到达了另一个进程$P_k$。</p><p>因为我们没有对消息的顺序关系做出假设，所以消息$r$可能在消息$a$之前到达进程$P_k$。进程$P_k$接受到消息$r$时检查其时间戳，并决定推迟提交消息$r$，直到因果关系上位于$r$之前的消息都接受到了才提交$r$。消息$r$ 只有在满足下列条件时才得到交付：</p><ol><li>$vt(r)[j] = V_k[j] + 1$；</li><li>对于所有满足$i \neq j$的$i$和$j$，$vt(r)[i] &lt; V_k[i]$；</li></ol><p>第一个条件说明$r$是进程$P_k$正在等待的下一条来自进程$P_j$的消息；</p><p>第二个条件说明当进程$P_j$发送消息$r$时，进程$P_k$只看到被进程$P_j$看到的消息。这意味着进程$P_k$已经看到了消息$a$。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/because.drawio.png" alt="because.drawio"></p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
      <category>分布式系统原理与范型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>时钟同步</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The Google File System</title>
    <link href="/2021/10/05/%E8%AF%BB%E8%AE%BA%E6%96%87/The%20Google%20File%20System/"/>
    <url>/2021/10/05/%E8%AF%BB%E8%AE%BA%E6%96%87/The%20Google%20File%20System/</url>
    
    <content type="html"><![CDATA[<h1 id="论文介绍"><a href="#论文介绍" class="headerlink" title="论文介绍"></a>论文介绍</h1><h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><h3 id="论文名"><a href="#论文名" class="headerlink" title="论文名"></a>论文名</h3><p>The Google File System</p><h3 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h3><p>Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung</p><h3 id="期刊-会议"><a href="#期刊-会议" class="headerlink" title="期刊/会议"></a>期刊/会议</h3><p> SOSP’03, October 19–22, 2003, Bolton Landing, New York, USA. </p><h2 id="论文摘要"><a href="#论文摘要" class="headerlink" title="论文摘要"></a>论文摘要</h2><h2 id="论文地址"><a href="#论文地址" class="headerlink" title="论文地址"></a>论文地址</h2><h3 id="原文地址"><a href="#原文地址" class="headerlink" title="原文地址"></a>原文地址</h3><p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf">「The Google File System」</a></p><h3 id="阅读参考"><a href="#阅读参考" class="headerlink" title="阅读参考"></a>阅读参考</h3><p><a href="http://duanple.com/?p=202">「google论文二Google文件系统(上)」</a></p><h1 id="阅读摘要-amp-笔记"><a href="#阅读摘要-amp-笔记" class="headerlink" title="阅读摘要&amp;笔记"></a>阅读摘要&amp;笔记</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients.</p><p>我们设计实现了Google文件系统，一个应用于大型分布式数据密集型应用程序的可扩展分布式文件系统。它在运行于廉价硬件设备的同时提供容错性，并为大量的客户端提供高聚合性能。</p><p>While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points.</p><p>虽然于很多之前的分布式文件系统有相同的目标，但是我们的设计是基于对我们的应用程序负载和技术环境的观察所驱动的，这反映了与早先的分布式文件系统的设计思想的明显背离。这促使我们重新审视传统的选择，并探索根本不同的设计要点。</p><p>The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients.</p><p>此文件系统成功的满足了我们的存储需要。它被广泛的部署在Google内部，并且作为产生和处理我们的服务所需要的数据，以及需要大型数据集的研究和开发工作的存储平台。迄今为止最大的集群在超过一千台机器上的数千个磁盘上提供数百 TB 的存储，并且它被数百个客户端同时访问。</p><p>In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.</p><p>在本文中，我们介绍了旨在支持分布式应用程序的文件系统接口扩展，讨论了我们设计的许多方面，并报告了来自微基准测试和现实世界使用的测试结果。</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>GFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability.</p><p>GFS和之前的大多数分布式系统一样，其主要设计目标是：性能、可扩展性、可靠性和可用性。</p><p>However, its design has been driven by key observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system design assumptions.</p><p>与早先的分布式系统的区别在于，它的设计是由我们当前和预期的应用负载和技术环境所驱动的。</p><p>We have reexamined traditional choices and explored radically different points in the design space.</p><p>我们重新审视了传统设计的选择，并在设计空间上探索了根本不同的设计要点。</p><ul><li>First, component failures are the norm rather than the exception.Therefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.</li><li>Second, files are huge by traditional standards. Multi-GB files are common.As a result, design assumptions and parameters such as I/O operation and block sizes have to be revisited.</li><li>Third, most files are mutated by appending new data rather than overwriting existing data.Random writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially.Given this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal.</li><li>Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility.For example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them.</li><li>我们将设备故障视为常态而不是意外。因此，持续监控、错误检测、容错性和自动恢复性必须作为系统不可或缺的一部分。</li><li>按照传统的标准，文件是巨大的。GB大小的文件是常态。因此必须重新考虑设计假设和参数，例如I/O操作和块大小。</li><li>大多数文件是通过追加操作而不是覆盖写来改变的。随机写操作很少出现，一旦写入后，大多数文件通常是只读的，并且是顺序读取。鉴于这种大文件的访问模式，追加操作成为性能优化和原子性保证的重点，而客户端的数据块缓存则失去了吸引力。</li><li>结合应用程序和文件系统一块设计API，能通过提高灵活性来使整个系统收益。例如，我们通过放松对GFS的一致性模型来简化文件系统，而不会对应用程序带来较大的负担。我们还通过引入原子性的追加操作来使多个客户端可以并发行的对同一个文件进行追加操作，而无需在它们之间进行额外的同步。</li></ul><h1 id="2-Design-Overview"><a href="#2-Design-Overview" class="headerlink" title="2 Design Overview"></a>2 Design Overview</h1><h2 id="2-1-Assumptions"><a href="#2-1-Assumptions" class="headerlink" title="2.1 Assumptions"></a>2.1 Assumptions</h2><p>We alluded to some key observations earlier and now lay out our assumptions in more details.</p><p>我们之前提到了一些关键性的观察结果，现在我们对它们进行更详细的描述。</p><ul><li>The system is built from many inexpensive commodity components that often fail. It must constantly monitor itself and detect, tolerate, and recover promptly from component failures on a routine basis.</li><li>The system stores a modest number of large files.Multi-GB files are the common case<br>and should be managed efficiently. Small files must be supported, but we need not optimize for them.</li><li>The workloads primarily consist of two kinds of reads: large streaming reads and small random reads.<ul><li>In large streaming reads, individual operations typically read hundreds of KBs, more commonly 1 MB or more.Successive operations from the same client often read through a contiguous region of a file.</li><li>A small random read typically reads a few KBs at some arbitrary offset. Performance-conscious applications often batch and sort their small reads to advance steadily through<br>the file rather than go back and forth.</li></ul></li><li>The workloads also have many large, sequential writes that append data to files. Typical operation sizes are similar to those for reads. Once written, files are seldom modified again. Small writes at arbitrary positions in a file are supported but do not have to be efficient.</li><li>The system must efficiently implement well-defined semantics for multiple clients that concurrently append to the same file.</li><li>High sustained bandwidth is more important than low latency. Most of our target applications place a premium on processing data in bulk at a high rate, while few have stringent response time requirements for an individual read or write.</li><li>系统由很多经常出问题的廉价设备组成。它们必须持续自我监视，并定期检测、容错并迅速从组件故障中恢复。</li><li>系统中存储着大量的大文件数据。GB大小的文件是作为常态存在的，并且必须进行高效的管理。同时，系统也必须支持小型文件，但不必对此进行优化。</li><li>工作负载主要由两种读操作组成：大规模的流读取和小规模的随机读取。<ul><li>在大规模的流读取中，每次操作通常读取几百KB，更常见的是1MB或更多。来自同一客户端连续读操作通常会读取文件的连续区域。</li><li>一个小的随机读操作通常会以任意偏移量读取几KB。注重性能的应用程序通常会对这些小的读取操作进行批处理和排序，以持续稳定推进文件的读操作，而不是来回读取。</li></ul></li><li>工作负载中也会有很多大的连续写操作追加数据到文件。一般数据大小和读操作类似。一旦写入后文件很少被修改。小的任意写操作必须支持，但不必支持高效性。</li><li>系统必须实现高效的、良好定义的语义，以支持大量客户端对同一文件的并发追加写操作。</li><li>高持续带宽比低延迟更重要。我们的大多数目标应用程序都非常重视以高速率批量处理数据，而对单个读或写操作的响应时间并没有严格的要求。</li></ul><h2 id="2-2-Interface"><a href="#2-2-Interface" class="headerlink" title="2.2 Interface"></a>2.2 Interface</h2><p>GFS provides a familiar file system interface, though it does not implement a standard API such as POSIX. Files are organized hierarchically in directories and identified by pathnames. We support the usual operations to <code>create</code>, <code>delete</code>, <code>open</code>, <code>close</code>, <code>read</code>, and <code>write</code> files.</p><p>GFS提供了一个熟悉的文件系统接口，虽然它并没有实现像POSIX标准那样的标准API接口。文件在目录中分层组织，并由路径名标识。我们还支持文件的一些常见操作，如<code>create</code>、<code>delete</code>、<code>open</code>、<code>close</code>、<code>read</code>、<code>write</code>。</p><p>Moreover, GFS has <code>snapshot</code> and <code>record append</code> operations. Snapshot creates a copy of a file or a directory tree at low cost. Record append allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity of each individual client’s append. It is useful for implementing multi-way merge results and producer-consumer queues that many clients can simultaneously append to without additional locking. We have found these types of files to be invaluable in building large distributed applications. Snapshot and record append are discussed further in Sections 3.4 and 3.3 respectively.</p><p>此外，GFS支持<strong>快照</strong>和<strong>追加</strong>写操作。快照会以低开销创建一个文件或目录树的拷贝。追加写操作允许大量客户端并发向同一个文件追加写，并且保证每个客户端的追加写都是原子性的。这对实现多路合并操作和生产者-消费者队列非常有用，许多客户端可以同时进行追加操作而不需要额外的加锁处理。我们发现这些类型的文件对构建大型分布式应用非常宝贵。快照和追加写操作将在3.4节和3.3节中进一步讨论。</p><h2 id="2-3-Architecture"><a href="#2-3-Architecture" class="headerlink" title="2.3 Architecture"></a>2.3 Architecture</h2><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/GFS_Figure1.png" alt="Untitled"></p><p>A GFS cluster consists of a single master and multiple chunk-servers and is accessed by multiple clients, as shown in Figure 1.</p><p>如图1所示，一个GFS集群由一个Master和大量的被很多Client访问的Chunk Server组成。</p><p>Files are divided into fixed-size chunks. Each chunks identified by an immutable and globally unique 64 bit chunk handle assigned by the master at the time of chunk creation.Chunk servers store chunks on local disks as Linux files and read or write chunk data specified by a chunk handle and byte range. For reliability, each chunks replicated on multiple chunk servers. By default, we store three replicas, though users can designate different replication levels for different regions of the file namespace.</p><p>文件被划分为固定大小的Chunk。每个Chunk在创建时由Master分配一个不可变的，并且全局唯一的64位Chunk Handle标识。Chunk Server将Chunks作为Linux文件存储在本地磁盘上，读写操作都由Chunk Handle和字节边界来明确。为了可靠性，每个Chunk被复制存储到多个Chunk Server上。虽然用户可以为文件命名空间的不同区域指定不同的备份级别，但通常默认为三个备份。</p><p>The master maintains all file system metadata. This includes the namespace, access control information, the mapping from files to chunks, and the current locations of chunks. It also controls system-wide activities such as chunk lease management, garbage collection of orphaned chunks, and chunk migration between chunk servers. The master periodically communicates with each chunk server in HeartBeat messages to give it instructions and collect its state.</p><p>集群Master保存了文件系统的所有元数据。这包括，命名空间、访问控制信息、文件和Chunk的映射关系，以及Chunk的当前保存位置。它也控制系统范围内的一些活动，比如Chunk租约管理、孤立块的垃圾回收，以及Chunk在Chunk Server之间的迁移。 Master还会周期性的和Chunk Server进行交流，通过心跳信息下发指令和收集Chunk Server状态。</p><p>GFS client code linked into each application implements the file system API and communicates with the master and chunk servers to read or write data on behalf of the application. Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunk servers.</p><p>链接到应用程序的客户端代码实现了文件系统API，并且代表应用程序与Master和Chunk Server通信以读写数据。客户端与主机交互以进行元数据操作，但所有的数据通信都是直接发送到Chunk Server。</p><p>Neither the client nor the chunk server caches file data. Client caches offer little benefit because most applications stream through huge files or have working sets too large to be cached. Not having them simplifies the client and the overall system by eliminating cache coherence issues. (Clients do cache metadata, however.) Chunk servers need not cache file data because chunks are stored as local files and so Linux’s buffer cache already keeps frequently accessed data in memory.</p><p>客户端和Chunk Server都不需要缓存文件数据。客户端缓存并不会带来明显的好处，因为大多数应用程序通过数据流与大型文件传输数据，或者因为数据量太大而无法缓存。去掉缓存可以简化客户端，以及整个系统（没有因缓存一致性而带来的问题）。Chunk Server不需要缓存文件数据，因为Chunk是作为本地文件存储的，所以Linux的Cache缓存已经将经常访问的数据保存在了内存中。（利用了操作系统的缓存）</p><h2 id="2-4-Single-Master"><a href="#2-4-Single-Master" class="headerlink" title="2.4 Single Master"></a>2.4 Single Master</h2><p>Having a single master vastly simplifies our design and enables the master to make sophisticated chunk placement and replication decisions using global knowledge.However, we must minimize its involvement in reads and writes so that it does not become a bottleneck. Clients never read and write file data through the master. Instead, a client asks the master which chunk servers it should contact. It caches this information for a limited time and interacts with the chunk servers directly for many subsequent operations.</p><p>仅有一个Master大大简化了我们的设计，并且使其能够利用全局知识做出复杂的决策以确定Chunk的放置位置和复制。但是，我们必须减少其所参与的读写操作，以保证它不会成为整个系统的瓶颈。客户端只是通过向Master询问它应该联系的Chunk Server信息，而不是通过Master直接读写数据，并且客户端会将其请求得到的信息缓存一段时间，在此时间段内它可以与Chunk Server直接交互而不需要向Master询问信息。</p><p>Let us explain the interactions for a simple read with reference to Figure 1.</p><ul><li>First, using the fixed chunk size, the client translates the file name and byte offset specified by the application into a chunk index within the file.</li><li>Then, it sends the master a request containing the file name and chunk index.</li><li>The master replies with the corresponding chunk handle and locations of the replicas. The client caches this information using the file name and chunk index as the key.</li><li>The client then sends a request to one of the replicas, most likely the closest one. The request specifies the chunk handle and a byte range within that chunk. Further reads of the same chunk require no more client-master interaction until the cached information expires or the file is reopened.</li></ul><p>In fact, the client typically asks for multiple chunks in the same request and the master can also include the information for chunks immediately following those requested. This extra information sidesteps several future client-master interactions at practically no extra cost.</p><p>我们根据图1来解释一个读操作的交互过程：</p><ul><li>首先，根据Chunk的固定大小，客户端通过应用程序中标识的文件名和字节偏移量转换为Chunk索引。</li><li>然后，客户端将包含文件名和Chunk索引的请求信息发送给Master。</li><li>Master向客户端响应Chunk Handle和一个Chunk副本的位置信息，客户端使用Chunk索引作为键值对中的键来缓存该信息。</li><li>客户端随后会向一个Chunk副本发送请求信息，通常是距离较近的副本。请求会标识Chunk Handle和字节边界。直到缓存信息到期或重新打开该文件前，客户端请求同一Chunk都不再需要和Master交互。</li></ul><p>实际上，会在一个查询请求信息中包含多个Chunk请求，Master也会将多个Chunk的信息封装在一个响应包中发回给客户端。这些额外的信息不需要其他成本就可以减少客户端和Master的几次交互操作。</p><h2 id="2-5-Chunk-Size"><a href="#2-5-Chunk-Size" class="headerlink" title="2.5 Chunk Size"></a>2.5 Chunk Size</h2><p>Chunk size is one of the key design parameters. We have chosen 64 MB, which is much larger than typical file system block sizes. Each chunk replica is stored as a plain Linux file on a chunk server and is extended only as needed. Lazy space allocation avoids wasting space due to internal fragmentation, perhaps the greatest objection against such a large chunk size.</p><p>Chunk的大小是设计中的关键参数。我们选择的64MB大小，远远大于典型的文件系统的块大小。每个Chunk副本都作为普通的Linux文件存储在Chunk Server中，并且只有在需要时才会进行扩展。懒空间分配避免了由于内部碎片所导致的空间浪费，可能产生的最大的碎片有一个Chunk那么大。</p><blockquote><p>惰性空间分配：使用惰性空间分配时，空间的物理分配会尽可能延迟，直到累积了块大小大小的数据(在GFS的默认情况为下为64 MB)。</p></blockquote><p>A large chunk size offers several important advantages.</p><ul><li>First, it reduces clients’ need to interact with the master because reads and writes on the same chunk require only one initial request to the master for chunk location information.</li><li>Second, since on a large chunk, a client is more likely to perform many operations on a given chunk, it can reduce network overhead by keeping a persistent TCP connection to the chunk server over an extended period of time.</li><li>Third, it reduces the size of the metadata stored on the master. This allows us to keep the metadata in memory, which in turn brings other advantages that we will discuss in Section 2.6.1.</li></ul><p>大的Chunk大小带来了以下重要的优势：</p><ul><li>首先，这减少了Client与Master多次交互的需要，因为Client可以将Chunk的位置信息缓存到本地，所以对于同一个Chunk的读写操作，Client只需要与Master进行一次请求。</li><li>其次，对于一个较大的Chunk，客户端可能在此块上进行更多的操作，这样就可以通过延长TCP连接时间来减少网络开销。</li><li>最后，这减少了存储在Master上的元数据大小。这就可以使master在内存保存更多的元数据，反过来这就带来了我们在2.6.1节中讨论的其他优势。</li></ul><p>On the other hand, a large chunk size, even with lazy space allocation, has its disadvantages. A small file consists of a small number of chunks, perhaps just one. The chunk servers storing those chunks may become hot spots if many clients are accessing the same file. In practice, hot spots have not been a major issue because our applications mostly read large multi-chunk files sequentially.</p><p>另一方面，使用大的Chunk，即使利用了惰性空间分配，也存在它的缺点。一个小型文件只有几个Chunk组成，甚至可能只有一个。存储这些Chunk的Chunk Server可能因为会被大量客户端访问同一个文件而成为访问热点。实际上，访问热点并不是一个主要的问题，因为我们的应用主要是顺序读取那些由很多Chunk组成的大文件。</p><h2 id="2-6-Metadata"><a href="#2-6-Metadata" class="headerlink" title="2.6 Metadata"></a>2.6 Metadata</h2><p>The master stores three major types of metadata: the file and chunk namespaces, the mapping from files to chunks, and the locations of each chunk’s replicas. </p><p>Master存储三种类型的元数据：文件和Chunk命名空间、文件到Chunk的映射关系、每个Chunk副本的位置信息。</p><p>All metadata is kept in the master’s memory. The first two types (namespaces and file-to-chunk mapping) are also kept persistent by logging mutations to an operation log stored on the master’s local disk and replicated on remote machines. Using a log allows us to update the master state simply, reliably, and without risking inconsistencies in the event of a master crash. The master does not store chunk location information persistently. Instead, it asks each chunk server about its chunks at master startup and whenever a chunk server joins the cluster.</p><p>所有的元数据信息都被Master保存在它的内存中。前两种类型的元数据（命名空间和文件到Chunk的映射）还通过操作日志更新到本地磁盘以及备份到远程的机器来保证数据持久化。使用日志可以使我们简单、可靠的更新Master的状态，而不用担心在Master故障时造成不一致性的危险。Master不会持久化的存储Chunk的位置信息，因为，它会在启动的时候，以及Chunk Server加入集群的时候询问每个Chunk Server的Chunk信息。</p><h3 id="2-6-1-In-Memory-Data-Structures"><a href="#2-6-1-In-Memory-Data-Structures" class="headerlink" title="2.6.1 In-Memory Data Structures"></a>2.6.1 In-Memory Data Structures</h3><p>Since metadata is stored in memory, master operations are fast. Furthermore, it is easy and efficient for the master to periodically scan through its entire state in the background. This periodic scanning is used to implement chunk garbage collection, re-replication in the presence of chunk server failures, and chunk migration to balance load and disk space usage across chunk servers. Sections 4.3 and 4.4 will discuss these activities further.</p><p>元数据被存储到Master的内存中后，Master对元数据的操作会非常快。此外，Master能在后台简单有效的完成对整体状态的周期性扫描。这个周期性的扫描主要用于：Chunk的垃圾回收，Chunk Server出现问题时的重新复制，Chunk迁移以平衡负载，以及Chunk Server的磁盘空间利用。4.3节和4.4节将会进一步讨论这些活动。</p><p>One potential concern for this memory-only approach is that the number of chunks and hence the capacity of the whole system is limited by how much memory the master has. This is not a serious limitation in practice. The master maintains less than 64 bytes of metadata for each 64 MB chunk. Most chunks are full because most files contain many chunks, only the last of which may be partially filled. Similarly, the file namespace data typically requires less than 64 bytes per file because it stores file names compactly using prefix compression.</p><p>这种使用内存的方法潜存的一种担心是，这些Chunk的数量以及整个系统的容量会受到Master内存空间的限制。实际上，这并不是一个严重的问题。Master对于每个64MB大小的Chunk保存少于64字节的元数据。因为大多数文件包含大量的Chunk，因此大多数Chunk都是满的，可能只有最后一个Chunk是部分填充后的。类似的，文件命名空间通常对于每个文件也只需要少于64字节的，因为它们存储的文件名是使用前缀紧凑压缩后的。</p><p>If necessary to support even larger file systems, the cost of adding extra memory to the master is a small price to pay for the simplicity, reliability, performance, and flexibility we gain by storing the metadata in memory.</p><p>即使需要支持更大的文件系统，为Master增加内存来将元数据存储在内存中，以获得简单型、可靠性、性能以及灵活性而花费的额外的钱也是很小的代价。</p><h3 id="2-6-2-Chunk-Locations"><a href="#2-6-2-Chunk-Locations" class="headerlink" title="2.6.2 Chunk Locations"></a>2.6.2 Chunk Locations</h3><p>The master does not keep a persistent record of which chunk servers have a replica of a given chunk. It simply polls chunk servers for that information at startup. The master can keep itself up-to-date thereafter because it controls all chunk placement and monitors chunk server status with regular HeartBeat messages.<br>Master并不会持久化那些拥有Chunk副本的Chunk Server给定的每个Chunk记录。它只是会在启动时轮询每个Chunk Server来获得这些信息。Master可以在此之后保证自己持有最新的信息，因为它控制Chunk的放置位置，以及通过与Chunk Server交换心跳信息来监听Chunk Server 状态。</p><p>We initially attempted to keep chunk location information persistently at the master, but we decided that it was much simpler to request the data from chunk servers at startup, and periodically thereafter. This eliminated the problem of keeping the master and chunk servers in sync as chunk servers join and leave the cluster, change names, fail, restart, and so on. In a cluster with hundreds of servers, these events happen all too often.</p><p>我们一开始也尝试过在Master中持久化Chunk的位置信息，但是后来我们发现，在启动时向每个Chunk Server来请求数据是更简单的方法。这消除了在Chunk Server加入和离开集群、更改名称、失败、重启等时，Master必须与Chunk Server保持同步的问题。而这些问题在具有几百台服务器的集群中是经常发生的。</p><p>Another way to understand this design decision is to realize that a chunk server has the final word over what chunks it does or does not have on its own disks. There is no point in trying to maintain a consistent view of this information on the master because errors on a chunk server may cause chunks to vanish spontaneously (e.g., a disk may go bad and be disabled) or an operator may rename a chunk server.</p><p>理解此设计决策的另一种方式是，意识到Chunk Server对它自己有没有某个Chunk拥有最终发言权（即只有Chunk Server才能确定他自己到底有没有某个Chunk）。试图在Master上维护此信息的一致性视图是没有意义的，因为在Chunk Server上发生的各种错误都可能会导致存储的Chunk自发性的消失（例如，磁盘可能会发生故障而无法使用），或者一个操作员可能会重命名一个Chunk Server。</p><h3 id="2-6-3-Operation-log"><a href="#2-6-3-Operation-log" class="headerlink" title="2.6.3 Operation log"></a>2.6.3 Operation log</h3><p>The operation log contains a historical record of critical metadata changes. It is central to GFS. Not only is it the only persistent record of metadata, but it also serves as a logical time line that defines the order of concurrent operations. Files and chunks, as well as their versions (see Section 4.5), are all uniquely and eternally identified by the logical times at which they were created.</p><p>操作日志包含了关键元数据改变的历史记录。它是GFS的核心。它不仅是元数据的唯一持久化数据，并且还充当定义并发操作顺序的时间线。文件和Chunk，以及它们的版本，都由它们创建时的逻辑时间唯一且永久标识。</p><p>Since the operation log is critical, we must store it reliably and not make changes visible to clients until metadata changes are made persistent. Otherwise, we effectively lose the whole file system or recent client operations even if the chunks themselves survive. Therefore, we replicate it on multiple remote machines and respond to a client operation only after flushing the corresponding log record to disk both locally and remotely. The master batches several log records together before flushing thereby reducing the impact of flushing and replication on overall system throughput.</p><p>因为操作日志非常重要，因此我们必须可靠的存储它，并且在对元数据的更改持久化之前不能使这些改变对客户端可见。否则，我们很可能失去整个的文件系统或最近的客户端操作，即使Chunks保存下来。因此，我们将其复制到多台远程的机器上，并且仅在本地和远程的机器将相应的日志刷新到磁盘上之后才向客户端响应。Master在刷新前将操作记录进行批处理，以减少刷新和复制对整个系统吞吐量的影响。</p><p>The master recovers its file system state by replaying the operation log. To minimize startup time, we must keep the log small. The master checkpoints its state whenever the log grows beyond a certain size so that it can recover by loading the latest checkpoint from local disk and replaying only the limited number of log records after that. The checkpoint is in a compact B-tree like form that can be directly mapped into memory and used for namespace lookup without extra parsing. This further speeds up recovery and improves availability.</p><p>Master通过重放操作日志来恢复其文件系统状态。为了减少启动时间，我们必须使日志记录尽可能的小。每当日志记录超过指定的大小时，Master都会检查它自身的状态，以便它可以通过从本地磁盘加载最新的检查点，再通过重放有限数量的日志记录来恢复文件系统状态。检查点采用类似B树的紧凑形式，可以直接映射到内存中，在无需额外解析的下用于命名空间的查找。这加速了文件系统的恢复过程，并且提高了可用性。</p><p>Because building a checkpoint can take a while, the master’s internal state is structured in such a way that a new checkpoint can be created without delaying incoming mutations. The master switches to a new log file and creates the new checkpoint in a separate thread. The new checkpoint includes all mutations before the switch. It can be created in a minute or so for a cluster with a few million files. When completed, it is written to disk both locally and remotely.</p><p>由于构建检查点需要一定的时间，因此，Master的内部状态以这样的一种方式来构建检查点，即在不延迟传入新的突变的情况下构建新的检查点。Master切换到一个新的日志文件中，并且在一个单独的线程中创建一个新的检查点。新的检查点包含在切换之前的所有突变。它需要1分钟左右的时间来为具有几百个文件的集群来创建检查点。创建完成后，它会被写到本地和远程的磁盘中。</p><p>Recovery needs only the latest complete checkpoint and subsequent log files. Older checkpoints and log files can be freely deleted, though we keep a few around to guard against catastrophes. A failure during checkpointing does not affect correctness because the recovery code detects and skips incomplete checkpoints.</p><p>文件系统恢复只需要最新的完整检查点以及后续的日志文件。较旧的检查点和日志文件可以自由删除，但我们也保留了一些来为抵抗灾难做保证。检查点期间的错误不会影响正确性，因为恢复代码会检测并跳过不完整的检查点。</p><h2 id="2-7-Consistency-Model"><a href="#2-7-Consistency-Model" class="headerlink" title="2.7 Consistency Model"></a>2.7 Consistency Model</h2><p>GFS has a relaxed consistency model that supports our highly distributed applications well but remains relatively simple and efficient to implement. We now discuss GFS’s guarantees and what they mean to applications. We also highlight how GFS maintains these guarantees but leave the details to other parts of the paper.</p><p>GFS使用的相对宽松的一致性模型不但能很好的支持我们的高度分布式应用程序，而且保证了实现上的简单和高效。我们现在讨论GFS所提供的保证，以及它们对应用程序来说意味着什么。我们还会强调GFS如何维护这些保证，但会将具体的细节留给论文的其他部分来描述。</p><h3 id="2-7-1-Guarantees-by-GFS"><a href="#2-7-1-Guarantees-by-GFS" class="headerlink" title="2.7.1 Guarantees by GFS"></a>2.7.1 Guarantees by GFS</h3><p>File namespace mutations (e.g., file creation) are atomic.They are handled exclusively by the master: namespace locking guarantees atomicity and correctness (Section 4.1); the master’s operation log defines a global total order of these operations (Section 2.6.3).</p><p>文件命名空间的改变是原子性的。它们仅由Master来处理：命名空间锁来保证原子性和正确性；Master的操作日志定义了这些操作的全局总顺序。</p><p><img src="https://ap0l1o.oss-cn-qingdao.aliyuncs.com/img/GFS_Table1.png" alt="Untitled"></p><p>The state of a file region after a data mutation depends on the type of mutation, whether it succeeds or fails, and whether there are concurrent mutations. Table 1 summarizes the result. </p><p>数据变更后文件区域的状态依赖于变更的类型，数据变更成功还是失败，以及是否存在并发行变更。表1对这些结果进行了总结。</p><p>A file region is consistent if all clients will always see the same data, regardless of which replicas they read from. A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety. </p><ul><li>When a mutation succeeds without interference from concurrent writers, the affected region is defined (and by implication consistent): all clients will always see what the mutation has written.</li><li>Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations.</li><li>A failed mutation makes the region inconsistent (hence also undefined): different clients may see different data at different times.</li></ul><p>如果客户端无论从哪个副本都能看到一样的数据，则文件区域是一致性的。如果一个文件数据在变更后是一致性的，并且客户端能看到变更写入的内容，则该区域是定义良好的。</p><ul><li>当一个变更成功并且不受其他并发写入的干扰时，受影响的区域是定义良好的（同时意味着是一致性的）：所有客户端都能看到变更所写入的内容。</li><li>并发的成功变更所影响的区域是一致的，但不是定义良好的：所有的客户端都能看到相同的数据，但并不能反映出每个变更所写入的内容。通常，这由多个变更混合片段组成。</li><li>一个失败的变更会导致区域处于不一致的状态（因此也不是定义良好的）：不同的客户端在不同的时间段能看到不同的数据。</li></ul><p>We describe below how our applications can distinguish defined regions from undefined regions. The applications do not need to further distinguish between different kinds of undefined regions.</p><p>我们会在下面描述我们的应用程序如何区分定义良好的区域和非定义良好的区域。应用程序不需要进一步区分各种不同的非定义良好的区域。</p><p>Data mutations may be writes or record appends. A write causes data to be written at an application-specified file offset. A record append causes data (the “record”) to be appended atomically at least once even in the presence of concurrent mutations, but at an offset of GFS’s choosing (Section 3.3). (In contrast, a “regular” append is merely a write at an offset that the client believes to be the current end of file.) The offset is returned to the client and marks the beginning of a defined region that contains the record. In addition, GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data.</p><p>数据变更可能是写入或者是记录追加。写入会将数据写入到应用程序指定的文件偏移位置。记录追加会使数据（也即记录record）至少原子性的追加一次，即使是在并发变更的情况下，但是偏移位置是由GFS决定的（相比之下，「常规」追加只是一次客户端认为的文件当前结尾偏移处的写入操作）。偏移量返回给客户端，并且标记包含追加记录的定义良好的区域的开始位置。此外，GFS可能会在它们之间插入填充或者是记录副本。这些插入的内容会占据被认为是不一致的区域，通常它们比用户数据小很多。</p><p>After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation. GFS achieves this by </p><ul><li>(a) applying mutations to a chunk in the same order on all its replicas(Section 3.1),</li><li>and (b) using chunk version numbers to detect any replica that has become stale because it has missed mutations while its chunk server was down (Section 4.5). Stale replicas will never be involved in a mutation or given to clients asking the master for chunk locations. They are garbage collected at the earliest opportunity.</li></ul><p>在一系列成功的变更后，文件变更区域会被保证是定义良好的，并且包含最后一次变更写入的数据。GFS通过以下方式来实现：</p><ul><li>将对一个Chunk的变更以同样的顺序应用到该Chunk的所有副本中；</li><li>使用Chunk版本号来检测那些由于Chunk Server 宕机而错过变更数据的陈旧副本。陈旧的副本将不会在参与数据变更或者向客户端响应请求。它们会优先参与垃圾回收。</li></ul><p>Since clients cache chunk locations, they may read from a stale replica before that information is refreshed. This window is limited by the cache entry’s timeout and the next open of the file, which purges from the cache all chunk information for that file. Moreover, as most of our files are append-only, a stale replica usually returns a premature end of chunk rather than outdated data. When a reader retries and contacts the master, it will immediately get current chunk locations.</p><p>客户端会缓存Chunk的位置信息，因此在信息刷新前，它们可能会从那些陈旧的副本中读取数据。此时间窗口会被缓存条目的超时时间以及下次打开文件的限制，这种文件的打开会使缓存清除掉所有该文件的Chunk信息。此外，因为我们的文件通常只是会被追加数据的，所以一个陈旧的副本通常返回的是一个提前结束的Chunk，而不是一个过时的数据。当一个读取者重试并且联系Master时，它会立即得到该Chunk当前的位置信息。</p><p>Long after a successful mutation, component failures can of course still corrupt or destroy data. GFS identifies failed chunk servers by regular handshakes between master and all chunk servers and detects data corruption by checksumming (Section 5.2). Once a problem surfaces, the data is restored from valid replicas as soon as possible (Section 4.3). A chunk is lost irreversibly only if all its replicas are lost before GFS can react, typically within minutes. Even in this case, it becomes unavailable, not corrupted: applications receive clear errors rather than corrupt data.</p><p>在数据变更很久之后，组件的故障仍然可能会损害或破坏数据。GFS通过定期的Master和所有Chunk Server之间的「握手」，来识别发生故障的Chunk Server，并且通过「检验和」来检测数据的损坏。一旦发生问题，数据将会尽快从可用副本中恢复。只有在Master反应之前丢失掉所有的Chunk副本（通常是几分钟以内），Chunk才会出现不可逆的丢失。即使是在这种情况，也只会发生Chunk的不可用而不是数据的损坏：应用程序会收到错误信息，而不是损坏的数据。</p><h3 id="2-7-2-Implications-for-Applications"><a href="#2-7-2-Implications-for-Applications" class="headerlink" title="2.7.2 Implications for Applications"></a>2.7.2 Implications for Applications</h3><p>GFS applications can accommodate the relaxed consistency model with a few simple techniques already needed for other purposes: relying on appends rather than overwrites, checkpointing, and writing self-validating, self-identifying records.</p><p>GFS应用程序可以通过已经被其他目的所需要的简单技术来实现这种宽松的一致性模型，例如：依赖于追加而不是覆盖写操作，检查点，写入时自我验证，自我标识记录。</p><h1 id="3-System-Interactions"><a href="#3-System-Interactions" class="headerlink" title="3 System Interactions"></a>3 System Interactions</h1><p>We designed the system to minimize the master’s involvement in all operations. With that background, we now describe how the client, master, and chunk servers interact to implement data mutations, atomic record append, and snapshot.</p><p>我们以减少Master参与所有操作的目的来设计这个系统。在这个背景之下，我们现在来描述客户端、Master以及Chunk Server之间是如何交互的以实现：数据变更、原子性的记录追加和快照。</p><h2 id="3-1-Leases-and-Mutation-Order"><a href="#3-1-Leases-and-Mutation-Order" class="headerlink" title="3.1 Leases and Mutation Order"></a>3.1 Leases and Mutation Order</h2><p>A mutation is an operation that changes the contents or metadata of a chunk such as a write or an append operation. Each mutation is performed at all the chunk’s replicas. We use leases to maintain a consistent mutation order across replicas. The master grants a chunk lease to one of the replicas, which we call the primary. The primary picks a serial order for all mutations to the chunk. All replicas follow this order when applying mutations. Thus, the global mutation order is defined first by the lease grant order chosen by the master, and within a lease by the serial numbers assigned by the primary.</p><p>变更是一种改变Chunk内容或元数据的操作，例如写和追加操作。每一个变更都会应用到相应Chunk的所有副本之中。我们使用租约来保证所有副本之间变更顺序的一致性。Master向其中一个包含指定副本的Chunk Server授予Chunk租约，这时我们将其称为主副本。主副本会为Chunk的所有变更操作制定一个串型化的顺序。所有的副本都会按照这个顺序来应用变更操作。因此，全局的变更操作的顺序首先由Master选择的租约授予顺序所决定，而同一个租约内的变更顺序则是由选择的主副本定义的。</p><p>The lease mechanism is designed to minimize management overhead at the master. A lease has an initial timeout of 60 seconds. However, as long as the chunk is being mutated, the primary can request and typically receive extensions from the master indefinitely. These extension requests and grants are piggybacked on the HeartBeat messages regularly exchanged between the master and all chunk servers. The master may sometimes try to revoke a lease before it expires (e.g., when the master wants to disable mutations on a file that is being renamed). Even if the master loses communication with a primary, it can safely grant a new lease to another replica after the old lease expires.</p><p>租约机制旨在最大程度的减少Master的管理开销。租约的初始超时时间为60秒。然而，只要Chunk正在被变更，选择的主副本就可以一直向Master请求延长租约。这些延长租约的请求和响应授权通过Master和Chunk Server之间周期交换的心跳报文来传送。Master有时也会在租约到期之前撤销租约（例如，Master想要禁用一个正在重命名的文件上的变更时）。即使Master与主副本断联了，Master也可以在旧的租约到期之后安全的将租约授予给另一个副本。</p><p>In Figure 2, we illustrate this process by following the control flow of a write through these numbered steps.</p><ol><li>The client asks the master which chunk server holds the current lease for the chunk and the locations of the other replicas. If no one has a lease, the master grants one to a replica it chooses (not shown).</li><li>The master replies with the identity of the primary and the locations of the other (secondary) replicas. The client caches this data for future mutations. It needs to contact the master again only when the primary becomes unreachable or replies that it no longer holds a lease.</li><li>The client pushes the data to all the replicas. A client can do so in any order. Each chunk server will store the data in an internal LRU buffer cache until the data is used or aged out. By decoupling the data flow from the control flow, we can improve performance by scheduling the expensive data flow based on the network topology regardless of which chunk server is the primary. Section 3.2 discusses this further.</li><li>Once all the replicas have acknowledged receiving the data, the client sends a write request to the primary. The request identifies the data pushed earlier to all of the replicas. The primary assigns consecutive serial numbers to all the mutations it receives, possibly from multiple clients, which provides the necessary serialization. It applies the mutation to its own local state in serial number order.</li><li>The primary forwards the write request to all secondary replicas. Each secondary replica applies mutations in the same serial number order assigned by the primary.</li><li>The secondaries all reply to the primary indicating that they have completed the operation.</li><li>The primary replies to the client. Any errors encountered at any of the replicas are reported to the client. In case of errors, the write may have succeeded at the primary and an arbitrary subset of the secondary replicas. (If it had failed at the primary, it would not<br>have been assigned a serial number and forwarded.)The client request is considered to have failed, and the modified region is left in an inconsistent state. Our client code handles such errors by retrying the failed mutation. It will make a few attempts at steps (3)through (7) before falling back to a retry from the beginning of the write.</li></ol><p>在图2中我们将通过步骤的编号来表示一个写操作的控制流程：</p><ol><li>客户端会向Master询问哪个Chunk Server获取到了指定Chunk的当前租约，以及其他副本的位置信息。如果没有Chunk Server获取到租约，则Master会将租约授予到其选择的一个副本。</li><li>Master回复主副本的标识，以及其他副本的位置。客户端会缓存此数据，以在将来数据变更时使用。只有当主副本不可达或者回复不再持有租约时，客户端才会需要再次联系Master。</li><li>客户端会将数据推送到所有的副本。客户端可以按照任何顺序执行此操作。每个Chunk Server会将该数据存储到其LRU缓冲区缓存中，直到数据被使用或者超时。通过将数据流和控制流解耦，我们可以通过基于网络拓扑来调动昂贵的数据流，而不管哪个Chunk Server是主副本。3.2节将会进一步讨论这些。</li><li>一旦所有的副本都确认接收到数据，客户端就会向主副本发送写请求。该写请求会标识之前推送到所有副本的数据。主副本会将其接收到的所有变更安排一个连续的序列号来提供必要的串型化，这些变更操作可能来自多个客户端。它会将所有变更按照序列号应用到本地的副本上。</li><li>主副本会将写请求向前传递给所有的次副本。次副本将会按照主副本指定的同样的序列号顺序将所有变更应用到本地。</li><li>次副本会响应主副本以暗示它们已经完成这些操作。</li><li>主副本响应客户端。所有副本所遇到的错误信息都会向客户端报告。在出现错误时，写操作可能已经成功应用到主副本和一些次副本。（如果在主副本上已经出现错误，它将不会再把序列号信息发送给其他次副本）客户端请求将被认为是失败的，修改过的区域将会处于不一致的状态。我们的客户端代码将会通过重试这些变更来处理遇到的错误。他将会先在步骤3到7之间尝试几次后重试这个写操作。</li></ol><h2 id="3-2-Data-Flow"><a href="#3-2-Data-Flow" class="headerlink" title="3.2 Data Flow"></a>3.2 Data Flow</h2><p>We decouple the flow of data from the flow of control to use the network efficiently. While control flows from the client to the primary and then to all secondaries, data is pushed linearly along a carefully picked chain of chunk servers in a pipelined fashion. Our goals are to fully utilize each machine’s network bandwidth, avoid network bottlenecks and high-latency links, and minimize the latency to push through all the data.</p><p>我们将控制流与数据流分离，以高效的利用网络。当控制流从客户端流向主副本，然后会流向所有的次副本，数据流将会以流水线方式按照精心挑选的Chunk Server链线性推送。我们的目标是充分利用每个机器的网络带宽，避免网络瓶颈和高延迟链路，并最大程度的减少推送数据的延迟。</p><p>To fully utilize each machine’s network bandwidth, the data is pushed linearly along a chain of chunk servers rather than distributed in some other topology (e.g., tree). Thus, each machine’s full outbound bandwidth is used to transfer the data as fast as possible rather than divided among multiple recipients.</p><p>为了充分利用每个机器的带宽，数据晚照Chunk Server链线性推送，而不是其他分散的拓扑（例如：树）。因此，每个机器的带宽可以尽可能的全部用来传输数据而不是为多个接受者进行划分。</p><p>To avoid network bottlenecks and high-latency links (e.g., inter-switch links are often both) as much as possible, each machine forwards the data to the “closest” machine in the network topology that has not received it.</p><p>为了尽可能避免网络瓶颈以及高延迟链路，每个机器会将数据推送到在网络拓扑中没收到数据且离它最近的机器。</p><p>Finally, we minimize latency by pipelining the data transfer over TCP connections. Once a chunk server receives some data, it starts forwarding immediately. Pipelining is especially helpful to us because we use a switched network with full-duplex links. Sending the data immediately does not reduce the receive rate.</p><p>最后，我们通过流水线化TCP连接上的数据传输来最小化延迟。Chunk Server一旦接收到数据将会立即传送。流水线对我们特别有帮助，因为我们使用了全双工链路的交换网络。立即发送数据并不会降低接收速率。</p><h2 id="3-3-Atomic-Record-Appends"><a href="#3-3-Atomic-Record-Appends" class="headerlink" title="3.3 Atomic Record Appends"></a>3.3 Atomic Record Appends</h2><p>GFS provides an atomic append operation called record append. In a traditional write, the client specifies the offset at which data is to be written. Concurrent writes to the same region are not serializable: the region may end up containing data fragments from multiple clients. In a record append, however, the client specifies only the data. GFS appends it to the file at least once atomically (i.e., as one continuous sequence of bytes) at an offset of GFS’s choosing and returns that offset to the client.</p><p>GFS提供了一种被称为记录追加的原子追加操作。在传统的写入操作中，客户端要指定数据写入的偏移位置。对于同一区域的并发写操作是不能串型化的：区域的末尾可能包含来自多个客户端的数据碎片。然而在记录追加中，客户端只需要指定数据。GFS会将其至少原子性的追加到文件中一次，追加的位置是由GFS选定的。</p><p>Record append is heavily used by our distributed applications in which many clients on different machines append to the same file concurrently. Clients would need additional complicated and expensive synchronization, for example through a distributed lock manager, if they do so with traditional writes. In our workloads, such files often serve as multiple-producer/single-consumer queues or contain merged results from many different clients.</p><p>我们的分布式应用程序中会大量的使用追加操作，不同机器上的大量客户端会并发的追加到同一个文件。如果使用传统的写操作，客户端需要复杂而又昂贵的同步操作，例如通过一个分布式锁管理。在我们的工作负载中，此类文件通常作为多生产者/单消费者队列或包含来自不同客户端的合并结果。</p><p>Record append is a kind of mutation and follows the control flow in Section 3.1 with only a little extra logic at the primary. The client pushes the data to all replicas of the last chunk of the file Then, it sends its request to the primary. The primary checks to see if appending the record to the current chunk would cause the chunk to exceed the maximum size (64 MB). If so, it pads the chunk to the maximum size, tells secondaries to do the same, and replies to the client indicating that the operation should be retried on the next chunk. (Record append is restricted to be at most one-fourth of the maximum chunk size to keep worst-case fragmentation at an acceptable level.) If the record fits within the maximum size, which is the common case, the primary appends the data to its replica, tells the secondaries to write the data at the exact offset where it has, and finally replies success to the client.</p><p>记录追加是一种变更操作，遵循3.1节中提到的控制流，除了在主副本中只需要一点额外的逻辑。客户端将所有数据（直到文件的最后一个Chunk）推送到所有的副本后，它向主副本发送请求。客户端会检查将记录追加到当前Chunk后是否会超过Chunk的最大值（64MB）。如果超过的话，它会填充当前Chunk到最大值，并且告诉其他次副本做同样的操作，然后告诉客户端在下一个Chunk上重复此操作（译者注：也即将此操作转移到另一个满足大小的Chunk上进行操作）（记录追加被严格限制在Chunk最大值的四分之一，以保证产生的最严重的碎片化在可接受的范围内）。如果记录没有超过最大值，则按普通情况处理，主副本将记录追加到它的副本，并且告诉次副本将此数据写到其拥有的确切偏移处（译者注：即写到与主副本相同的位置），最后向客户端回复成功消息。</p><p>If a record append fails at any replica, the client retries the operation. As a result, replicas of the same chunk may contain different data possibly including duplicates of the same record in whole or in part. GFS does not guarantee that all replicas are byte wise identical. It only guarantees that the data is written at least once as an atomic unit.</p><p>如何任何副本追加失败，客户端将会重试此操作。因此，对于同一个Chunk，副本可能会有不同的数据，这些数据可能包含了相同记录的整个或者部分的重复值。GFS并不会保证所有的副本在位级别上保证一致性。它只保证数据在所有副本上至少原子性的写入一次。</p><h2 id="3-4-Snapshot"><a href="#3-4-Snapshot" class="headerlink" title="3.4 Snapshot"></a>3.4 Snapshot</h2><p>The snapshot operation makes a copy of a file or a directory tree (the “source”) almost instantaneously, while minimizing any interruptions of ongoing mutations. Our users use it to quickly create branch copies of huge data sets (and often copies of those copies, recursively), or to checkpoint the current state before experimenting with changes that can later be committed or rolled back easily.</p><p>快照可以快速的创建一个文件或目录树的拷贝，而且能够最小化对于正在执行的变更的中断。我们的用户用它来创建一个大型数据集的分支，或者创建当前状态的检查点以验证稍后将要提交的更改或者快速回滚。</p><p>Like AFS , we use standard copy-on-write techniques to implement snapshots. When the master receives a snapshot request, it first revokes any outstanding leases on the chunks in the files it is about to snapshot. This ensures that any subsequent writes to these chunks will require an interaction with the master to find the lease holder. This will give the master an opportunity to create a new copy of the chunk first.</p><p>像AFS一样，我们使用标准的写时复制技术来实现快照。当Master接收到快照请求，它首先撤销关于快照的文件的有关Chunk的租约。这就确保对于这些Chunk的后续写操作都要先与Master交互以获得租约持有者。这首先给了Master机会去创建对于Chunk的一个新的拷贝。</p><p>After the leases have been revoked or have expired, the master logs the operation to disk. It then applies this log record to its in-memory state by duplicating the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files.</p><p>当租约被撤销或者到期后，Master将操作记录到磁盘。然后通过复制源文件或目录树的元数据，将日志记录应用到其内存状态。新创建的快照文件和源文件指向相同的块。</p><p>The first time a client wants to write to a chunk C after the snapshot operation, it sends a request to the master to find the current lease holder. The master notices that the reference count for chunk C is greater than one. It defers replying to the client request and instead picks a new chunk handle C’. It then asks each chunk server that has a current replica of C to create a new chunk called C’. By creating the new chunk on the same chunk servers as the original, we ensure that the data can be copied locally, not over the network(our disks are about three times as fast as our 100 Mb Ethernet links). From this point, request handling is no different from that for any chunk: the master grants one of the replicas a lease on the new chunk C’ and replies to the client, which can write the chunk normally, not knowing that it has just been created from an existing chunk.</p><p>客户端在快照操作后第一次想要写入Chunk C时，它向Master发送请求以查询当前合约的持有者。Master注意到Chunk C的引用计数大于1。它延迟向客户端回复请求，而且选择一个新的Chunk Handle C‘。然后它要求所有拥有Chunk C副本的Chunk Server创建一个新的叫做C‘的Chunk。通过在与原始Chunk Server相同的Chunk Server上创建新的Chunk，我们可以确保数据是在本地复制的，而不是通过网络（我们的磁盘速度大概是100MB以太网链路的三倍）。通过这一点，对于任何Chunk的请求处理都没什么不同：master将新创建的Chunk C‘的租约授予给一个副本Chunk Server，然后回复客户端可以正常写入这个Chunk了，客户端不会知道这是刚刚从现有的Chunk中创建出来的副本。</p><h1 id="4-Master-Operation"><a href="#4-Master-Operation" class="headerlink" title="4 Master Operation"></a>4 Master Operation</h1><p>The master executes all namespace operations. In addition, it manages chunk replicas throughout the system: it makes placement decisions, creates new chunks and hence replicas, and coordinates various system-wide activities to keep chunks fully replicated, to balance load across all the chunk servers, and to reclaim unused storage. We now discuss each of these topics.</p><p>Master执行所有的命名空间操作。此外，它还管理整个系统的Chunk副本：它做出放置决策，创建新的Chunk和副本，协调整个系统范围内的活动以保证Chunk被备份，平衡所有Chunk Server之间的负载，以及回收未使用的存储。我们现在将逐个讨论这些话题。</p><h2 id="4-1-Namespace-Management-and-Locking"><a href="#4-1-Namespace-Management-and-Locking" class="headerlink" title="4.1 Namespace Management and Locking"></a>4.1 Namespace Management and Locking</h2><p>Many master operations can take a long time: for example, a snapshot operation has to revoke chunk server leases on all chunks covered by the snapshot. We do not want to delay other master operations while they are running. Therefore, we allow multiple operations to be active and use locks over regions of the namespace to ensure proper serialization.</p><p>许多的Master操作需要花费很长的时间：比如，一个快照操作不得不使快照所覆盖的所有的块都撤销其租约。我们并不想延迟其他正在运行的Master操作。因此，我们允许多个操作处于活跃状态，并且在命名空间的区域上使用锁来保证正确的序列化。</p><p>Unlike many traditional file systems, GFS does not have a per-directory data structure that lists all the files in that directory. Nor does it support aliases for the same file or directory (i.e, hard or symbolic links in Unix terms). GFS logically represents its namespace as a lookup table mapping full pathnames to metadata. With prefix compression, this table can be efficiently represented in memory. Each node in the namespace tree (either an absolute file name or an absolute directory name) has an associated read-write lock.</p><p>与许多的传统文件系统不同，GFS并没有一个能列举出目录中所有文件的目录数据结构。此外，它也不支持对于同一个文件和目录的别名（例如Unix系统中的硬链接和符号链接）。GFS在逻辑上将其命名空间表示为将完整的目录名映射到元数据的查找表。通过前缀压缩能有效的在内存中展示该表。命名空间树中的每个节点（包括绝对文件名和绝对目录名）都有一个关联的读写锁。</p><p>Each master operation acquires a set of locks before it runs. Typically, if it involves <code>/d1/d2/.../dn/leaf,</code> it will acquire read-locks on the directory names <code>/d1, /d1/d2, ..., /d1/d2/.../dn</code>, and either a read lock or a write lock on the full pathname <code>/d1/d2/.../dn/leaf</code>.Note that leaf may be a file or directory depending on the operation.</p><p>每个Master的操作在它运行之前都需要获得一个锁的集合。典型的，如果它需要操作<code>/d1/d2/.../dn/leaf</code> ，那么它需要获得在目录<code>/d1,/d1/d2,.../d1/d2/.../dn</code> 上的读锁，以及一个在全路径<code>/d1/d2/..../dn/leaf</code>上的读锁或写锁。需要注意的是，leaf可能是个文件或目录，这取决于具体的操作。</p><p>We now illustrate how this locking mechanism can prevent a file <code>/home/user/foo</code> from being created while <code>/home/user</code> is being snapshotted to <code>/save/user</code>. The snapshot operation acquires read locks on <code>/home</code> and <code>/save</code>, and write locks on <code>/home/user</code> and <code>/save/user</code>. The file creation acquires read locks on <code>/home</code> and <code>/home/user</code>, and a write lock on <code>/home/user/foo</code>. The two operations will be serialized properly because they try to obtain conflicting locks on <code>/home/user</code>. File creation does not require a write lock on the parent directory because there is no “directory”, or <em><code>inode-like</code></em>, data structure to be protected from modification. The read lock on the name is sufficient to protect the parent directory from deletion.</p><p>我们现在来列举锁机制是如何避免<code>/home/user/foo</code>被创建的，当在创建<code>/home/user</code>的快照<code>/save/user</code>时。快照操作需要获得<code>/home</code>和<code>/save</code>的读锁，以及<code>/home/user</code>和<code>/save/user</code>的写锁。文件创建需要获得<code>/home</code>和<code>/home/user</code>的读锁，以及<code>/home/user/foo</code>的写锁。这两个操作将被正确的序列化，因为它们试图获得在<code>/home/user</code>上的冲突锁。文件创建不需要获得副目录的写锁，因为这里并没有目录或者类似<code>inode</code>的数据结构需要被保护以防止修改。读锁已经足够用来保护副目录被删除。</p><p>One nice property of this locking scheme is that it allows concurrent mutations in the same directory. For example, multiple file creations can be executed concurrently in the same directory: each acquires a read lock on the directory name and a write lock on the file name. The read lock on the directory name suffices to prevent the directory from being deleted, renamed, or snapshotted. The write locks on file names serialize attempts to create a file with the same name twice.</p><p>这种锁机制的一个好处是允许同一个目录内的并发变更操作。例如，可以在同一个目录内同时执行多个文件的创建操作：每个创建操作需要一个对于目录名的读锁，以及对于文件名的写锁。目录名的写锁用于放置目录被删除、重命名或被执行快照操作。在文件名上的写锁用于序列化对于同一个文件名的创建操作。</p><p>Since the namespace can have many nodes, read-write lock objects are allocated lazily and deleted once they are not in use. Also, locks are acquired in a consistent total order to prevent deadlock: they are first ordered by level in the namespace tree and lexicographically within the same level.</p><p>由于命名空间可以有多个节点，所以读写锁对象会被惰性分配，一旦不使用就被删除。 此外，以一致的总顺序获取锁以防止死锁：它们首先在命名空间树中按级别排序，并在同一级别内按字典顺序排列。</p><h2 id="4-2-Replica-Placement"><a href="#4-2-Replica-Placement" class="headerlink" title="4.2 Replica Placement"></a>4.2 Replica Placement</h2><p>A GFS cluster is highly distributed at more levels than one. It typically has hundreds of chunk servers spread across many machine racks. These chunk servers in turn may be accessed from hundreds of clients from the same or different racks. Communication between two machines on different racks may cross one or more network switches. Additionally, bandwidth into or out of a rack may be less than the aggregate bandwidth of all the machines within the rack. Multi-level distribution presents a unique challenge to distribute data for scalability, reliability, and availability.</p><p>GFS在各个层级上都实现了高度的分布式。它通常由几百个分布在多个机架上的Chunk Server组成。这些Chunk Server又可能被几百个来自相同或不同机架上的客户端访问。来自不同机架上的两个机器之间的通信可能或跨一个或多个交换机。此外，进出一个机架的带宽可能会小于一个机架上所有机器的总带宽。多层级的分布式也面临着独一无二的挑战：分布式数据的扩展性、可靠性和可用性。</p><p>The chunk replica placement policy serves two purposes: maximize data reliability and availability, and maximize network bandwidth utilization. For both, it is not enough to spread replicas across machines, which only guards against disk or machine failures and fully utilizes each machine’s network bandwidth. We must also spread chunk replicas across racks. This ensures that some replicas of a chunk will survive and remain available even if an entire rack is damaged or offline (for example, due to failure of a shared resource like a network switch or power circuit). It also means that traffic, especially reads, for a chunk can exploit the aggregate bandwidth of multiple racks. On the other hand, write traffic has to flow through multiple racks, a trade off we make willingly.</p><p>Chunk副本的放置策略主要服务于两个目的：最大化数据的可靠性和可用性，最大化利用网络带宽。对于两者来说，仅仅实现跨机器的副本是不够的，这只能保证抵抗磁盘或机器的错误，以及最大化利用每个机器的网络带宽。我们必须实现Chunk副本的跨机架。这能保证一个Chunk的副本是可用的，即使一整个机架都被破坏或者下线（例如，网络交换机和电源电路等共享资源的故障）。这也意味着，对于一个Chunk的流量特别是读操作，可以充分利用多个机架的总带宽。另一方面，写流量需要在多个机架之间进行，这也是我们自愿做出的权衡。</p><h2 id="4-3-Creation-Replication-Rebalancing"><a href="#4-3-Creation-Replication-Rebalancing" class="headerlink" title="4.3 Creation, Replication, Rebalancing"></a>4.3 Creation, Replication, Rebalancing</h2><p>Chunk replicas are created for three reasons: chunk creation, re-replication, and rebalancing.</p><p>Chunk副本的创建有三种原因：Chunk的创建，重备份，重平衡。</p><p>When the master creates a chunk, it chooses where to place the initially empty replicas. It considers several factors. (1) We want to place new replicas on chunk servers with below-average disk space utilization. Over time this will equalize disk utilization across chunk servers. (2) We want to limit the number of “recent” creations on each chunk server. Although creation itself is cheap, it reliably predicts imminent heavy write traffic because chunks are created when demanded by writes, and in our append-once-read-many workload they typically become practically read-only once they have been completely written. (3) As discussed above, we want to spread replicas of a chunk across racks.</p><p>当Master创建一个Chunk的时候，它会选择在何处放置初始化为空的副本。它会考虑以下几个因素：</p><ol><li>我们会希望将新的副本放置在低于平均磁盘利用率的Chunk Serve上。随着时间的推移，这将会平衡各个Chunk Server的磁盘利用率。</li><li>我们希望能限制在每个Chunk Server 上的「最近」创建Chunk的数量。尽管创建本身是比较廉价的，但是这能可靠的预测即将到来的大量的写流量，因为Chunk是为了写操作而创建的，并且在我们的一次写入多次读的负载模型中，一旦写入完成它们通常都是只读的。</li><li>正如我们在上面讨论的那样，我们希望实现Chunk副本的跨机架放置。</li></ol><p>The master re-replicates a chunk as soon as the number of available replicas falls below a user-specified goal. This could happen for various reasons: a chunk server becomes unavailable, it reports that  it‘s replica may be corrupted, one of its disks is disabled because of errors, or the replication goal is increased. Each chunk that needs to be re-replicated is prioritized based on several factors. One is how far it is from its replication goal. For example, we give higher priority to a chunk that has lost two replicas than to a chunk that has lost only one. In addition, we prefer to first re-replicate chunks for live files as opposed to chunks that belong to recently deleted files (see Section 4.4). Finally, to minimize the impact of failures on running applications, we boost the priority of any chunk that is blocking client progress.</p><p>Master会在当Chunk副本的数量少于用户预定义的数量时进行重备份。这可能发生在以下情况：一个Chunk Server变得不可达，它报告自己的副本可能被污染了，它的一个磁盘由于错误变得不可用了，或者预设的副本数量增加了。需要重新备份的Chunk的优先级主要有以下几个因素来确定。一个是它与备份的目标数量差了多少。例如，我们将更高的优先级给丢失了两个副本的Chunk而不是只丢失了一个副本的Chunk。</p><p>The master picks the highest priority chunk and “clones” it by instructing some chunk server to copy the chunk data directly from an existing valid replica. The new replica is placed with goals similar to those for creation: equalizing disk space utilization, limiting active clone operations on any single chunk server, and spreading replicas across racks. To keep cloning traffic from overwhelming client traffic, the master limits the numbers of active clone operations both for the cluster and for each chunk server. Additionally, each chunk server limits the amount of bandwidth it spends on each clone operation by throttling its read requests to the source chunk server.</p><p>Master挑选具有最高优先级的Chunk，并且通过命令其他Chunk Server直接通过其他可用的副本来复制Chunk数据来进行Chunk的克隆操作。这个新的副本的放置目标类似创建操作：平衡磁盘空间利用率，限制对于单个Chunk Server上的活跃克隆操作数量，实现副本的跨机架放置。为了防止克隆流量超过客户端流量，Master 限制了集群和每个Chunk服务器的活跃克隆操作的数量。 此外，每个Chunk服务器通过限制对源Chunk服务器的读取请求来限制它在每个克隆操作上花费的带宽量。</p><p>Finally, the master rebalances replicas periodically: it examines the current replica distribution and moves replicas for better disk space and load balancing. Also through this process, the master gradually fills up a new chunk server rather than instantly swamps it with new chunks and the heavy write traffic that comes with them. The placement criteria for the new replica are similar to those discussed above. In addition, the master must also choose which existing replica to remove. In general, it prefers to remove those on chunk servers with below-average free space so as to equalize disk space usage.</p><p>最后，Master会周期性的重平衡副本：它会检验当前副本的分布，移动副本以实现更好的磁盘空间和负载的平衡。通过这个过程，Master会逐渐填满一个新的Chunk Server，而不是将大量的新Chunk和随之而来的写流量来淹没它。新副本的放置标准和我们之前讨论的类似。此外，Master还必须要选择删除哪个现有的副本。通常，它更偏向于删除那些位于低于平均空闲空间Chunk Server上的副本，以平衡磁盘上的可用空间。</p><h2 id="4-4-Garbage-Collection"><a href="#4-4-Garbage-Collection" class="headerlink" title="4.4 Garbage Collection"></a>4.4 Garbage Collection</h2><p>After a file is deleted, GFS does not immediately reclaim the available physical storage. It does so only lazily during regular garbage collection at both the file and chunk levels. We find that this approach makes the system much simpler and more reliable.</p><p>文件被删除后，GFS并不会立即回收可用的物理存储。它只会在文件和Chunk级别上的常规垃圾回收期间惰性的执行这样的操作。我们发现这样可以使系统更简单和可靠。</p><h3 id="4-4-1-Mechanism"><a href="#4-4-1-Mechanism" class="headerlink" title="4.4.1 Mechanism"></a>4.4.1 Mechanism</h3><p>When a file is deleted by the application, the master logs the deletion immediately just like other changes. However instead of reclaiming resources immediately, the file is just renamed to a hidden name that includes the deletion times-tamp. During the master’s regular scan of the file system namespace, it removes any such hidden files if they have existed for more than three days (the interval is configurable). Until then, the file can still be read under the new, special name and can be undeleted by renaming it back to normal. When the hidden file is removed from the namespace, its in-memory metadata is erased. This effectively severs its links to all its chunks.</p><p>当一个文件被应用程序删除后，Master会像记录其他更改一样立刻记录删除操作。然而，文件只是被重命名为一个包含了删除时间戳的隐藏名称，而不是立刻回收资源。在Master定期扫描系统命名空间时，它会删除那些存在超过三天的隐藏文件（时间间隔是可配置的）。在此之前，仍可以使用新的特殊名称读取该文件，并且可以通过将其重命名为正常名称来取消删除该文件。 当隐藏文件从命名空间中移除时，其内存中的元数据将被擦除。 这有效地切断了它与所有块的链接。</p><p>In a similar regular scan of the chunk namespace, the master identifies orphaned chunks (i.e., those not reachable from any file) and erases the metadata for those chunks. In a HeartBeat message regularly exchanged with the master, each chunk server reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata. The chunk server is free to delete its replicas of such chunks. </p><p>在类似的Chunk命名空间的定期扫描中，Master会识别孤儿Chunk（例如那些不被任何文件可达的Chunk）并且擦除这些Chunk的元数据。在定期与Master交换的心跳报文中，每个Chunk Server都会报告它所拥有的Chunk的子集，Master会回复它已经没有其元数据的所有Chunk的标识。Chunk Server可以自由的删除这些块的副本。</p><h3 id="4-4-2-Discussion"><a href="#4-4-2-Discussion" class="headerlink" title="4.4.2 Discussion"></a>4.4.2 Discussion</h3><p>Although distributed garbage collection is a hard problem that demands complicated solutions in the context of programming languages, it is quite simple in our case. We can easily identify all references to chunks: they are in the file-to-chunk mappings maintained exclusively by the master. We can also easily identify all the chunk replicas: they are Linux files under designated directories on each chunk server. Any such replica not known to the master is “garbage.”</p><p>尽管分布式垃圾回收在编程语言的上下文中是一个需要复杂解决方案的难题，但在我们的案例中却非常简单。 我们可以很容易地识别出所有对Chunk的引用：它们位于由Master专门维护的文件到块的映射中。 我们还可以轻松识别所有Chunk副本：它们是每个Chunk Server上指定目录下的 Linux 文件。 Master不知道的任何此类副本都是“垃圾”。</p><p>The garbage collection approach to storage reclamation offers several advantages over eager deletion. First, it is simple and reliable in a large-scale distributed system where component failures are common. Chunk creation may succeed on some chunk servers but not others, leaving replicas that the master does not know exist. Replica deletion messages may be lost, and the master has to remember to resend them across failures, both its own and the chunk server’s. Garbage collection provides a uniform and dependable way to clean up any replicas not known to be useful. Second, it merges storage reclamation into the regular background activities of the master, such as the regular scans of namespaces and handshakes with chunk servers. Thus, it is done in batches and the cost is amortized. Moreover, it is done only when the master is relatively free. The master can respond more promptly to client requests that demand timely attention. Third, the delay in reclaiming storage provides a safety net against accidental, irreversible deletion.</p><p>与立刻删除相比，存储回收的垃圾回收方法提供了几个优点。首先，它在组件故障常见的大型分布式系统中简单可靠。Chunk创建可能在某些Chunk Server上成功但在其他Chunk Server上不会成功，从而留下Master不知道存在的副本。副本删除消息可能会丢失，并且 Master 必须记住在失败时重新发送它们，包括它自己的和Chunk Server的。垃圾收集提供了一种统一且可靠的方法来清理任何已知无用的副本。其次，它将存储回收合并到 Master 的常规后台活动中，例如命名空间的常规扫描和与Chunk Server的握手。因此，它是分批完成的，成本被摊销。而且，只有在Master比较空闲的时候才做。 Master 可以更迅速地响应需要及时关注的客户端请求。第三，回收存储的延迟提供了防止意外、不可逆删除的安全网。</p><h2 id="4-5-Stale-Replica-Detection"><a href="#4-5-Stale-Replica-Detection" class="headerlink" title="4.5 Stale Replica Detection"></a>4.5 Stale Replica Detection</h2><p>Chunk replicas may become stale if a chunk server fails and misses mutations to the chunk while it is down. For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas.</p><p>如果Chunk Server发生故障并且在它关闭时错过了对Chunk的变更，则Chunk副本可能会变得过时。 对于每个Chunk，Master都会维护一个Chunk版本号以区分最新和陈旧的副本。</p><p>Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-to-date replicas. The master and these replicas all record the new version number in their persistent state. This occurs before any client is notified and therefore before it can start writing to the chunk. If another replica is currently unavailable, its chunk version number will not be advanced. The master will detect that this chunk server has a stale replica when the chunk server restarts and reports its set of chunks and their associated version numbers. If the master sees a version number greater than the one in its records, the master assumes that it failed when granting the lease and so takes the higher version to be up-to-date.</p><p>每当Master授予一个Chunk新的租约时，它就会增加Chunk版本号并通知最新的副本。 Master 和这些副本都在它们的持久状态中记录了新的版本号。 这发生在任何客户端被通知之前，因此在它可以开始写入Chunk之前。 如果另一个副本当前不可用，则其Chunk版本号不会继续增加。 当Chunk Server重新启动并报告其Chunk集合及其相关联的版本号时，Master将检测到该Chunk Server具有过时的副本。 如果 Master 看到版本号大于其记录中的版本号，则 Master 假定它在授予租约时失败，因此将更高的版本更新为最新版本。</p><h1 id="5-Fault-Tolerance-And-Diagnosis"><a href="#5-Fault-Tolerance-And-Diagnosis" class="headerlink" title="5 Fault Tolerance And Diagnosis"></a>5 Fault Tolerance And Diagnosis</h1><p>One of our greatest challenges in designing the system is dealing with frequent component failures. The quality and quantity of components together make these problems more the norm than the exception: we cannot completely trust the machines, nor can we completely trust the disks. Component failures can result in an unavailable system or, worse, corrupted data. We discuss how we meet these challenges and the tools we have built into the system to diagnose problems when they inevitably occur.</p><p>我们在设计系统时遇到的最大的挑战之一是处理频繁的组件故障。组件的质量和数量共同导致这些问题成为常态而不是意外：我们既不能完全信任这些机器，也不能完全信任这些磁盘。组件故障会导致系统不可用，甚至更严重的是会导致数据的损坏。我们讨论了我们是如何应对这些挑战的，以及我们在系统中内置的工具，以便在问题不可避免地发生时进行诊断。</p><h2 id="5-1-High-Availability"><a href="#5-1-High-Availability" class="headerlink" title="5.1 High Availability"></a>5.1 High Availability</h2><p>Among hundreds of servers in a GFS cluster, some are bound to be unavailable at any given time. We keep the overall system highly available with two simple yet effective strategies: fast recovery and replication.</p><p>在GFS的数百台机器中，在任何给定的时间总有些机器是不可用的。我们通过两个简单却有效的策略来保证整个系统的高可用性：快速恢复和备份。</p><h3 id="5-1-1-Fast-Recovery"><a href="#5-1-1-Fast-Recovery" class="headerlink" title="5.1.1 Fast Recovery"></a>5.1.1 Fast Recovery</h3><p>Both the master and the chunk server are designed to restore their state and start in seconds no matter how they terminated. In fact, we do not distinguish between normal and abnormal termination; servers are routinely shut down just by killing the process. Clients and other servers experience a minor hiccup as they time out on their outstanding requests, reconnect to the restarted server, and retry. Section 6.2.2 reports observed startup times.</p><p>Master和Chunk Server都被设计为恢复它们的状态和在几秒后重启而不管他们是如何被终止的。实际上，我们并不会区分正常和异常终止。服务器会例行的通过杀死进程来关闭。客户端和其他服务器在处理未完成的请求时会遇到小问题，重新连接到重新启动的服务器并重试。 第 6.2.2 节报告观察到的启动时间。</p><h3 id="5-1-2-Chunk-Replication"><a href="#5-1-2-Chunk-Replication" class="headerlink" title="5.1.2 Chunk Replication"></a>5.1.2 Chunk Replication</h3><p>As discussed earlier, each chunk is replicated on multiple chunk servers on different racks. Users can specify different replication levels for different parts of the file namespace. The default is three. The master clones existing replicas as needed to keep each chunk fully replicated as chunk servers go offline or detect corrupted replicas through checksum verification (see Section 5.2). Although replication has served us well, we are exploring other forms of cross-server redundancy such as parity or erasure codes for our increasing read- only storage requirements. We expect that it is challenging but manageable to implement these more complicated redundancy schemes in our very loosely coupled system be- cause our traffic is dominated by appends and reads rather than small random writes.</p><p>正如前面讨论的那样，每个Chunk被复制到多个位于不同机架上的Chunk Server上。用户可以为文件命名空间的不同部分设置不同的备份级别。默认为3。</p><h3 id="5-1-3-Master-Replication"><a href="#5-1-3-Master-Replication" class="headerlink" title="5.1.3 Master Replication"></a>5.1.3 Master Replication</h3><p>The master state is replicated for reliability. Its operation log and checkpoints are replicated on multiple machines. A mutation to the state is considered committed only after its log record has been flushed to disk locally and on all master replicas. For simplicity, one master process remains in charge of all mutations as well as background activities such as garbage collection that change the system internally. When it fails, it can restart almost instantly. If its machine or disk fails, monitoring infrastructure outside GFS starts a new master process elsewhere with the replicated operation log. Clients use only the canonical name of the master (e.g. gfs-test), which is a DNS alias that can be changed if the master is relocated to another machine.</p><p>Master的状态被备份以保证可靠性。它的操作日志和检查点被复制到多台机器上。对于状态的变更只有当它的日志记录被刷新到本地磁盘和所有的Master副本上后才会被确认提交。为了简单起见，一个Master进程负责处理所有的变更和后台活动，就像更改内部系统的垃圾回收那样。当出现故障时，它几乎可以立即重启。如果它的机器或者磁盘出现故障，GFS之外的监控基础设施会在其他地方重新启动一个带有复制的操作日志的新的Master进程。客户端仅使用Master 的规范名称（例如 gfs-test），这是一个 DNS 别名，如果 master 重新定位到另一台机器，则可以更改该别名。</p><p>Moreover, “shadow” masters provide read-only access to the file system even when the primary master is down. They are shadows, not mirrors, in that they may lag the primary slightly, typically fractions of a second. They enhance read availability for files that are not being actively mutated or applications that do not mind getting slightly stale results. In fact, since file content is read from chunk servers, applications do not observe stale file content. What could be stale within short windows is file metadata, like directory contents or access control information.</p><p>此外，「影子」Master提供对文件系统的只读访问，即使主Master宕掉。它们是影子，而不是镜子，因为它们可能稍微滞后于主Master，通常是几分之一秒。 它们增强了未主动变更的文件或不介意获得稍微过时的结果的应用程序的读取可用性。 事实上，由于文件内容是从Chunk Server读取的，应用程序不会观察到陈旧的文件内容。 在短窗口中可能过时的是文件元数据，如目录内容或访问控制信息。</p><p>To keep itself informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does. Like the primary, it polls chunk servers at startup (and infrequently thereafter) to locate chunk replicas and exchanges frequent handshake messages with them to monitor their status. It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas.</p><p>为了保证它被通知，影子Master读取不断增长的操作日志的副本，并且按照和主Master同样的更改序列应用到它的数据结构。与主Master一样，它在启动时（之后很少）轮询Chunk Server以定位Chunk副本并与它们交换频繁的握手消息以监控它们的状态。 它仅依赖于主Master来更新由主Master创建和删除副本的决定所导致的副本位置更新。</p><h2 id="5-2-Data-Integrity"><a href="#5-2-Data-Integrity" class="headerlink" title="5.2 Data Integrity"></a>5.2 Data Integrity</h2><p>Each chunk server uses checksumming to detect corruption of stored data. Given that a GFS cluster often has thousands of disks on hundreds of machines, it regularly experiences disk failures that cause data corruption or loss on both the read and write paths. (See Section 7 for one cause.) We can recover from corruption using other chunk replicas, but it would be impractical to detect corruption by comparing replicas across chunk servers. Moreover, divergent replicas may be legal: the semantics of GFS mutations, in particular atomic record append as discussed earlier, does not guarantee identical replicas. Therefore, each chunk server must independently verify the integrity of its own copy by maintaining checksums.</p><p>每个Chunk Server使用检验和来检测存储数据的损坏。因为每个GFS集群通常在几百台机器上有几千个磁盘，这会经常遇到磁盘故障，并导致在读或写路径上的数据损坏和丢失。我们可以使用其他的Chunk副本来从损坏中恢复数据，但通过跨Chunk Server的方式来比较副本以检验数据损坏是不切实际的。此外，不同的副本可能是合法的：GFS变更的语义，特别是在我们之前讨论过的原子追加记录上，并不会保证一致的副本。因此，每个Chunk Server必须通过维护独立检验和的方式来保证它自己副本数据的完整性。</p><p>A chunk is broken up into 64 KB blocks. Each has a corresponding 32 bit checksum. Like other metadata, checksums are kept in memory and stored persistently with logging, separate from user data.</p><p>每个Chunk被划分为64KB大小的块。每个块都有对应的32位的检验和。像元数据一样，检验和被保存在内存中，并通过日志的方式持久化，独立于用户数据。</p><p>For reads, the chunk server verifies the checksum of data blocks that overlap the read range before returning any data to the requester, whether a client or another chunk server. Therefore chunk servers will not propagate corruptions to other machines. If a block does not match the recorded checksum, the chunk server returns an error to the requestor and reports the mismatch to the master. In response, the requestor will read from other replicas, while the master will clone the chunk from another replica. After a valid new replica is in place, the master instructs the chunk server that reported the mismatch to delete its replica.</p><p>对于读操作，Chunk Server在将数据返回给请求者之前（无论是客户端还是其他的Chunk Server），都会验证读操作范围内的数据块的检验和。因此，Chunk Server不会将损坏的数据传播到其他机器。如果一个块不匹配记录的检验和，Chunk Server将会向请求者返回一个错误信息，并且向Master报告不匹配信息。作为响应，请求者将会从其他的副本读取数据，并且Master将会从其他的副本克隆Chunk。在有效的新副本就位后，Master会指示报告不匹配的Chunk Server删除其副本。</p><p>Checksumming has little effect on read performance for several reasons. Since most of our reads span at least a few blocks, we need to read and checksum only a relatively small amount of extra data for verification. GFS client code further reduces this overhead by trying to align reads at checksum block boundaries. Moreover, checksum lookups and comparison on the chunk server are done without any I/O, and checksum calculation can often be overlapped with I/Os.</p><p>出于多个原因，检验和对读操作的性能机会没有影响。因为我们的读操作至少跨越几个块，我们只需要读取和检验相对很少的额外数据进行验证。GFS客户端代码尝试通过在检验和的块边界对齐读取以进一步减少该开销。此外，Chunk Server上的检验和查找和比较是在没有任何IO的情况下完成的，并且检验和的计算通常会与IO重叠。</p><p>Checksum computation is heavily optimized for writes that append to the end of a chunk(as opposed to writes that overwrite existing data) because they are dominant in our workloads. We just incrementally update the checksum for the last partial checksum block, and compute new checksums for any brand new checksum blocks filled by the append. Even if the last partial checksum block is already corrupted and we fail to detect it now, the new checksum value will not match the stored data, and the corruption will be detected as usual when the block is next read.</p><p>检验和计算针对附加到块的末尾的写入（而不是覆盖现有数据的写入）因为在我们的工作负载中它们占主导地位。我们只会增量更新最后部分检验和块的检验和，并为由追加填充得到的新的检验和块计算新的检验和。即使最后的部分检验和块已经损坏了，而且我们现在没法检测到它，新的检验和值也不会匹配到存储的数据，并且会在下次读取块时检测到损坏。</p><p>In contrast, if a write overwrites an existing range of the chunk, we must read and verify the first and last blocks of the range being overwritten, then perform the write, and finally compute and record the new checksums. If we do not verify the first and last blocks before overwriting them partially, the new checksums may hide corruption that exists in the regions not being overwritten.</p><p>相反，如果写入操作覆盖写了Chunk的现有范围，我们必须读取和检测覆盖写范围内的第一个和最后一个块，然后执行写入，最后计算并记录新的检验和。如果我们不对部分覆盖写范围内的第一个和最后一个块进行验证，新的检验和可能会隐藏存在于覆盖写范围之外的损坏。</p><p>During idle periods, chunk servers can scan and verify the contents of inactive chunks. This allows us to detect corruption in chunks that are rarely read. Once the corruption is detected, the master can create a new uncorrupted replica and delete the corrupted replica. This prevents an inactive but corrupted chunk replica from fooling the master into thinking that it has enough valid replicas of a chunk.</p><p>在空闲时期，Chunk Server会扫描和验证非活动Chunk的内容。这使我们可以检测到那些很少读取的Chunk中的损坏。一旦检测到损坏，Master就可以创建一个新的未损坏的副本并删除已损坏的副本。这避免了不活跃但已损坏的Chunk副本欺骗Master，使其以为我们已经拥有了足够的可用Chunk副本。</p><h2 id="5-3-Diagnostic-Tools"><a href="#5-3-Diagnostic-Tools" class="headerlink" title="5.3 Diagnostic Tools"></a>5.3 Diagnostic Tools</h2><p>Extensive and detailed diagnostic logging has helped immeasurably in problem isolation, debugging, and performance analysis, while incurring only a minimal cost. Without logs, it is hard to understand transient, non-repeatable interactions between machines. GFS servers generate diagnostic logs that record many significant events (such as chunk servers going up and down) and all RPC requests and replies. These diagnostic logs can be freely deleted without affecting the correctness of the system. However, we try to keep these logs around as far as space permits.</p><p>广泛而详细的诊断日志在问题隔离、调试和性能分析方面起到了不可估量的作用，同时只产生了最低限度的成本。 没有日志，就很难理解机器之间短暂的、不可重复的交互。 GFS 服务器生成诊断日志，来记录许多重要事件（例如Chunk Server启动和关闭）以及所有 RPC 请求和回复。 这些诊断日志可以随意删除，不影响系统的正确性。 但是，我们会尽量在空间允许的范围内保留这些日志。</p><p>The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written. By matching requests with replies and collating RPC records on different machines, we can reconstruct the entire interaction history to diagnose a problem. The logs also serve as traces for load testing and performance analysis.</p><p>RPC 日志包括在线路上发送的确切请求和响应，但正在读取或写入的文件数据除外。 通过将请求与回复匹配并整理不同机器上的 RPC 记录，我们可以重建整个交互历史以诊断问题。 日志还用作负载测试和性能分析的跟踪。</p><p>The performance impact of logging is minimal (and far outweighed by the benefits) because these logs are written sequentially and asynchronously. The most recent events are also kept in memory and available for continuous online monitoring.</p><p>日志记录对性能的影响很小（并且远远超过好处），因为这些日志是按顺序和异步写入的。 最近的事件也保存在内存中，可用于持续在线监控。</p><h1 id="6-Measurements"><a href="#6-Measurements" class="headerlink" title="6 Measurements"></a>6 Measurements</h1><p>以下内容略。</p><h2 id="6-1-Micro-benchmarks"><a href="#6-1-Micro-benchmarks" class="headerlink" title="6.1 Micro-benchmarks"></a>6.1 Micro-benchmarks</h2><h3 id="6-1-1-Reads"><a href="#6-1-1-Reads" class="headerlink" title="6.1.1 Reads"></a>6.1.1 Reads</h3><h3 id="6-1-2-Writes"><a href="#6-1-2-Writes" class="headerlink" title="6.1.2 Writes"></a>6.1.2 Writes</h3><h3 id="6-1-3-Record-Appends"><a href="#6-1-3-Record-Appends" class="headerlink" title="6.1.3 Record Appends"></a>6.1.3 Record Appends</h3><h2 id="6-2-Real-World-Cluster"><a href="#6-2-Real-World-Cluster" class="headerlink" title="6.2 Real World Cluster"></a>6.2 Real World Cluster</h2><h3 id="6-2-1-Storage"><a href="#6-2-1-Storage" class="headerlink" title="6.2.1 Storage"></a>6.2.1 Storage</h3><h3 id="6-2-2-Metadata"><a href="#6-2-2-Metadata" class="headerlink" title="6.2.2 Metadata"></a>6.2.2 Metadata</h3><h3 id="6-2-3-Read-and-Write-Rates"><a href="#6-2-3-Read-and-Write-Rates" class="headerlink" title="6.2.3 Read and Write Rates"></a>6.2.3 Read and Write Rates</h3><h3 id="6-2-4-Master-Load"><a href="#6-2-4-Master-Load" class="headerlink" title="6.2.4 Master Load"></a>6.2.4 Master Load</h3><h3 id="6-2-5-Recovery-Time"><a href="#6-2-5-Recovery-Time" class="headerlink" title="6.2.5 Recovery Time"></a>6.2.5 Recovery Time</h3><h2 id="6-3-Workload-Breakdown"><a href="#6-3-Workload-Breakdown" class="headerlink" title="6.3 Workload Breakdown"></a>6.3 Workload Breakdown</h2><h3 id="6-3-1-Methodology-and-Caveats"><a href="#6-3-1-Methodology-and-Caveats" class="headerlink" title="6.3.1 Methodology and Caveats"></a>6.3.1 Methodology and Caveats</h3><h3 id="6-3-2-Chunk-server-Workload"><a href="#6-3-2-Chunk-server-Workload" class="headerlink" title="6.3.2 Chunk-server Workload"></a>6.3.2 Chunk-server Workload</h3><h3 id="6-3-3-Appends-versus-Writes"><a href="#6-3-3-Appends-versus-Writes" class="headerlink" title="6.3.3 Appends versus Writes"></a>6.3.3 Appends versus Writes</h3><h3 id="6-3-4-Master-Workload"><a href="#6-3-4-Master-Workload" class="headerlink" title="6.3.4 Master Workload"></a>6.3.4 Master Workload</h3><h1 id="7-Experiences"><a href="#7-Experiences" class="headerlink" title="7 Experiences"></a>7 Experiences</h1><h1 id="8-Related-Work"><a href="#8-Related-Work" class="headerlink" title="8 Related Work"></a>8 Related Work</h1><h1 id="9-Conclusions"><a href="#9-Conclusions" class="headerlink" title="9 Conclusions"></a>9 Conclusions</h1>]]></content>
    
    
    <categories>
      
      <category>分布式存储论文</category>
      
      <category>Goole论文</category>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>分布式文件系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>动态内存分配</title>
    <link href="/2021/09/24/C%E5%92%8CC++/%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"/>
    <url>/2021/09/24/C%E5%92%8CC++/%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/</url>
    
    <content type="html"><![CDATA[<h2 id="C-语言的动态内存分配"><a href="#C-语言的动态内存分配" class="headerlink" title="C 语言的动态内存分配"></a>C 语言的动态内存分配</h2><p>C语言使用<code>malloc</code>和<code>free</code>两个库函数完成动态内存的分配和释放，头文件为<code>stdlib.h</code>。其函数原型为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> * <span class="hljs-title">malloc</span><span class="hljs-params">(size_t_ size)</span></span>;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">free</span><span class="hljs-params">(<span class="hljs-keyword">void</span> *p)</span></span>;<br></code></pre></td></tr></table></figure><p>使用实例：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;string.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">char</span> * name;<br>    name = (<span class="hljs-keyword">char</span> *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">char</span>) * <span class="hljs-number">20</span>);<br>    <span class="hljs-built_in">strcpy</span>(name, <span class="hljs-string">&quot;Ap0l1o&quot;</span>);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s&quot;</span>, name);<br>    <span class="hljs-built_in">free</span>(name);<br>    name = <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>需要注意的地方(C语言内存分配的不足之处)：</p><ul><li><code>malloc</code>函数的参数是要分配的字节数目，这个需要我们自己来计算。比如，上面的实例中，我们先使用<code>sizeof</code>函数计算了<code>char</code>类型的内存大小，然后分配了20个<code>char</code>类型内存大小；</li><li><code>malloc</code>函数的返回值是无类型指针<code>void *</code>，需要我们在程序中强制将其转为指定的类型。所以在上面的实例中，我们使用<code>(char *)</code>将其转为<code>char</code>类型的指针变量；</li><li>特别需要注意的是<code>free</code>函数只是释放了<code>malloc</code>所申请的内存，但并没有改变指针的值，因此，在释放内存后应该将指针指向<code>NULL</code>，否则该指针将指向一个无法控制的内存区域，成为野指针；</li></ul><h2 id="C-动态内存分配"><a href="#C-动态内存分配" class="headerlink" title="C++动态内存分配"></a>C++动态内存分配</h2><p>为了弥补C语言动态内存分配的缺点，C++提供了新的运算符<code>new</code>和<code>delete</code>来完成动态内存的分配和释放。</p><p>使用运算符<code>new</code>和<code>delete</code>的优点为：</p><ul><li><code>new</code>的参数为待分配单元的数目，它自动计算要分配的变量类型的大小；</li><li>它自动返回正确的指针类型，不必对返回的指针进行类型转换；</li><li>可以用<code>new</code>将分配的存储空间进行初始化；</li></ul><p>使用方法为：</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs haxe"><span class="hljs-number">1.</span>  指针变量名 = <span class="hljs-keyword">new</span> <span class="hljs-type"></span>指针基类型名(指针基类型表达式);<br>圆括号里的「指针基类型表达式」意思是用这个表达式的值来初始化指针指向的单元。<br>例如，p = <span class="hljs-keyword">new</span> <span class="hljs-type">double</span>(<span class="hljs-number">1.0</span>)，将指针p指向地址的值初始化为<span class="hljs-number">1.0</span><br><span class="hljs-number">2.</span>  指针变量名 = <span class="hljs-keyword">new</span> <span class="hljs-type"></span>指针基类型名[整型表达式];<br>方括号里的「整型表达式」是要分配一个数组，表达式的值是分配的数组的长度。<br>例如，p = <span class="hljs-keyword">new</span> <span class="hljs-type">char</span>[<span class="hljs-number">10</span>]，指针p指向长度为<span class="hljs-number">10</span>的数组的第一个元素。<br></code></pre></td></tr></table></figure><p>注意事项如下：</p><ul><li>使用<code>new</code>申请的存储空间是没有名字的，只能通过指针间接访问它们；</li><li><code>delete</code> 的操作数必须是一个<code>new</code>返回的指针；</li></ul>]]></content>
    
    
    <categories>
      
      <category>C/C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
      <tag>编程语言</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
